\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
%\NOREVIEWERNOTES
\title
    [Операторы распознавания в моделях восприятия] % Краткое название; не нужно, если полное название влезает в~колонтитул
    {Алгебраические свойства операторов распознавания в моделях зрительного восприятия}
\author
    %[Панов~А.\,И. и др.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
    {Панов~А.\,И.} % основной список авторов, выводимый в оглавление
    %[Автор~И.\,О.$^1$, Соавтор~И.\,О.$^2$, Фамилия~И.\,О.$^2$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\thanks
    {Работа выполнена при финансовой поддержке РФФИ, проект \No\,14-07-31194.}
\email
    {pan@isa.ru}
\organization
    {Федеральное государственное бюджетное учреждение науки Институт системного анализа Российской академии наук (ИСА РАН), Москва, Россия}
\abstract
    {
	В~статье рассматривается задача моделирования зрительного восприятия, приводятся основные принципы построения нисходящих моделей. На~основе этих принципов приводится формальное определение распознающего блока, как базового математического объекта большинства моделей восприятия. Описывается алгоритм его работы, на~основе которого строятся операторы распознавания. Проводится постановка классической статической и динамической задач распознавания и исследуются свойства корректности построенных операторов с использованием алгебраического подхода Ю.\,И.\;Журавлева.

	\bigskip
    \textbf{Ключевые слова}: \emph {компьютерное когнитивное моделирование, распознавание образов, иерархическое динамическое распознавание, корректность операторов распознавания}.
	}
\titleEng
    {Algebraic Properties fo Recogniton Operators in Modeling Visual Perception}
\authorEng
    {Panov~A.\,I.}
\organizationEng
    {Institution of Russian academy of sciences Institute for Systems Analysis RAS, Moscow, Russia}
\abstractEng
    {
	The article discusses the problem of visual perception modelling and presents the main principles of 
	top-down models developed as a result of neurophysiological research. These principles include (a) 
	hierarchical information representation; (b) the ability to predict the type of the incoming signal; (c) the 
	ability to recognize both static and dynamic scenes; (d) the controllability of the perception process. 
	
	The basis of most perception models is a so called recognizing unit. In this paper it is formally defined 
	according to the described principles. Recognition operators are built upon the recognizing unit 
	algorithm which is proposed in the article.
	
	Classical static and dynamic recognition problems are formulated. Correctness of the operators is
	examined using Yu. I. Zhuravlev’s algebraic theory.	The article presents theorems about correctness of several operator classes. These theorems indicate the possibility to build a hierarchy of basic elements that can recognize the incoming signals. This, in its turn, indicates the existence of the corresponding learning algorithm that uses the recognizing blocks.
	
	The obtained results prove that (a) the recognizing blocks algorithm properly models human perception subsystem and does not contradict the modern pattern recognition theory; (b) it is possible to use Yu.\,I.\;Zhuravlev’s algebraic theory to verify if the operators are correct.
	
	\bigskip
    \textbf{Keywords}: \emph{computational cognitive modeling, pattern recognition, dynamic hierarchical recognition, correctness of recognition operators}.
    }
\begin{document}
\maketitle
\linenumbers
\section{Введение}
В отличие от классической задачи распознавания (классификации) образов, задача моделирования зрительного восприятия человека и высших животных имеет ряд существенных особенностей. В моделях восприятия, также как и при распознавании, каждому входному сигналу ставится в соответствие класс (категория, понятие), которому принадлежит данный сигнал. Однако основным критерием качества работы системы, реализующей модель восприятия,является биологическое правдоподобие, а не точность и полнота классификации. Под биологическим правдоподобием понимается два критерия: совпадение определенных параметров поведения системы с параметрами поведения человека в условиях конкретной задачи и построение структуры системы и ее основных компонент в соответствии с физиологическими и нейрофизиологическими особенностями строения функциональных систем \cite{Anohin1975} организма человека, отвечающих за тот или иной моделируемый аспект процесса восприятия.

Наибольший интерес представляют в настоящее время так называемые биологически оправданные (biological-inspired) модели зрительного восприятия, которые за основу берут нейрофизиологические данные о строении зрительных участков коры головного мозга и строении глаза человека. В данном направлении большое внимание уделяется такому аспекту восприятия как внимание, системы моделирования которого получили в последнее время широкое практические применение не только в компьютерном зрении, но и в таких областях робототехники, как навигация, локализация, человеко-машинное взаимодействие \cite{Borji2013}. В биологически оправданных моделях, несмотря на широкое распространение нейросетевой парадигмы, в качестве математического аппарата используются не только нейронные и байесовские сети, но также обобщенные ресурсные и фильтрующие функции, которые строятся по данным когнитивных экспериментов и, как предполагается, моделируют вычисления, производимые отдельным нейроном или их ансамблем в процессе восприятия.

Наибольший интерес с точки зрения моделирования восприятия и внимания у человека представляют так называемые нисходящие (top-down) подходы, в которых делается попытка связывания высокоуровневой модели мира и низкоуровневых процессов распознавания. Иными словами, в таких подходах предпринимается попытка создания системы, которая обладает как моделью представления знаний, подтверждаемой психологическими и лингвистическими данными (например, такой как в работе \cite{Osipov2014}), так и моделью процессов восприятия и внимания, подтверждаемой в свою очередь нейрофизиологическими данными. При такой постановке задачи, возникает большое количество различных подзадач, одной из которых является исследование математических свойств формальных объектов, лежащих в основе моделей, разрабатываемых в рамках нисходящих подходов.

В данной статье приводятся основные принципы работы биологически оправданных моделей восприятия, используемые для построения формальных математических объектов. Проводится исследование этих объектов с использованием алгебраического подхода, разработанного Ю.\,И. Журавлевым для построения общей теории операторов распознавания \cite{Zhuravlev1977}, в частности проводится анализ корректности получаемых множеств биологически оправданных операторов распознавания.

\section{Основные принципы моделей зрительного восприятия}
В данной статье будут рассматриваться математические объекты, которые возникают при описании моделей зрительного восприятия, построенных на следующих основных принципах:
\begin{enumerate*}
\item 
	иерархичность;
\item
	способность выдвигать гипотезы;
\item
	способность распознавать как динамические так и статические явления;
\item
	управляемость.
\end{enumerate*}

Первый принцип был выдвинут в работах когнитивных психологов Трисман и Джелед \cite{Triesman1980} и заключается в том, что на уровне работы сетчатки имеется набор базовых признаков  или протобъектов (на уровне вторичных зрительных отделов коры головного мозга) \cite{Rensink2000}, из которых в процессе научения образуются более сложные признаки. Из полученных сложных признаков строятся еще более сложные и т.\,д. При этом процесс восприятия представляет собой последовательную активацию части получающейся иерархии, начиная с базовых признаков и заканчивая сложным объектом, предъявляемым зрительной системе. Основным критерием принадлежности разных признаков одному объекту (сложному признаку) является пространственная и временная когерентность. Иерархичность процесса восприятия также проявляется и в функциональной иерархичности коры головного мозга, что подтверждается большим количеством нейрофизиологических данных \cite{Hawkins2009, Bolotova2011}.

Основной задачей системы, моделирующей восприятие, на каждом уровне иерархии, таким образом, становится выявление повторяющихся временных и пространственных шаблонов в поступающем наборе сигналов и низкоуровневых признаков.

По данными анализа движения глаз испытуемых доказано, что любой процесс восприятия, как динамического так и статического явления, представляет собой развернутый во времени процесс, каждый этап которого с той или иной степенью точности предсказывается на основе предыдущих этапов \cite{Velichkovsky2006, Hawkins2009}. Именно в этом заключается второй принцип: модель должна включать в себя процессы выдвижения гипотез о том, какая часть иерархии признаков будет активирована в следующий момент времени.

Третий принцип определяет важность параметра времени: модель должна с самого начала уметь работать с меняющимися во времени признаками, не выделяя явно случай статического изображения. Наконец, четвертый принцип основан на теории активного зрения и том факте, что каждый этап распознавания признака на каком-либо уровне иерархии в процессе восприятия чередуется с активным этапом моторной реакции. Особенно ярко этот факт проявляется в случае зрительного восприятия при наблюдении саккадических движений глаза.

Учитывая перечисленные принципы, на которых строятся большинство существующих моделей восприятия (не только зрительного), в следующем параграфе вводится определение распознающего блока, являющегося основным структурным элементом данных моделей. Далее приводится классическая постановка задачи распознавания, множество получаемых операторов распознавания исследуется на корректность относительно поставленной задачи.

\section{Распознающий блок}
Будем рассматривать сложный математический объект $R_i^j$, который будем называть распознающим блоком уровня $j$ с индексом $i$ или просто распознающим блоком. Каждый распознающий блок, исходя из своего названия, распознает, или, как мы будем говорить, измеряет, некоторые признаки. Измерение заключается в сопоставлении признака "--- весовому значению, характеризующему тот факт, удается ли собрать (измерить) признак из составляющих его низкоуровневых входных признаков. Такой вес будем называть весом присутствия признака во входном векторе. Входной вектор, в свою очередь, представляет собой весовой вектор присутствия низкоуровневых признаков, по которым измеряются выходные признаки. Распознающий блок обладает состоянием, которое представляет собой также весовой вектор присутствия входных признаков, но в следующий момент времени. Такой вектор будем называть вектором ожиданий. Запишем все вышесказанное строго.

Пусть заданы множества $\{R_i^j\}$ и $\{f_k\}$. Множество $\{R_i^j\}$ будем называть совокупностью распознающих блоков, а множество $\{f_k\}$ - совокупностью допустимых признаков. Введем бинарное отношение $\dashv$, определенное на паре множеств $\{f_k\}$ и $\{R_i^j\}$, и будем читать $f_k{\dashv}R_i^j$ как <<признак $f_k$ измеряется распознающим блоком $R_i^j$>>. Множество всех измеряемых распознающим блоком $R_i^j$ признаков будем обозначать $F_i^{*j}$, т.е. ${\forall}f^*{\in}F_i^{*j} f^*{\dashv}R_i^j, F_i^{*j}{\subseteq}\{f_k\}$.

Рассмотрим связный ориентированный (ярусный) граф $G_R=(V,E)$, где $V$ - множество вершин, $E$ - множество ребер. Каждую вершину $v$, принадлежащую $j$"~ому ярусу графа $G_R$, будем связывать с соответствующим распознающим блоком $R_i^j$ уровня $j$, а ребро $e=(v,u){\in}E$ будем интерпретировать как иерархическую связь между соответствующим вершине $v$ дочерним блоком $R_{i_1}^{j_1 }$ и соответствующим вершине $u$ блоком-родителем $R_{i_2}^{j_2}$ (рис.~\ref{fg:rec_unit}\subref{fg:operators}).

\begin{figure}[t]
    \centering
    \subfloat[Пример иерархии распознающих блоков]{\includegraphics[width=0.4\textwidth]{operators.jpg}\label{fg:operators}}
    \hspace{0.05\textwidth}
    \subfloat[Циклы вычисления распознающего блока $R_i^j$]{\includegraphics[width=0.4\textwidth]{operator_time.jpg}    \label{fg:operator_time}}
    \caption{Функционирование распознающих блоков.}
    \label{fg:rec_unit}
\end{figure}

Рассмотрим распознающий блок $R_i^j$. Определим множество $F_i^j\subseteq\{f_k\}$ таких признаков, что для любого $f{\in}F_i^j$ существует распознающий блок $R_k^{j-1}$ уровня $j-1$, дочерний по отношению к блоку $R_i^j$, такой, что $f{\dashv}R_k^{j-1}$. Такое множество $F_i^j$ будем называть совокупностью входных признаков распознающего блока $R_i^j$. Для каждого признака $f^*{\in}F_i^{*j}$ введем функцию измерения $\hat{f}(x_1,…,x_q )=x^*$, где $x^*{\in}[0,1]$ "--- весовое значение присутствия измеряемого признака $f^*$, а $x_1,\dots,x_q{\in}[0,1]$ "--- весовое значение присутствия признаков из множества входных признаков $F_i^j$. Множество таких функций для распознающего блока $R_i^j$ обозначим как $\hat{F}_i^j$.

Опишем распознающий блок $R_i^j$ с точки зрения классической теории динамических систем \cite{Kalman1971}. Пусть мощность множества измеряемых признаков $F_i^{*j}$ и множества функций измерения $\hat{F}_i^j$ равна $l$, а мощность множества входных признаков $F_i^j$ равна $q$. Введем упорядоченное множество локальных моментов времени $T_i^j$ для распознающего блока $R_i^j$. Для каждого распознающего блока определим характерный масштаб времени $h_i^j$, за который происходит один цикл вычисления в распознающем блоке $R_i^j$. 

В начале $s$-ого цикла вычисления (момент времени $\tau_s\in{T_i^j}$)  распознающий блок $R_i^j$ получает на вход вектор длины $l$ ожиданий $\hat{x}_i^{j+1}(\tau_s)$, вычисляемый по формуле среднего от векторов ожиданий, получаемых от родительских относительно блока $R_i^j$ распознающих блоков $R_k^{j+1}$:
\[
    \hat{x}_i^{j+1}(\tau_s)=\frac{1}{N}\sum_{k{\in}K^{j+1}}\hat{x}_k^{j+1}(\tau_s),
\]
где $N$ - количество родительских блоков, $K^{j+1}$ - множество индексов родительских относительно $R_i^j$ распознающих блоков. Далее в каждый момент времени $t\in{T_i^j}$, $\tau_s\leqslant{t}\leqslant\tau_s+h_i^j$,  распознающий блок $R_i^j$ получает на вход весовой вектор $\bar{x}_i^j(t)$ длины $l$ присутствия входных признаков из множества $F_i^j$, вычисляет выходной весовой вектор $\bar{x}_i^{*j}(t)$ длины $l$ присутствия измеряемых признаков из множества $F_i^{*j}$, вычисляет вектор длины $q$ ожиданий $\hat{x}_i^j(t)$ присутствия входных признаков в следующий момент времени (рис.~\ref{fg:rec_unit}\subref{fg:operator_time}). 

Обозначим множество возможных мгновенных значений выходных векторов распознающего блока $R_i^j$ как $X_i^{*j}$. Очевидно, что $X_i^{*j}$ является векторным пространством. Обозначим множество возможных мгновенных значений весовых векторов присутствия входных признаков как $X_i^j$. Очевидно, что $X_i^j$ также является векторным пространством. Определим входное воздействие $\omega:T{\to}X_i^j$ и выходную величину $\gamma:T{\to}X_i^{*j}$ в смысле теории динамических систем. Будем считать, что множество всех возможных мгновенных значений векторов ожиданий образует множество состояний $\hat{X}_i^j$ распознающего блока $R_i^j$. Определим функцию переходов $\varphi(t;\tau_s,\hat{x}_i^{j+1},\omega)=\hat{x}_i^j$ в смысле теории динамических систем. Множество $\hat{X}_i^j$ в таком случае интерпретируется как множество состояний распознающего блока $R_i^j$. Также определим выходное отображение $\eta:T{\times}\hat{X}_i^j{\to}X_i^{*j}$ в смысле теории динамических систем, определяющее выходные векторы $\bar{x}_i^{*j}(t)=\eta(t,\hat{x}_i^j(t))$ (рис.~\ref{fg:recognition_unit}).

\begin{figure}[t]
    \includegraphics[width=\linewidth]{recognition_unit.jpg}
    \caption{Схема входных и выходных отображений распознающего блока.}
    \label{fg:recognition_unit}
\end{figure}

Будем рассматривать распознающий блок $R_i^j$ как динамическую систему с дискретным временем, т.е. считать множество моментов времени $T$ множеством целых чисел. Каждой функции измерения $\hat{f}_k$ из множества $\hat{F}_i^j$ будем ставить в соответствие набор матриц предсказания $Z_k=\{Z_1^k,…,Z_m^k\}$ размерности $q{\times}h_i^j$, где $h_i^j$ - характерное время распознающего блока $R_i^j$. Столбец $\bar{z}_u^r=(z_{u1}^k,…,z_{uq}^k)$ матрицы $Z_r^k$ интерпретируется как вектор предсказания присутствия входных признаков из множества $F_i^j$ в момент времени $\tau_s+u$, при этом $z_{uv}^k\in\{0,1\}$, т.е. вектор $\bar{z}_u^r$ является булевым вектором. Сама матрица $Z_r^k$ задает, таким образом, последовательность событий, наличие которой свидетельствует о присутствии измеряемого функцией $\hat{f}_k$ признака. Множество всех матриц предсказания распознающего блока $R_i^j$ будем обозначать как $\mathcal{Z}_i^j$.

В листинге \ref{alg:transit_th} приведен пороговый алгоритм $\mathfrak{A}_{th}$ вычислительного цикла распознающего блока, в котором рассчитываются значения функции переходов $\varphi(\tau_s+t;\tau_s,\hat{x}_i^{j+1},\omega)$, $0\leqslant{t}\leqslant{h_i^j}$, и выходного отображения $\eta(\tau_s+t,\hat{x}_i^j(\tau_s+t))$.

\begin{algorithm}
\caption{Пороговый алгоритм $\mathfrak{A}_{th}$}
\label{alg:transit_th}
\begin{algorithmic}[1]
    \REQUIRE $\tau_s, \hat{x}_i^{j+1}(\tau_s), \omega$
    \ENSURE $\varphi, \eta$

    \STATE $\hat{F}^*=\varnothing$ \COMMENT{множество активных функций измерения}
    \STATE $Z^*=\varnothing$ \COMMENT{множество подходящих матриц предсказания}
	\STATE $t=0$
    \STATE $c_1\in(0,1), c_2\in(0,1)$ \COMMENT{константы --- параметры алгоритма}

    \FORALL{компонент $\hat{x}_{ik}^{j+1}$ вектора $\hat{x}_i^{j+1}(\tau_s)=(\hat{x}_{i1}^{j+1},\hat{x}_{i2}^{j+1},\dots,\hat{x}_{il}^{j+1})$}
        \IF{$\hat{x}_{ik}^{j+1}{\ge}c_1$}
            \STATE $\hat{F}^*:=\hat{F}^*\cup\{\hat{f}_k\}$ \COMMENT{помещаем соответствующую функцию измерения в множество активных функций измерения}
        \ENDIF
    \ENDFOR

    \FORALL{функций измерения $\hat{f}_k\in\hat{F}^*$}
        \FORALL{матриц предсказания $Z_r^k$ из соответствующего функции измерения $\hat{f}_k$ множества $\mathcal{Z}_k$}
            \IF{$\frac{\|\bar{z}_1^r-\bar{x}_i^j\|}{\|\bar{z}_1^r\|+\|\bar{x}_i^j\|}<c_2$}
                \STATE $Z^*:=Z^*\cup\{Z_r^k\}$ \COMMENT{пополняем множество подходящих матриц предсказания}
            \ENDIF
        \ENDFOR
    \ENDFOR

	\STATE $\hat{x}_i^j(\tau_s)=\hat{x}_i^{j+1}(\tau_s)$

	\WHILE{$t\leqslant{h_i^j}-1$}
		\STATE $\bar{x}_i^j=\omega(\tau_s+t)$
		\STATE $\bar{x}_i^{*j}=(0,\dots,0)$

    		\FORALL{компонент $x_{is}^{*j}$ вектора $\bar{x}_i^{*j}=(x_{i1}^{*j},…,x_{il}^{*j})$}
        		\STATE $x_{is}^{*j}=\frac{|Z^*|_s}{\max_{\hat{f}_v}|Z^*|_v}$ \COMMENT{$|Z^*|_s$ - количество матриц предсказания, соответствующих функции измерения $\hat{f}_s$}
    		\ENDFOR
		
		\STATE $\eta(\tau_s+t, \hat{x}_i^j(\tau_s+t))=\bar{x}_i^{*j}$

		\FORALL{матриц предсказания $Z_r^k$ из множества $Z^*$}
            \IF{$\frac{\|\bar{z}_{t+2}^r-\omega(\tau_s+t+1)\|}{\|\bar{z}_{t+2}^r\|+\|\omega(\tau_s+t+1)\|}\geqslant{c_2}$}
                \STATE $Z^*:=Z^*\setminus\{Z_r^k\}$ \COMMENT{исключаем не подходящие на следующем шаге матрицы предсказания}
            \ENDIF
        \ENDFOR
		
		\STATE $t=t+1$
		
		\IF{$t\leqslant{h}_i^j-1$}
			\STATE $\hat{x}_i^j=(0,\dots,0)$ \COMMENT{следующее состояние}

    			\FORALL{компонент $\hat{x}_{is}^j$ вектора ожиданий $\hat{x}_i^j=(\hat{x}_{i1}^j,\hat{x}_{i2}^j,\dots,\hat{x}_{iq}^j)$}
        			\STATE $\hat{x}_{is}^j=\frac{1}{|Z^*|}\sum_{\hat{f}_v{\in}\hat{F}^*}\sum_{Z_r^v{\in}Z^*}\hat{x}_v^{j+1}{\cdot}z_{(t+1)s}^r$
        		\COMMENT{$|Z^*|$~--- мощность множества подходящих матриц предсказания $Z^*$, $\bar{z}_{t+1}^r$~--- $(t+1)$-й столбец входящей в множество $Z^*$ матрицы предсказаний $Z_r^v$ признака $f_v$}
    			\ENDFOR
			\STATE $\varphi(\tau_s+t;\tau_s,\hat{x}_i^{j+1}, \omega)=\hat{x}_i^j(\tau_s+t)=\hat{x}_i^j$
		\ENDIF
	\ENDWHILE

\end{algorithmic}
\end{algorithm}

\section{Статическая задача классификации}
В начале рассмотрим статический случай, т.е. зафиксируем момент времени $t$, равный началу некоторого $s$~-го вычислительного цикла $\tau_s$, и будем считать, что характерное время $h_i^j$ распознающего блока $R_i^j$ равно $1$, т.е. все матрицы из множества $\mathcal{Z}_i^j$ состоят из одного столбца. В этом случае, распознающий блок $R_i^j$ можно рассматривать как статический оператор распознавания $R_i^j(\hat{x}_i^{j+1},\mathcal{Z}_i^j,\bar{x}_i^j)=\bar{x}_i^{*j}$. Напомним, что $\bar{x}_i^{*j}$ "--- это весовой вектор присутствия измеряемых признаков $f_1^*,\dots,f_l^*$ из множества $F_i^{*j}$. Далее кратко будем записывать $R(\hat{x},\mathcal{Z},\bar{x})=\bar{x}^*$, опуская индексы $j$ и $i$.

Введем совокупность задач $\{Q\}$ аналогично работе \cite{Zhuravlev1977}. Задача $Q(\hat{x},\bar{x},\alpha_1,\dots,\alpha_l)\in\{Q\}$ состоит в построении оператора, вычисляющего по поступившему вектору ожиданий $\hat{x}$ и входному вектору $\bar{x}$ значения $\alpha_1,\dots,\alpha_l\in\{0,1\}$ присутствия признаков $f_1^*,…,f_l^*$. Другими словами, искомый алгоритм $\mathcal{A}^*$ переводит набор $(\hat{x},\bar{x})$ в вектор $\bar{\alpha}=(\alpha_1,\dots,\alpha_l)$, который будем называть информационным вектором входного вектора $\bar{x}$.
Пусть множество $\{\mathcal{A}\}$ состоит из алгоритмов, переводящих пары $(\hat{x},\bar{x})$ в векторы $\bar{\beta}$, составленные из элементов $0,1,\Delta:\mathcal{A}(\hat{x},\bar{x})=\bar{\beta}$. Если $\beta_i\in\{0,1\}$, то $\beta_i$~--- значение величины $\alpha_i$, вычисленное алгоритмом $\mathcal{A}$. Если $\beta_i=\Delta$, то алгоритм $\mathcal{A}$ не вычислил значение $\alpha_i$.

\begin{Def}
    Алгоритм $\mathcal{A}$ называется корректным для задачи $Q$, если выполнено равенство
    \[
        \mathcal{A}(\hat{x},\bar{x})=\bar{\alpha}.
    \]
    Алгоритм $\mathcal{A}$, не являющийся корректным для $Q$, называется некорректным.
\end{Def}

Далее будем считать, что множество $\{\mathcal{A}\}$ является совокупностью, вообще говоря, некорректных алгоритмов.

\begin{State}[аналог теоремы 1 из \cite{Zhuravlev1977}]
\label{st:decompositon}
    Каждый алгоритм $\mathcal{A}\in\{\mathcal{A}\}$ представим как последовательность выполнения алгоритмов $R$ и $C$, где $R(\hat{x},\bar{x})=\bar{x}^*$, $\bar{x}^*$~--- вектор действительных чисел, $C(\bar{x}^*)=\bar{\beta}$, $\beta_i\in\{0,1,\Delta\}$.
\end{State}

\begin{Proof}
    Пусть $D$ "--- алгоритм перехода вектора $\bar{\beta}$ к числовому вектору $\bar{y}$. В качестве $D$ можно рассмотреть, например, $y_i=\beta_i$, если $\beta_i\in\{0,1\}$, и $y_i=1/2$, если $\beta_i=\Delta$. Очевидно, что существует обратный алгоритм $D^{-1}$ перехода от $\bar{y}$ к $\bar{\beta}$. Положим $R=\mathcal{A}{\cdot}D$, $C=D^{-1}$. Тогда очевидно, что $\mathcal{A}=R{\cdot}C=(\mathcal{A}{\cdot}D){\cdot}D^{-1}=\mathcal{A}$.
\end{Proof}

Из утверждения \ref{st:decompositon} следует, что множество алгоритмов $\{\mathcal{A}\}$ порождает множества $\{R\}$ и $\{C\}$, которые будем называть множеством операторов распознавания и множеством решающих правил, соответственно. В качестве операторов из множества $\{R\}$ будем рассматривать операторы $R(\hat{x},\mathcal{Z},\bar{x})$.

\begin{Def}
    Решающее правило $C^*$ называется корректным на множестве входных векторов $X$, если для всякого вектора $\bar{x}$ из $X$ существует хотя бы один числовой вектор $\bar{x}^*$ такой, что $C^*(\bar{x}^*)=\bar{\alpha}$, где $\bar{\alpha}$~--- информационный вектор входного вектора $\bar{x}$.
\end{Def}

В множестве операторов $\{R\}$ введем операции умножения на скаляр, сложения и умножения. Пусть $r'$ - скаляр, $R',R''\in\{R\}$. Определим операторы $r'{\cdot}R'$, $R'+R''$ и $R{\cdot}R''$ следующим образом:

\begin{equation}
\label{eq:oper_scalar}
    r'{\cdot}R'=(r'{\cdot}{x_1^*}',\dots,r'{\cdot}{x_l^*}'),
\end{equation}

\begin{equation}
\label{eq:oper_sum}
    R'+R''=({x_1^*}'+{x_1^*}'',\dots,{x_1^*}'+{x_l^*}''),
\end{equation}

\begin{equation}
\label{eq:oper_mult}
    R'{\cdot}R''=({x_1^*}'{\cdot}{x_1^*}'',\dots,{x_1^*}'{\cdot}{x_l^*}'').
\end{equation}

\begin{State}
    Замыкание $L\{R\}$ множества $\{R\}$ относительно операций \eqref{eq:oper_scalar} и \eqref{eq:oper_sum} является векторным пространством.
\end{State}

\begin{State}
    Замыкание $\mathfrak{U}\{R\}$ множества $\{R\}$ относительно операций \eqref{eq:oper_scalar}, \eqref{eq:oper_sum} и \eqref{eq:oper_mult} является ассоциативной линейной алгеброй с коммутативным умножением.
\end{State}

\begin{Def}
    Множества $L\{A\}$ и $\mathfrak{U}\{A\}$ алгоритмов $\mathcal{A}=R{\cdot}C^*$ соответственно таких, что $R{\in}L\{R\}$ и $R\in\mathfrak{U}\{R\}$, соответственно называются линейными и алгебраическими замыканиями множества $\{\mathcal{A}\}$.
\end{Def}

Зафиксируем пару $(\hat{x},\bar{x})$ вектора ожидания и входного вектора. Аналогично \cite{Zhuravlev1977} будем рассматривать задачи $Q(\hat{x},\bar{x})$, обладающие следующим свойством относительно множества операторов распознавания $\mathcal{R}$.

\begin{Def}
    Если множество векторов $\{R(\hat{x},\bar{x})\}$, где $R$ пробегает некоторое множество операторов распознавания $\mathcal{R}$, содержит базис в пространстве числовых векторов длины $l$, то задача $Q(\hat{x},\bar{x},\bar{\alpha})$ называется полной относительно $\mathcal{R}$.
\end{Def}

\begin{State}[аналог теоремы 2 из \cite{Zhuravlev1977}]
\label{st:correctness}
    Если множество задач $\{Q\}$ состоит лишь из задач, полных относительно $\mathfrak{R}$, то линейное замыкание $L\{R{\cdot}C^*\}$ ($C^*$~--- произвольное фиксированное корректное решающее правило, $R$ пробегает множество $\mathcal{R}$) является корректным относительно $\{Q\}$.
\end{State}

\begin{Proof}
    При фиксированном $l$ пространство числовых векторов длины $l$ состоит из $l$ векторов. В множестве $\{R(\hat{x},\bar{x})\}$ выделим совокупность базисных векторов $e_1,\dots,e_l$. Тогда существуют числа $c_1,\dots,c_l$ такие, что
    \[
        \bar{x}^*=\sum_{i=1}^{l}c_i{\cdot}e_i,
    \]
    где $\bar{x}^*$~--- такой вектор, что $C^*(\bar{x}^*)=\bar{\alpha}$~--- информационный вектор входного вектора $\bar{x}$. Из корректности $C^*$ следует, что такой вектор существует. Разложение вектора $\bar{x}^*$ возможно в силу того, что векторы $e_1,\dots,e_l$ образуют базис в пространстве числовых векторов длины $l$. Если векторы $e_1,\dots,e_l$ построены из пары $(\hat{x},\bar{x})$ при помощи операторов $R_1,\dots,R_l$, то алгоритм $\mathcal{A}=(\sum_{i=1}^{l}c_i{\cdot}e_i){\cdot}C^*$ переводит $(\hat{x},\bar{x})$ в информационный вектор $\bar{\alpha}$.
\end{Proof}

\begin{Corollary}
    Пусть $\{\mathcal{A}\}$~--- совокупность некорректных алгоритмов, $\{R\}$~--- соответствующее множество операторов распознавания, $C^*$~--- фиксированное корректное решающее правило. Тогда $L\{\mathcal{A}\}=L\{R{\cdot}C^*\}$ является корректным относительно множества задач $\{Q\}$, если $\{Q\}$ состоит из задач, полных относительно $\{R\}$.
\end{Corollary}

Будем рассматривать только такие задачи $Q(\hat{x},\bar{x},\bar{\alpha})$, для которых удовлетворяется следующее условие: ${\exists}k$ такое, что $x_k$ является $k$~-ым элементом вектора $\bar{x}$ и $x_k>c_1$. Такое условие является естественным, иначе вектор $\bar{x}$, в котором отсутствуют весовые значения больше $c_1$, не может рассматриваться как достоверный с точки зрения порогового алгоритма \ref{alg:transit_th}.

\begin{Theorem}
	\label{th:correctness}
    Линейное замыкание $L\{\mathcal{A}\}$ семейства алгоритмов $\{\mathcal{A}\}=\{R{\cdot}C^*\}$ с произвольным корректным решающим правилом $C^*$ и операторами распознавания $R$, определенными пороговым алгоритмом \ref{alg:transit_th}, является корректным на $\{Q\}$.
\end{Theorem}

\begin{Proof}
    В силу утверждения \ref{st:correctness} достаточно доказать, что произвольная задача $Q\in\{Q\}$ является полной относительно $\{R\}$. Доказательство полноты $Q$ состоит в прямом построении операторов $R_i^\epsilon, i=1,2,\dots,l$ из $L\{R\}$, переводящих пару $(\hat{x},\bar{x}), \hat{x}=(\hat{x}_1,\dots,\hat{x}_l), \bar{x}=(x_1,\dots,x_q)$ в числовой вектор $\bar{x}_i^*=(x_{i1}^*,\dots,x_{il}^*)$, в котором $x_{ii}^*=1$, а $|x_{ij}^*|<\epsilon$ при $j{\neq}i$. Построение проводится для любого сколь угодно малого $\epsilon$.

    Пусть мощность множества $\mathcal{Z}_i$ признака $f_i$ равна $N$, норма $\|x\|$ равна $M{\leqslant}q$, максимальная компонента вектора $\bar{x}$ равна $x_{max}$. Зафиксируем величину $i$ и коэффициенты $c_1=\min_{x}\hat{x}_k, c_2=\frac{M}{1+M}$. Рассмотрим матрицы предсказания из множеств $\mathcal{Z}_1,\dots,\mathcal{Z}_l$ признаков $f_1,\dots,f_l$, удовлетворяющие следующим условиям:
    \begin{enumerate}
    \afterlabel)
        \item
            в каждой матрице предсказаний $Z_r^i\in\mathcal{Z}_i$ в столбце $\bar{z}_{t-\tau}^r=(z_{t-\tau,1}^r,\dots,z_{t-\tau,q}^r)$ компонента $z_{t-\tau,k}^r=1$, если $x_k=x_{max}$, и $z_{t-\tau,k}^r=0$, если $x_k<x_{max}$;
        \item
            в каждой матрице предсказаний $Z_r^j\in\mathcal{Z}_j, j{\neq}i$ в столбце $\bar{z}_{t-\tau}^r=(z_{t-\tau,1}^r,\dots,z_{t-\tau,q}^r)$ компонента $z_{t-\tau,k}^r=0$ при любых $k$.
    \end{enumerate}

    Вычислим величину $x_{ii}^*$. Т.\,к.~$c_1=\min_{\hat{x}}\hat{x}_k$, то условие $\hat{x}_i{\geqslant}c_1$ на строчке 5 алгоритма \ref{alg:transit_th} автоматически выполняется и функция измерения $\hat{f}_i$ попадает в множество $\hat{F}^*$. Из условия 1) следует, что каждая матрица $Z_r^i\in\mathcal{Z}_i$ попадает в множество $Z^*$ на строчке 10 алгоритма \ref{alg:transit_th}:
    \[
        \frac{\|\bar{z}_{t-\tau}^r-\bar{x}\|}{\|\bar{z}_{t-\tau}^r\|+\|\bar{x}\|}<\frac{\sum_{k}|z_{t-\tau,k}^r-x_k|}{1+M}<\frac{M}{1+M}=c_2,
    \]
    так как минимум один компонент в $\bar{z}_{t-\tau}^r$ равен $1$ и существует элемент $x_k>1/2$. В этом случае $x_{ii}^*=\gamma{\cdot}N$, где $\gamma$~--- весовой коэффициент.

    Оценим величины $x_{ij}^*$. Т.к. $c_1=\min_{\hat{x}}\hat{x}_k$, то условие $\hat{x}_j{\geqslant}c_1$ на строчке 5 алгоритма \ref{alg:transit_th} автоматически выполняется и все функции измерения $\hat{f}_j$ попадают в множество $\hat{F}^*$. Из условия 2) следует, что каждая матрица $Z_r^j\in\mathcal{Z}_j$ не попадает в множество $Z^*$ на строчке 10 алгоритма \ref{alg:transit_th}:
    \[
        \frac{\|\bar{z}_{t-\tau}^r-\bar{x}\|}{\|\bar{z}_{t-\tau}^r\|+\|\bar{x}\|}=\frac{M}{M}=1>\frac{M}{1+M}>c_2.
    \]
    В этом случае $x_{ij}^*=0$.

    Рассмотрим оператор распознавания $\frac{1}{\gamma{\cdot}N}R(\hat{x},\mathcal{Z},\bar{x})$, который переводит задачу $Q$ в вектор $\bar{x}_i^*$, причем $\bar{x}_{ii}^*=1$, а $\bar{x}_{ij}^*=0<\epsilon, j{\neq}i$. Таким образом, условия на числовой вектор $\bar{x}_i^*$ выполняются. Полнота задачи $Q$ доказана.
\end{Proof}

Фиксация момента времени не в начале вычислительного цикла, а на любом другом значении $\tau_s<t\leqslant\tau_s+h_i^j$, приводит к операторам вида $R_i^j(\hat{x}_i^j(t), \mathcal{Z}_i^j, \bar{x}_i^j(t))$, который кратко будем записывать $R^t$. Для этих операторов постановка задачи распознавания выглядит таким же образом как и для операторов $R$, формулировки определений полноты и корректности идентичны. Теорема о корректности линейного замыкания $L\{R^t\cdot{C^*}\}$ доказывается аналогично.

\section{Динамическая задача классификации}
Теперь рассмотрим динамическую постановку задачи. Будем фиксировать не конкретный момент времени $t$, а промежуток времени ${\Delta}t=[\tau_s,\tau_s+h_i^j)$. В этом случае распознающий блок $R_i^j$ можно рассматривать как динамический оператор распознавания $\hat{R}_i^j(\hat{x}_i^{j+1}(\tau_s), \mathcal{Z}_i^j, \omega_{\Delta{t}})=\gamma_{\Delta{t}}$, принимающий  функцию входного воздействия $\omega$, ограниченную на промежутке времени ${\Delta}t$, и выдающую функцию выходной величины $\gamma$ на том же временном промежутке. Так как мы предполагаем время дискретным, т.~е. множество моментов времени $T$ является множеством целых чисел, то действие динамического оператора $\hat{R}_i^j$ можно заменить последовательным действием статических операторов $R_i^j(\hat{x}_i^{j+1}(\tau_s), \mathcal{Z}_i^j, \bar{x}_i^j(\tau_s)), R_i^j(\hat{x}_i^j(\tau_s+1), \mathcal{Z}_i^j, \bar{x}_i^j(\tau_s+1)), \dots, R_i^j(\hat{x}_i^j(\tau_s+h_i^j-1), \mathcal{Z}_i^j, \bar{x}_i^j(\tau_s+h_i^j-1))$, в результате выдающих последовательность $\{\bar{x}_i^{*j}(t)\}=\{\bar{x}_i^{*j}(\tau_s), \bar{x}_i^{*j}(\tau_s+1), \dots, \bar{x}_i^{*j}(\tau_s+h_i^j-1)\}$. Так как параметр $h_i^j$ фиксирован, то конечные последовательности векторов  $\omega_{\Delta{t}}$ и $\gamma_{\Delta{t}}$ можно считать матрицами размерности $l\times{h_i^j}$. Далее будем опускать индексы $i$ и $j$.

Формулировка задачи в динамическом случае будет выглядеть следующим образом: задача $\hat{Q}(\hat{x}, \omega_{{\Delta}t}, \bar{\alpha})$ состоит в построении алгоритма $\hat{\mathcal{A}}$, вычисляющего по поступившему начальному вектору ожиданий $\hat{x}$ матрице входных воздействий $\omega_{{\Delta}t}$  последовательность векторов $\beta_{\Delta{t}}$, монотонно сходящуюся к информационному вектору $\bar{\alpha}$. Т.~е. искомый оператор распознавания $\hat{R}$ должен выдавать матрицу весовых значений присутствия измеряемых признаков $\gamma_{\Delta{t}}$, столбцы которой должны сходиться (с учетом корректного решающего правила) к информационному вектору: $\lim_{t\to\tau_s+h}\bar{x}^*(t)=\bar{\alpha}$. Введем соответствующие определения.

\begin{Def}
Алгоритм $\hat{\mathcal{A}}(\hat{x},\bar{x})=\beta_{\Delta{t}}=(\bar{\beta}_1,\dots,\bar{\beta}_h)$ называется корректным для задачи $\hat{Q}$, если выполнено условие
	\[
        \|\bar{\beta}_1-\bar{\alpha}\|\geqslant\|\bar{\beta}_2-\bar{\alpha}\|\geqslant\dots
\geqslant\|\bar{\beta}_h-\bar{\alpha}\|=0.
    \]
$\|\bar{\beta}_i-\bar{\alpha}\|=
\sum_j{(\beta_{ij}-\alpha_j)}$, где $\beta_{ij}-\alpha_j=0$, если $\beta_{ij}=\alpha_j$, $\beta_{ij}-\alpha_j=\frac{1}{2}$, если $\beta_{ij}=\Delta$, и $\beta_{ij}-\alpha_j=0$ иначе. Алгоритм $\hat{\mathcal{A}}$, не являющийся корректным для $\hat{Q}$, называется некорректным.
\end{Def}

\begin{State}
\label{st:decompositon_dyn}
    Каждый алгоритм $\hat{\mathcal{A}}\in\{\hat{\mathcal{A}}\}$ представим как последовательность выполнения алгоритмов $\hat{R}$ и $\hat{C}$, где $\hat{R}(\hat{x}, \mathcal{Z}, \omega_{\Delta{t}})=\gamma_{\Delta{t}}$, $\gamma_{\Delta{t}}$~---матрица действительных чисел, $\hat{C}(\gamma_{\Delta{t}})=\beta_{\Delta{t}}$, $\beta_{\Delta{t}}$~---матрица значений $\beta_{ij}\in\{0,1,\Delta\}$.
\end{State}

\begin{Proof}
	Проводится аналогично утверждению \ref{st:decompositon} с тем отличием, что рассматриваются не отдельные векторы, а матрицы.
\end{Proof}

Корректное решающее правило $\hat{C}^*$ для матрицы $\gamma_{\Delta{t}}$ определяется через набор корректных правил для векторов $(
\hat{C}_1^*, \dots, \hat{C}_h^*)$ таких, что $\|C_1^*(\bar{x}^*(\tau_s))-\bar{\alpha}\|\geqslant\|C_2^*(\bar{x}^*(\tau_s+1))-\bar{\alpha}\|\geqslant\dots\geqslant\|C_h^*(\bar{x}^*(\tau_s+h-1))-\bar{\alpha}\|=0$. В простейшем случае $\forall{i}$ $C_i^*(\bar{x}^*(\tau_s+i))=\bar{\alpha}$. Аналогично статическому случаю вводятся определения линейного $L\{\hat{R}\}$ и алгебраического $\mathfrak{U}\{\hat{R}\}$ замыкания над множеством $\{\hat{R}\}$. 

Зафиксируем начальный вектор ожиданий $\hat{x}$ и последовательность входных векторов $\omega_{\Delta{t}}$. Если, как и в статическом случае, будем рассматривать только такие задачи $\hat{Q}(\hat{x},\omega_{\Delta{t}},\bar{\alpha})$, для которых в матрице $\omega_{\Delta{t}}$ в каждом столбце с номером $s$ ${\exists}k$ такое, что $x_{sk}$ является $k$~-ым элементом вектора $\bar{x}(\tau_s+s)$ и $x_{sk}>c_1$, то можно сформулировать следующую теорему.

\begin{Theorem}
    Линейное замыкание $L\{\hat{\mathcal{A}}\}$ семейства алгоритмов $\{\hat{\mathcal{A}}\}=\{\hat{R}{\cdot}\hat{C}^*\}$ с произвольным корректным решающим правилом $\hat{C}^*$ и операторами распознавания $\hat{R}$, определенными пороговым алгоритмом \ref{alg:transit_th}, является корректным на $\{\hat{Q}\}$.
\end{Theorem}

\begin{Proof}
	В силу того, что динамический оператор $\hat{R}$ представим в виде последовательного применения статических операторов $R_i$ к столбцам матрицы $\omega_{\Delta{t}}$, то для доказательства теоремы необходимо подобрать такие операторы $R_i$, которые выдают последовательность $\gamma_{\Delta{t}}$, сходящуюся (с учетом применения простейшего корректного решающего правила $\hat{C}^*=(C_1^*,\dots,C_i^*)$) к информационному вектору $\bar{\alpha}$.
	
Рассмотрим алгебраическое замыкание $L\{R_i\}$ операторов вида $R_i(\hat{x}(\tau_s+i), \mathcal{Z}_i, \omega_{{\Delta}t}(\tau_s+i))$ с фиксированным вектором $\hat{x}(\tau_s+i)$ и $\omega(\tau_s+i)$. Из задачи $\hat{Q}(\hat{x}, \omega_{{\Delta}t}, \bar{\alpha})$ выделим подзачаду $Q_i(\hat{x}(\tau_s+i), \omega_{{\Delta}t}(\tau_s+i), \bar{\alpha})$. В силу теоремы \ref{th:correctness} можно построить такой оператор $R_i^*\in{L}\{R_i\}$, что $C_i^*(R_i^*(\omega(\tau_s+i)))=\bar{\alpha}$. Формируя таким образом линейные замыкания и формулируя подзадачи для каждого момента времени, получим необходимую последовательность $\gamma_{\Delta{t}}=(C_1^*(R_1^*(\omega(\tau_s))), \dots, C_h^*(R_h^*(\omega(\tau_s+h-1))))=(\bar{\alpha},\dots,\bar{\alpha})$, которая очевидным образом сходится к $\bar{\alpha}$. Корректность, таким образом, доказана.
\end{Proof}

\section{Заключение}
На основании исследуемых в статье математических свойств распознающих блоков, реализующих основные принципы моделей восприятия, можно сделать следующие выводы:
\begin{enumerate*}
\item 
	динамические характеристики моделей восприятия описываются в терминах классической теории управления;
\item
	базовые структурные элементы данных моделей представляют собой операторы распознавания, которые можно изучать в рамках классических алгебраических теорий;
\item
	базовые структурные элементы моделей восприятия обладают свойством корректности относительно входных данных и требуемых результатов классификации, что означает существования такого процесса обучения, в рамках которого будут сформирована иерархия базовых элементов, корректно распознающая (классифицирующая) поступающие сигналы.
\end{enumerate*}

\section{Литература}
\renewcommand{\bibname}{}
\begin{thebibliography}{99}
\bibitem{Anohin1975}
    \BibAuthor{Анохин\;П.\,К.}\, 1975.
    Очерки по физиологии функциональных систем.
    М.:~Медицина.
\bibitem{Bolotova2011}
    \BibAuthor{Болотова\;Ю.\,А., Спицын\;В.\,Г., Фомин\;А.\,Э.}
    \BibTitle{Применение иерархической временной памяти в распознавании изображений}~//
    \BibJournal{Известия Томского политехнического университета}. 2011. Т.\,318, \No\,5. С.\,60--63.
\bibitem{Velichkovsky2006}
    \BibAuthor{Величковский\;Б.\,М.}
    Когнитивная наука: основы психологии познания. Т.\,1. "---
    М.: Смысл, 2006. "--- 448~с.
\bibitem{Zhuravlev1977}
    \BibAuthor{Журавлев\;Ю.\,И.}
    \BibTitle{Корректные алгебры над множеством некорректных (эвристических) алгоритмов. Часть I}~//
    \BibJournal{Кибернектика}. 1977. \No\,4. С.\,5--17.
\bibitem{Kalman1971}
    \BibAuthor{Калман\;Р., Фалб\;П., Арбиб\;М.}
    Очерки по математической теории систем. "---
    М.: Мир, 1971. "--- 400~с.
\bibitem{Osipov2014}
    \BibAuthor{Осипов\;Г.\,С., Панов\;А.\,И., Чудова\;Н.\,В.}
    \BibTitle{Управление поведением как функция сознания. I. Картина мира и целеполагание}~//
    \BibJournal{Известия РАН. Теория и системы управления}. 2014. \No\,4. С.\,83--96.
\bibitem{Borji2013}
    \BibAuthor{Borji\;A., Itti\;L.}
    \BibTitle{State-of-the-Art in Visual Attention Modeling}~//
    \BibJournal{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2013. Vol.\,35, No.\,1. Pp.\,185--207.
\bibitem{Hawkins2009}
    \BibAuthor{George\;D., Hawkins\;J.}
    \BibTitle{Towards a Mathematical Theory of Cortical Micro-circuits}~//
    \BibJournal{PLoS Computational Biology}, 2009. Vol.\,5, No.\,10. Pp.\,1--26.
\bibitem{Rensink2000}
    \BibAuthor{Rensink\;R.}
    \BibTitle{The dynamic representation of scenes}~//
    \BibJournal{Visual Cognition}, 2000. No.\,7. Pp.\,17--42.
\bibitem{Triesman1980}
    \BibAuthor{Triesman\;A.\,M., Gelade\;G.}
    \BibTitle{A Feature Integration Theory of Attention}~//
    \BibJournal{Cognitive Psyhology}, 1980. Vol.\,12. Pp.\,97--136.
\end{thebibliography}

\section{References}
\renewcommand{\bibname}{}
\begin{thebibliography}{99}
\bibitem{Anohin1975e}
	\BibAuthor{Anokhin\;P.\,K.}
	Philosophical aspects of the theory of functional systems. "---
	1978.
\bibitem{Bolotova2011e}
    \BibAuthor{Bolotova\;Ju.\,A., Spicin\;V.\,G., Fomin\;A.\,E.}
    \BibTitle{Application of hierarchical temporal memory in image recognition (in Russian)}~//
    \BibJournal{Izvestia Tomskogo politechnicheskogo universiteta}. 2011. Vol.\,318, No.\,5. Pp.\,60--63.
\bibitem{Borji2013e}
    \BibAuthor{Borji\;A., Itti\;L.}
    \BibTitle{State-of-the-Art in Visual Attention Modeling}~//
    \BibJournal{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2013. Vol.\,35, No.\,1. Pp.\,185--207.
\bibitem{Hawkins2009e}
    \BibAuthor{George\;D., Hawkins\;J.}
    \BibTitle{Towards a Mathematical Theory of Cortical Micro-circuits}~//
    \BibJournal{PLoS Computational Biology}, 2009. Vol.\,5, No.\,10. Pp.\,1--26.
\bibitem{Kalman1971e}
    \BibAuthor{Kalman\;R.\,E. and Falb\;P.\,L. and Arbib\;M.\,A.}
    Topics in Mathematical System Theory. "---
    1969.
\bibitem{Osipov2014e}
    \BibAuthor{Osipov\;G.\,S., Panov\;A.\,I., Chudova\;N.\,V.}
    \BibTitle{Behavior Control as a Function of Consciousness. I. World model and Goal Setting}~//
    \BibJournal{Journal of Computer and Systems Sciences International}, 2014. Vol.\,53, No.\,4.
\bibitem{Rensink2000e}
    \BibAuthor{Rensink\;R.}
    \BibTitle{The dynamic representation of scenes}~//
    \BibJournal{Visual Cognition}, 2000. No.\,7. Pp.\,17--42.
\bibitem{Triesman1980e}
    \BibAuthor{Triesman\;A.\,M., Gelade\;G.}
    \BibTitle{A Feature Integration Theory of Attention}~//
    \BibJournal{Cognitive Psyhology}, 1980. Vol.\,12. Pp.\,97--136.
\bibitem{Velichkovsky2006e}
    \BibAuthor{Velichkovsky\;B.\,M.}
    Cognitive Science: Foundations of Epistemic Psychology. Vol.\,1. "---
    2006.
\bibitem{Zhuravlev1977e}
    \BibAuthor{Zhuravlev\;Yu.\,I.}
    \BibTitle{Correct algebras over sets of incorrect (Heuristic) algorithms. I}~//
    \BibJournal{Cybernetics}, 1977. Vol.\,13, No.\,4. Pp.\,489-497.
\end{thebibliography}

% Решение Программного Комитета:
%\ACCEPTNOTE
%\AMENDNOTE
%\REJECTNOTE
\end{document}
