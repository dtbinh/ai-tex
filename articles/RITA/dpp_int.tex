
%%%%%%%%%%%%%%%%%%%%%%% file typeinst.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is the LaTeX source for the instructions to authors using
% the LaTeX document class 'llncs.cls' for contributions to
% the Lecture Notes in Computer Sciences series.
% http://www.springer.com/lncs       Springer Heidelberg 2006/05/04
%
% It may be used as a template for your own input - copy it
% to a new file with a new name and use it as the basis
% for your article.
%
% NB: the document class 'llncs' has its own and detailed documentation, see
% ftp://ftp.springer.de/data/pubftp/pub/tex/latex/llncs/latex2e/llncsdoc.pdf
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}

\usepackage{url}
\urldef{\mailsa}\path|{pan ,yakovlev}@isa.ru|    
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}

\mainmatter  % start of an individual contribution

% first the title is needed
\title{Behavior and path planning for the coalition of cognitive robots in smart relocation tasks}

% a short form should be given in case it is too long for the running head
\titlerunning{Behavior and path planning for the coalition of cognitive robots}

\author{Aleksandr I. Panov \and Konstantin Yakovlev}
%
\authorrunning{Aleksandr I. Panov \and Konstantin Yakovlev}
% (feature abused for this document to repeat the title also on left hand pages)

% the affiliations are given next; don't give your e-mail address
% unless you accept that it will be published
\institute{Federal Research Center ``Computer Science and Control'' of RAS,\\
pr. 60-letiya Octyabrya 9, 117312 Moscow, Russia\\
%\mailsa\\
%\url{http://www.isa.ru}
}

\toctitle{Behavior and path planning for the coalition of cognitive robots in smart relocation tasks}
\tocauthor{Aleksandr I. Panov, Konstantin Yakovlev}
\maketitle


\begin{abstract}
In this paper we outline the approach of solving special type of navigation tasks for robotic systems, when a coalition of robots (agents) acts in the 2D environment, which can be modified by the actions, and share the same goal location. The latter is originally unreachable for some members of the coalition, but the common task still can be accomplished as the agents can assist each other (e.g. by modifying the environment). We call such tasks smart relocation tasks (as the can not be solved by pure path planning methods) and study spatial and behavior interaction of robots while solving them. We use cognitive approach and introduce semiotic knowledge representation – sign world model which underlines behavioral planning methodology. Planning is viewed as a recursive search process in the hierarchical state-space induced by sings with path planning signs reside on the lowest level. Reaching this level triggers path planning which is accomplished by state of the art grid-based planners focused on producing smooth paths (e.g. LIAN) and thus indirectly guarantying feasibility of that paths against agent's dynamic constraints.
\keywords{behavior planning, task planning, coalition, path planning, sign world model, semiotic model, knowledge representation, LIAN}
\end{abstract}


\section{Introduction}

In pursuit of higher autonomy degree of modern robotics systems researchers combine various methods and algorithms of Artificial Intelligence, Cognitive Science, Control Theory into so-called Intelligent Control Systems (ICS) \cite{Albus2002,Yoo2015}. These systems are the collections of software modules automating robot behavior and are conventionally organized in a hierarchical fashion. Usually three levels of control – strategic, tactical and reactive (or named in another way but still bearing the same sense) – are distinguished \cite{Emelyanov2015}. In this work, we address the planning problem and examine planning methods on both strategic and tactical levels and their interaction. On strategic level, we assume that there exist a description of situations and goals, and the search space induced by such descriptions is processed to produce a valid plan. Typically in AI planning \cite{Ghallab2004} first-order logic is used to model the world as well as specialized first-order logic languages – PDDL and it's derivatives – are used to formalize robot's actions \cite{Ghallab1998,Fox2003}. Planning relying on these models and languages is known as task planning. In our work a new formalism – sign world model – is introduced which is based on cognitive theories, takes into account results of recent cognitive and neurophysiologic research and thus make robot's behavior more human-like, robust and versatile. We refer to planning based on sign world model as to behavior planning. As for the tactical level of control system, it deals mainly with navigation tasks so planning is considered in spatial (geometrical) sense and is aimed at finding a path (feasible trajectory) for the robot. Both planning activities – behavior planning and path planning – despite the common term involved in their names utilize different models and algorithms and commonly are studied independently. In the present work, we study them as a part of coherent framework. One should say, that there exists a limited number of the approaches of task (not – behavior) and path planning integration, see \cite{Karlsson2012,Abdo2012} for example. These approaches mainly examine some aspects of task and path planning integration when there is a single robot interacting with the environment. In our work, we study the behavior of the coalition of robots and how integration of planning activities on both strategic and tactical layer can affect such behavior. We examine navigation tasks in 2D world which can be transformed by the robots' actions. More precisely, we investigate the case when unsolvable for some member of the coalition problem can be solved if other robots alter their plans and assist each other. We call such tasks – smart relocation tasks (as they can not be accomplished by path planning only methods).

The latter of the paper is organized as follows – in Section~\ref{works} related works regarding task and path planning are discussed. Section~\ref{case} contains the description of the smart relocation task we are interested in. Novel world modeling formalism, which utilizes cognitive approach, is introduced in Section~\ref{knowledge} and in Section~\ref{behavior} planning method based on this formalism is described. Suggested path planning approach is discussed in Section~\ref{path}. Model example in studied in Section~\ref{example}.

\section{Related works}\label{works}
\subsection{World modeling and behavior planning}

Behavior (task) planning is the main objective of control systems based on cognitive architectures. Well-known SOAR \cite{Laird2008,Laird2012} system is considered as the industry standard in this area. In SOAR, as well is in majority of other cognitive control systems, agent's memory is separated into the long term memory, the short term memory and the memory of estimates. Objects, situations and goals are represented in the short term memory in the form of attribute descriptions. The long term memory contains transitions (operators) between short term memory states and is represented by AI rules \cite{Nilsson1998}.
 
Agent's planning procedure in SOAR consists of a sequence of decisions, where the aim of each decision is to select and apply an operator in service of the agent's goals. The simple decision circle contains five steps: encode perceptual input, activate rules to elaborate agent's state (propose and evaluate operators) in parallel, select an operator, activate rules in parallel that apply the operator and then process output directives and retrievals from long-term memory.

Similar knowledge representation and planning method are implemented in other cognitive control systems. In the Icarus project \cite{Langley1997,Langley2006} the division of the long term memory into conceptual and action memories was introduced. Planning procedure of Icarus relies on recursive action decomposition up to low level actions, called skills. Skill sequence is executed when start situation is satisfied in short term memory. In Clarion \cite{Sun1994,Sun2006} some rules of action choosing are based on neural networks. Thus knowledge representation in Clarion contains not only explicit (attributive) component but also an implicit one. The learning process on the set of predefined precedents is the distinctive feature of this system.

Modern algorithms of behavior (task) planning use so called STRIPS description of planning domain \cite{Fikes1971}. One of the main directions in task planning is the development of special graph structures encoding both state descriptions and state transitions for further search. The first algorithm using graph representation was Graphplan \cite{Blum1997}. Graphplan search procedure is executed on the special layered compact planning graph and returns a shortest-possible partial-order plan or state that indicates the absence of the valid plan.

Further research in this area was concentrated on development of specialized search algorithms for these graph structures. For example in the Fast Forward (FF) \cite{Hoffmann2001} and the Fast Downward (FD) planning systems \cite{Helmert2006} heuristic search is used. These planners are aimed at solving general deterministic planning problems encoded in the propositional fragment of PDDL description \cite{Fox2003} and search the state space in the forward direction. FF, FD and other widespread PDDL-based planners use the propositional representation with special implicit constraints being considered in some cases. For example, FD planner computes its causal graph  heuristic function taking these implicit constraints into account as well as using hierarchical decompositions of planning tasks.

Another remarkable heuristic planning system is LAMA \cite{Richter2010}. It uses pseudo-heuristic derived from landmarks – propositional formulas that must be true in every solution of a planning task. The LAMA system builds plan using finite domain rather than binary state variables as in the FF planner.

One should note that the propositional language for task description is not relevant to many real problems. Thus extensions of the language and development of hybrid planning domains is appealing research area. For example, UPMorphi universal planner \cite{Della2012} is capable of reasoning with mixed discrete and continuous domains and fully respect  the semantics of PDDL+ \cite{Fox2006}. UPMorhi performs universal planning on some initial discretization and checks the correctness of the result. If the validation fails, discretization is refined and algorithm is reinvoked. 

All of the abovementioned and other existing planners are not suitable for the cooperative behavior (task) planning. Special knowledge representation such as MA-PDDL \cite{Kovacs2012} should be used in this case. These representations and planners based on them should solve symbol grounding problem \cite{Harnad1990} and support goal-setting and role distribution procedures. Such requirements can be met by the sign representation, which is based on the models of cognitive functions \cite{Osipov2014} and neurophysiological studies of the cognition process \cite{Edelman1987,Ivanitsky1997}. We will use this approach to realize communication protocol for cooperative planning and providing a link between the symbolic models and sensor (low level) data.

\subsection{Spatial modeling and path planning}

Traditionally in artificial intelligence and robotics path planning is viewed as a graph search process. Agent's knowledge about the environment is encoded into the graph model and the search for a path on that graph is performed. Typically, graph's vertices correspond to the locations an agent can occupy and edges – to the trajectories it can traverse (for example – straight sections or curves of predefined lengths and curvatures). Weighting function, which assigns weights to the edges, is commonly used to quantitatively express any characteristics of the corresponding trajectories (length, energy cost, risk of traversing etc.). So to plan a path one needs to a) construct a graph model out of the environment description available to an agent b) find a (shortest) path on that graph.

The most widespread graph models used as the spatial world model of an agent are Visibility Graphs \cite{Lozano1979}, Voronoi Diagrams \cite{Bhattacharya2008}, Navigation Meshes \cite{Kallmann2010}, Regular Grids \cite{Yap2002} etc. Each of them needs it's own algorithm to be executed to transform raw information about the environment to the model. In case environment is compound of the free space and the polygonal obstacles (the most widespread case), two graph models are typically used – visibility graphs and regular grids. Constructing visibility graph is computationally burdensome and each time goal position changes additional calculations should be performed to add corresponding edges to VG \cite{Wooden2006}. Algorithm of grid construction is much more simple – it's complexity is a constant in respect of number of obstacles' vertices and edges, and no additional calculations should be made when goal or start position alters. So, grids can be referred to as simple yet informative graph models, and in most cases it is the grids that are used for path planning. Another reason grids are so widespread is that new knowledge on the environment gained via sensor information processing can be easily integrated into them \cite{Elfes1989} without the necessity to re-invoke graph construction algorithm, which significantly saves computational resources.

After the graph is constructed, the search for a path is performed (typically, the shortest path is targeted). There exist a handful of algorithms for that: Dijkstra \cite{Dijkstra1959}, A* \cite{Hart1968} – which is the heuristic modification of Dijkstra, and many of their derivatives: R* \cite{Likhachev2008}, Theta* \cite{Nash2007}, JPS \cite{Harabor2011}, D* Lite \cite{Koenig2000} etc. Some of these algorithms are specifically tailored to grid path planning (like JPS or Theta*) some work on any graphs (D* Lite, R*) with A* and Dijkstra being the most universal ones (and the most computationally ineffective while solving practical tasks as well).

If we are talking not about an abstract agent, which can move in any directions, with any speed and acceleration, and stop instantly, we need to take into account agent dynamic constraints while searching for a path. Common way to consider these constraints is to incorporate them somehow into the graph model or, which is nearly the same, into the search space – see \cite{Kuwata2009} for example. The main problem here is that the search space becomes orders of magnitude times larger, especially when an agent exhibits rather complex dynamics (for example - multirotor UAV).  Another problem here is that admissible, monotone, well-informed heuristics utilized to guide the search can be easily introduced only for the spatial-only search spaces, which is not the case anymore. Summing up the above mentioned one can claim that it may be beneficial to stay within spatial-only search spaces but search for such paths that indirectly guarantee feasibility against the agent's dynamic constraints, e.g. smooth paths not containing sharp turns.  One of the recently introduced approach in this area, is planning for angle-constrained paths \cite{Kim2014}. We believe that this approach is very promising and suggest using LIAN algorithm \cite{Yakovlev2015} for agent's path planning. To the best of our knowledge it's the only angle-constrained path planning algorithm which is sound and complete (in respect to it's input parameters). 

When talking about coalitions of agents and multi-agent grid path planning the most well-studied problem is resolving spatial conflicts for groups of agents with primitive dynamics, e.g. agents that can move from an arbitrary grid cell to any of it's 8 adjacent neighbors and stop (and later on start) moving instantaneously. There exist both sound and complete but very computationally expensive methods of solving this task \cite{Standley2010} and fast but incomplete algorithms \cite{Wang2008,Silver2006}. Much less attention is paid to the problem of agents spatial interaction when planning for a path – a problem which will be addressed in our work in more details.

\subsection{Summary}
Currently existing cognitive control systems and PDDL-based planners don't consider some important features of the planning problem in case coalition of interacting agents is involved. Dynamic formation of goals and goal sharing in the context of changing environment impose special restrictions on the knowledge representation to be used by planning systems. Necessity to divide believes of a single agent into communicable and personal parts presents another restriction. It's also worth noting that within existing task planning frameworks little attention is paid to coordination of path planning process and behavior knowledge about the environment. Regarding path planning itself one can state that grid-based path planning is the most widespread methodology as grids are simple yet informative spatial models and a handful of methods tailored to grid path finding exist. Unfortunately grid-based paths do not take into account agent's dynamic constraints while incorporating dynamic laws encodings into the  search process severely degrades overall performance (due to the enormous extension of the search space). So it can be beneficial to stay within spatial only search spaces but search for a specific, geometrically constrained class of paths and thus indirectly guaranty path's feasibility. Further on we will present a coherent task-path planning framework which addresses all the mentioned concerns and bottlenecks.

\section{Considered case}\label{case}

Further on we will use the term agent as well as robot (robotic system) following the conventions of AI literature.

We consider the following task. The coalition of agents $A=\{A_1,\dots, A_N\}$ acts in the static  environment (workspace) which is the rectangular area of 2D Euclidean space $U: x_{min} \leq x \leq x_{max}, y_{min} \leq y \leq y_{max}$. $U$ is comprised out of the free space $U_{free}$ and the obstacles $U_{obs}=\{obs_1,\dots,obs_M\}$. Each obstacle is a polygon defined by the set of it's vertices' coordinates $obs_i=\{p_{i1}, p_{i2}, \dots, p_{ij}, \dots, p_{iK_i}\}$, $p_{ij}=(x_{ij}, y_{ij})\in U$. Obstacles are additionally characterized by types: $type(obs_i)=ot_j$, $ot_j\in OT$, $OT=\{ot_1, \dots, ot_Z\}$. All agents have similar sizes and can be represented as the circles of radius $r$ in $U$.

We suppose that the agent's movement dynamics is encoded as a set of differential equations:
\begin{equation}
	\frac{dx}{dt} = f(x,u),
\end{equation}
where $f(x,u)$ – vector function, $x\in R^n$ – vector of the phase coordinates, $u\in R^r$ – control vector, $t$ – time. Following \cite{Yakovlev2015a} we assume that given dynamic constraints can be transformed to geometry constraints, e.~g. we assume that a feasible trajectory for an agent is the angle-constrained path in $U$ which is a sequence of line segments such that the angle of alteration between two consecutive segments doesn't exceed predefined threshold $\alpha_m$.

Agent's knowledge base contains high-level representations of locations and distances as well as the mechanisms of mapping these representations to the workspace. Set of agent's actions is organized in hierarchical structure and three types of actions exist: transition actions, transforming actions and messaging actions. Each action is parameterized and for the same action different parameters can be used. For example, transforming action a of the agent $A_1$ destroys obstacles of $ot_1$ and $ot_2$ types while the same action of the agent $A_2$ (parameterized in another way) destroys obstacles of $ot_2$ type only. We consider the case when each agent has its own planning focus containing current believes about external objects and processes. Details of the knowledge representation will be described further in Section \ref{knowledge}.

Single agent's task is reaching the predefined goal area which is the same for all other agents. This common task description for an agent includes explicit constraint that all the agents should reach the goal area (not the only one). We investigate scenarios (as depicted on Fig.~\ref{fig:case}) when some agents can not reach the goal area separately, without the assistance from the other members of the coalition. As seen on Fig.~\ref{fig:case} agent $A_1$ can not reach the goal as it's blocked by the obstacle $obs_1$ can not be destroyed by $A_1$, while $A_2$ can alter it's plan, $obs_1$ first and destroy this obstacle assisting $A_1$ in accomplishing the task). We call such tasks – smart relocation tasks.

\begin{figure}
	\centering
	\includegraphics[height=6cm]{rita_example}
	\caption{Considered case of the coalition relocation task where $A_1, A_2$ - members of the coalition, $G$ - the goal area, $obs_1,obs_2$ - obstacles of the destroyable type (crosshatched blocks).}
	\label{fig:case}
\end{figure}

\section{Knowledge representation}\label{knowledge}

Agent's knowledge base contains descriptions of objects, processes and properties of the external environment and information about other members of the coalition. To formalize the knowledge base we use the semiotic approach where-in all above entities are mediated by sings.  Each sign is composed of a name and three components – image, significance, personal meaning – which are used to implement different functional steps of the planning process. Signs come with the special structured set of links to other sings and to data from inner and external sensors of the agent. We will name these links as features (see Fig.~\ref{fig:sign}).

\begin{figure}
	\centering
	\includegraphics[height=8cm]{sign_kr}
	\caption{Structure of the sign knowledge representation.}
	\label{fig:sign}
\end{figure}

The first component of a sign is image. Image is the set of sets of features specific to the mediated entity. At the same time image also implements the process of recognizing the entity based on the input data. Each set of features encapsulated in image contains those features that are grouped together in the input data stream. Considering that features are links to other signs, the hierarchy of signs is formed on the set of images. Lowest level of the hierarchy consists of input data from sensors or information received from path planning operators.

The second component of a sign is significance. Significance is the set of procedural features (or causal relations) and it is used to describe characteristic actions in which mediated entity is engaged. A causal relation consists of the set of conditional features or conditions (encountered before the execution of the action) and the set of resultant features or effects (encountered after the execution of the action). Thus procedural features are the models of AI rules \cite{Nilsson1998}. Additionally, at least one feature (condition or effect) is a link to the sign possessing the significance itself. Considering that features are links to other signs, another hierarchy of signs is formed on the set of significances of mediated actions. Lowest level of the hierarchy contains elementary skills . Significance components of common signs are the same for all agents in the coalition.

Finally the third component of a sign is personal meaning and it also (like significance) describes actions involving the mediated entity. There exist a link between a causal relation of the personal meaning and a causal relation of the significance defined by the function $\Xi$. Unlike significance, personal meaning contains special type of features – personal features – in it's causal relations. These features mediate inner properties of the agent and replace elementary skills of the corresponding significance. Personal meaning implements the process of applying agent's actions. Lowest level of the personal meanings hierarchy is comprised by path planning operators. 

The structure of the sign corresponds to psychological models of high cognitive functions \cite{Vygotsky1986,Leontyev2009} and allows to separate generalized representation of actions that are known to all members of the coalition and specific implementation of such actions, which takes into account inner properties of the agent.

The hierarchy of signs (based on images, significances and personal meanings) serves as a tool for the input signal (low level features) recognition and for the corresponding sign actualization. An algorithm of sign recognition is simple comparison of input features with corresponding set of features predicted by upper level signal on each level of the hierarchy \cite{Osipov2014}. In this way the recognition process is bottom-up spreading of the activation in the hierarchy of features right down to levels where there is correspondence between features and signs. This algorithm models functioning of the human cortex sensor regions \cite{Mountcastle1998,George2009}.The set of activated (actualized) signs at the moment represents the agent's believe about the current environment state. Since the hierarchy of signs encodes the set of agent's actions via the procedural features all transitions between states during behavior planning are executed as top-down or bottom-up activation processes in the hierarchy. Low level procedural features include path planning operators and reaching this level while the activation (planning) process triggers path planning procedures.

\section{Behavior planning algorithm}\label{behavior}

On sign level behavior planning is realized in the situation space by $PMA$ algorithm proposed in \cite{Osipov2015}. The situation is defined as the set of signs. Use of sign representation allows to combine believes about relationships and believes about objects and consider all properties, processes and objects in a situation as signs. Transitions between situations are implement-ed by casual relations contained in procedural features of significances or personal meanings in dependence the planning step. The initial situation is defined as the current observed situation, i.e. the current set of actualized signs. The goal situation is agent's believe about the result of the solving current problem, i.e. it is the set of goal signs.

In the case of the transfer planning task low level features are implemented by path planning algorithms and considered as personal features included in agent's procedural features. Thus the hierarchy of procedural features in fact is the action hierarchy and low level actions are performed and simulated by the subsystem of realization and prediction of particular operation beyond sign representation.

The algorithm of behavior planning is iterative process that consists of the main procedure named $PMA$-procedure realized following functions:
\begin{itemize}
	\item the function of search of appropriate significances (the $M$-step), 
	\item the function of choosing personal meanings corresponding to the significances retrieved (the $A$-step), 
	\item the function of message sending to other members of the coalition (part of the $S$-step),
	\item the function of testing the action corresponding to the personal meaning constructed (part of the $S$-step),
	\item the function of the inflation of the image corresponding to the personal action and the construction of the new current situation (the $P$-step).
\end{itemize}
Below we describe these functions in details.

Input of the $PMA$-procedure is the pair of tow situations: start and final situations. On the first iteration of the algorithm the start situation is the current situation observed by the agent and the final situation is the goal situation implemented task solving conditions. For all signs included in the final situation such procedural features are selected which contains in their effects maximum features corresponding to final situation signs. This step of algorithm is named as the $M$-step. The procedure $\Xi$ associates the set $a*$ of procedural features relevant to personal meanings with obtained set of procedural features ($A$-step). The population of all features of personal action conditions define the new planning situation. Then transition to $P$-step occurs. This step of the algorithm is combining of all features included in conditions of personal meaning features. After P-step the new iteration of $PMA$-procedure is executed with the same start situation and the new formed final situation. If new situation is the subset of start situation (the first argument of $PMA$-procedure) then in some cases $S$-step occurs depending on cognitive qualities (parameters of planning process) of the agent. $S$-step is the simulation of personal meaning execution, i.e. the prediction of the goal situation as a result of the action (rule) application. This simulation activates all procedural features with which features of personal meanings are recognized. In a result activation process reaches the level where operations of path planning process included in personal features are placed. After path planning operations execution if some new features are appear in current observed situation the $PMA$-procedure are re-executed from the first step (see Fig. \ref{fig:bplan}).

\begin{figure}
	\centering
	\includegraphics[height=6.5cm]{beh_plan}
	\caption{Schema of behavior planning $PMA$-procedure}
	\label{fig:bplan}
\end{figure}

All changes arising in the current observed situation (for example, emerging unaccounted obstacle detected by path planning process or the new task received from other member of the coalition) triggers the re-execution of $PMA$-procedure with new start or final situations.

With new sign representation of agent's knowledge about environment and its own qualities we can describe and implement meta-cognitive regulation functions of the agent behavior. These functions are realized by rule (mental action) application mediated by personal meanings and significances during the selection of $PMA$-procedure parameters. This regulation process executes some rules that change personal features of the agent implemented parameters of planning and recognition processes.

All members of the coalition have signs that mediate both objects of external environment and other members of the coalition. The significances of these signs include agent's knowledge about actions available for corresponding agents. The personal meanings of these signs include actions by sending them a communication messages.
The constructed plan of behavior can contain personal meanings of signs corresponding to other members of the coalition. In this case a message with description of the significance obtained by the inverse procedure $\Xi$ is sent to the corresponding member. This message plays the role of the new task for this agent and triggers its $PMA$-procedure re-execution. Thus the common plan of the task resolving includes all sub-plans and all goal-setting messages of all members of the coalition.

\section{Path planning algorithm}\label{path}

We suggest using grids as spatial representations for path planning as they are both informative and easy-to-search graph models of the agents' environment (as described in Section \ref{case}). Grid is constructed by overlaying regular square mesh over the workspace $U$ in such way that each grid element $c$, e.g. a cell, corresponds to a unique square area in $U$ sized $res \times res$, where $res$ – is an input parameter. If this area overlaps with any obstacle, cell с is marked untraversable (traversable – otherwise). We adopt center-based grid notation (in opposition to corner-based) meaning that a path should start (and end) at the center of some grid cell $c(x, y)$ (and thus it's supposed that any agent is tied to the center of some grid cell initially). We also adopt the idea of any-angle path finding \cite{Nash2007} and consider the path as the sequence of traversable but not obligatory adjacent cells $\pi=\{c_1, c_2, \dots, c_p\}$, such that an agent can move from one cell to next one in the sequence following the straight line connecting the centers of those cells. Function $los(c_i, c_j)\rightarrow\{true, false\}$ is given to check this condition. If the size of the cell is big enough to accommodate an agent (e.g. $res\geq 2r$) one can use well-known (and fast) Bresenham algorithm \cite{Bresenham1965} to check line-of-sight constraint. This algorithm identifies grid cells forming discrete representation of straight line, so after that, one needs to check if they all are traversable. Occasionally it can happen so that Bresenham algorithm identifies cells, that are all traversable, although actual straight line intersect an untraversable cell (and thus, possibly, an obstacle). To avoid this we suggest double-outlining the obstacles in the following way: after the grid is constructed mark all the adjacent cells for each untraversable and then put all the marked cells untraversable – see Fig.~\ref{fig:grid}.

\begin{figure}
	\centering
	\includegraphics[height=6cm]{path_grid}
	\caption{Grid representation of the workspace. a) Initial workspace. b) Square pattern used for discretization. c) Path on a grid colliding with the untraversable regions. d) Double-outlining of the obstacles and creating additional untraversable cells prevent from generating paths colliding with true obstacles.}
	\label{fig:grid}
\end{figure}

We use two algorithms for path finding: Basic Theta* \cite{Nash2007} and LIAN \cite{Yakovlev2015}. First algorithm searches for any angled path on given grid, second  searches for angle-constrained path, e.g. for such a path $\pi=\{c_1, c_2, \dots, c_p\}$ that an angle of alteration between any consecutive sections $\langle c_{i-1}, c_i\rangle, \langle c_i, c_{i+1}\rangle$ is less than the predefined threshold $\alpha_m$ (see Fig.~\ref{fig:lian}). Searching for the angle-constrained path is much more burdensome but such a path indirectly guarantees it's feasibility, e.~g. agent's ability to follow the trajectory in U defined by that path without violating the dynamic constraints (as described in Section~\ref{works}). 

\begin{figure}
	\centering
	\includegraphics[height=3.5cm]{path_lian}
	\caption{LIAN algorithm details.}
	\label{fig:lian}
\end{figure}

So we search for any angle path first and if it is found start searching for the angle-constrained path. If it is found, we report success to the upper level, e.g. behavior planning module and wait for the next goal to be given. Failure to find a path means that angle constraint is too strict (in respect to the current environment model, e.g. grid, and start-goal locations) so the new sub-goal is to be given by the behavior planning module or the new angle constraint.

An interesting case occurs when any angle path planning returns failure, which means that there is no path to given goal location not due to the angle constraints, but due to the obstacles configuration, e.g. namely some obstacle is blocking the path (otherwise it would have been found as Theta* is sound and complete). In this case it is useless to ask for a new subgoal as a resultant path won't be found anyway. An obstacle blocking the path should be identified and its coordinates should be transmitted to the behavior planning module. To the best of authors' knowledge currently there are now works on the methods of identifying blocking obstacles, so this is an appealing research area to be investigated further.

Previously, when describing the path planning process we supposed that the goal cell is given, although, in the case sign-world model is used for behavior planning, the fuzzy goal area is under concern. This area is characterized by the point $cp(x, y)$ and radius $r_g$ – if the agent reaches any point of the circle with radius $r_g$ and center in $cp(x, y)$ path planning is considered to be successfully accomplished. This can be taken into account in the following way – execution of the LIAN algorithm should be stopped when any cell of the circle is under consideration. We also perform the consistency of the goal area check before path planning in the following manner: if given center point belongs to the grid's untraversable cell – choose one of it's traversable adjacent cells as $cp$. If all the neighbors are untraversable – examine their neighbors and so on up to the moment traversable cell of the goal area will be identified. If all cells forming the goal area are untraversable – report  behavior planner and wait for the new goal area. 

\section{Example of integrated planning algorithm application}\label{example}

Below we demonstrate implementation of the planning method in solving the smart relocation task as described in Section~\ref{case}. We consider a simple case when two agents $A_1$ and $A_2$ form the coalition and share common goal area. Fragment of the agents knowledge base (sign model) is depicted in Tab.~\ref{tab:world}.

\setlength{\tabcolsep}{5pt}
\renewcommand{\arraystretch}{1.5}
\begin{table}\tiny
	\caption{The fragment of the sign world model of agents.}	
	\label{tab:world}
	\begin{tabular}{| p{1.5cm} | p{2.2cm} | p{2.2cm} | p{2.2cm} | p{2.2cm} |}
		\hline
		Specific signs of the $A_1$ agent
		&
		$s_1$: $n$=``obstacle 1''\newline
		$p$=\{``place $X_4$'', ``type 1''\}\newline
		$m$=\{``destroying 1''\}\newline
		$a$=\{``I destroying 1''\}
		&
		$s_2$: $n$=``obstacle 2''\newline
		$p$=\{``place X2'', ``type 2''\}\newline
		$m$=\{``destroying 2''\}\newline
		$a$=$\emptyset$
		&
		$s_3$: $n$=``far''\newline
		$p$=\{mechanical sensor parameters\}\newline
		$m$=\{``move 1'', ``move 2''\}\newline
		$a$=\{``I move 1'', ``I move 2''\}
		&
		$s_4$: $n$=``agent 2''\newline
		$p$=\{mass, coordinates etc.\}\newline
		$m$=\{``send message''\}\newline
		$a$=\{``I send message''\}
		\\\cline{2-5}
		&
		$s_5$: n=``I move 1''\newline
		$p$=\{``I move 3'', ``I move 3'', ``place X''\}\newline
		$m$=$\emptyset$\newline
		$a$=$\emptyset$	
		&
		$s_6$: $n$=``I move 3''\newline
		$p$=\{``I'', ``here'' $\rightarrow$ ``empty'', ``place $X_3$''\}\newline
		$m$=\{``move 3''\}\newline
		$a$=\{path planning realization\}
		&
		$s_7$: $n$=``I – agent 1''\newline
		$p$=\{mass, coordinates etc.\}\newline
		$m$=$\emptyset$\newline
		$a$=$\emptyset$	
		&
		$s_{10}$: $n$=``place X3''\newline
		$p$=\{``close'', ``ahead'', ``right''\}\newline
		$m$=$\emptyset$\newline
		$a$=$\emptyset$
		\\ \hline
		Specific signs of the $A_2$ agent
		&
		$s_1$: $n$=``obstacle 1''\newline
		$p$=\{``place $Y_2$'', ``type 1''\}\newline
		$m$=\{``destroying 1''\}\newline
		$a$=$\emptyset$
		&
		$s_2$: $n$=``obstacle 2''\newline
		$p$=\{``place Y3'', ``type 2''\}\newline
		$m$=\{``destroying 2''\}\newline
		$a$=\{``I destroying 2''\}
		&
		$s_3$: $n$=``far''\newline
		$p$=\{mechanical sensor parameters\}\newline
		$m$=\{``move 1'',``move 2''\}\newline
		$a$=\{``I move 1''\}	
		&
		$s_8$: $n$=``agent 1''\newline
		$p$=\{mass, coordinates etc.\}\newline
		$m$=\{``send message''\}\newline
		$a$=\{``I send message''\}
		\\\cline{2-5}
		&
		$s_5$: $n$=``move 1''\newline
		$p$=\{``I'', ``here'' $\rightarrow$ ``empty'', ``place $Y_1$''\}\newline
		$m$=\{``move 1''\}\newline
		$a$=\{path planning realization\}	
		&
		$s_9$: $n$=``I – agent 2''\newline
		$p$=\{mass, coordinates etc.\}\newline
		$m$=$\emptyset$\newline
		$a$=$\emptyset$
		&
		$s_{10}$: $n$=``place $Y_1$''\newline
		$p$=\{``far'', ``ahead''\}\newline
		$m$=$\emptyset$\newline
		$a$=$\emptyset$	
		&
		\\\hline
	\end{tabular}
\end{table}

We consider the planning process of the agent $A_1$. In a result of task formulation agents confront goal area G with its own sign (named ``place $X_1$'' for $A_1$). $PMA$-procedure executes its first iteration with the start situation containing current observable sings and with the final situation containing goal signs (for $A_1$ they are ``I'', ``agent 2'', ``place $X_1$''). The fist $M$-step is to search maximal effect-covered procedural feature from the set of available significances. From the Tab.~\ref{tab:world} we can find that it is significance $m$=``move 1'' (transition ahead and right). Then the $A$-step is executed and in our case the procedure $\Xi$ gives the personal meaning that includes feature corresponding ``I move 1'' (see Fig.~\ref{fig:example}).

If the agent $A_1$ have low introspection level of planning process then obtained personal meaning activates on the $S$-step path planning operations. In example map this operations cannot be accomplished and coordinates of main $obs_1$ obstacle will be returned. For this obstacle agent $A_2$ has special procedural feature that can actualize (activate) the sign ($n$=``$obs_1$'') corresponding this external object. New activated sign of the detected obstacle will be added into final situation as deleted feature and the $PMA$-procedure will be re-executed. In the new $M$-step we will obtain also procedural feature $m$=``destroying 2'' that will satisfy new sub-goal and remove the obstacle.

\begin{figure}
	\centering
	\includegraphics[height=6cm]{rita_ex_proc}
	\caption{Representations of space in sign level. $X_i$ - names of places associated with signs for the agent $A_1$, $Y_1$ - a name of the place associated with the sign for the agent $A_2$.}
	\label{fig:example}
\end{figure}

Agent $A_1$ after his $S$-step and re-executing $PMA$-procedure cannot find suitable action because in his set of personal meaning there is no destroying action. In this case it will active communication action and sends message to the agent $A_2$ with coordinates of $obs_1$ obstacle and result of destroying of this obstacles (presence the agent $A_1$ in the goal area). In the goal situation of the $A_2$ the presence of the agent $A_1$ in the goal area is required and it will use this task as its own sub-goal.

\section{Conclusion}

In this paper we have presented an approach to build a two-layered planner for the robotic system which is a part of a coalition solving common task. We suggest following semiotic approach to develop cognitive top-level planner in order to make the system more versatile, robust and human-like (in contrary to the existing logic based approaches – PDDL languages etc.). We have introduced new knowledge representation formalism – sign world model – which aligns well with the results of recent cognitive and neurophysiologic research. Path planning operators are the integral part of this hierarchical model so task and path planning processes are tied together as a parts of coherent framework. Behavior planning is a recursive search process in the hierarchical state-space induced by sign representation ending up with path planner triggering: when behavior planning reaches the lowest level of sign world model state-of-the-art grid-based planners are executed. We suggest focusing on searching for the special type of smooth paths – angle-constrained paths – in order to indirectly satisfy agent's dynamic constraints and produce feasibly trajectories. We also discuss involving sound and complete any angle path planner in the loop in order to be able to better distinguish between different failure outcomes of the path planning process.

We believe that proposed approach leads not only to extensive flexibility of the planning system which is now capable of solving collaborative navigation tasks which are not solvable by the individual members implementing traditional path planning algorithms, but also will significantly aid solving various human-robot interaction problems. One of worth mentioning tasks which can be positively impacted is natural language formulation of collaborative task to the group (coalition) of robots. Regarding path planning, the task of the blocking areas identification (in case of planner failure) is an appealing direction of further research.


\subsubsection*{Acknowledgments.} The reported study was supported by RFBR, research projects No. 14-07-31194 and No. 15-37-20893.

\begin{thebibliography}{4}

\bibitem{Albus2002} Albus, James S. 4D/RCS: a reference model architecture for intelligent unmanned ground vehicles. AeroSense 2002. International Society for Optics and Photonics, 2002.
\bibitem{Yoo2015} Yoo J.-K., Kim J.-H. (2015) Gaze Control-based Navigation Architecture with a Situation-specific Preference Approach for Humanoid Robots. IEEE Transactions on Mechatronics.
\bibitem{Emelyanov2015} Emel’yanov S. and etc. (2015) Multilayer cognitive architecture for UAV control. Cognitive System Research, 34.
\bibitem{Ghallab2004} Ghallab, M., Nau, D., Traverso, P. (2004). Automated planning: theory and practice. Elsevier.
\bibitem{Ghallab1998} Ghallab, Malik, et al. "PDDL-the planning domain definition language." (1998).
\bibitem{Fox2003} Fox, M., Long, D. (2003). PDDL2. 1: An Extension to PDDL for Expressing Temporal Planning Domains. J. Artif. Intell. Res.(JAIR), 20, 61-124.
\bibitem{Karlsson2012} Karlsson L. and etc. (2012) Combining Task and Path Planning for a Humanoid Two-arm Robotic System. TAMPRA'12: Proceedings of the 2012 ICAPS Workshop on Combining Task and Motion Planning for Real-World Applications, 13-20.
\bibitem{Abdo2012} Abdo N., Kretzschmar H. and Stachniss C. From Low-Level Trajectory Demonstrations to Symbolic Actions for Planning. TAMPRA'12: Proceedings of the 2012 ICAPS Workshop on Combining Task and Motion Planning for Real-World Applications, 29-36.

\bibitem{Laird2008} Laird J. Extending the Soar cognitive architecture // Proceedings of the First AGI Conference. 2008. Pp. 224...235.
\bibitem{Laird2012} J.E. Laird The Soar Cognitive Architecture MIT Press, Cambridge (2012).
\bibitem{Nilsson1998} Nilsson, N. J. (1998). Artificial Intelligence: A New Synthesis. San Francisco: Morgan Kaufmann.
\bibitem{Langley1997} Langley P. Learning to sense selectively in physical domains // Proceedings of the First International Conference on Autonomous Agents (Marina del Rey, USA). 1997. Pp. 217...226.
\bibitem{Langley2006} Langley P. Cognitive architectures and general intelligent systems // AI Mag. 2006. Vol. 27. Pp.  33...44.
\bibitem{Sun1994} Sun R., Bookman L. Computational Architectures Integrating Neural and Symbolic Processes. Boston: Kluwer Academic Publishers, 1994. 496 p.
\bibitem{Sun2006} Sun R. The CLARION cognitive architecture: Extending cognitive modeling to social simulation. New York: Cambridge University Press, 2006. 434 p.
\bibitem{Fikes1971} Fikes, R. E., Nilsson, N. J. (1971). STRIPS: A new approach to the application of theorem proving to problem solving. Artificial Intelligence, 2(3-4), 189–208. http://doi.org/10.1016/0004-3702(71)90010-5.
\bibitem{Blum1997} Blum, A. L., Frust, M. L. (1997). Fast planning through planning graph analysis. Artificial Intelligence, 90(1-2), 281–300. doi:10.1016/S0004-3702(96)00047-1.
\bibitem{Hoffmann2001} Hoffmann, J., Nebel, B. (2001). The FF Planning System: Fast Plan Generation Through Heuristic Search. Journal of Artificial Intelligence Research, 14, 253–302.
\bibitem{Helmert2006} Helmert, M. (2006). The fast downward planning system. Journal of Artificial Intelligence Research, 26, 191–246. doi:10.1613/jair.1705.
\bibitem{Richter2010} Richter, S., Westphal, M. (2010). The LAMA planner: Guiding cost-based anytime planning with landmarks. Journal of Artificial Intelligence Research, 39, 127–177. doi:10.1613/jair.2972.
\bibitem{Della2012} Della Penna, G., Magazzeni, D., Mercorio, F. (2012). A universal planning system for hybrid domains. Applied Intelligence, 36(4), 932–959. doi:10.1007/s10489-011-0306-z.
\bibitem{Fox2006} Fox M, Long D (2006) Modelling mixed discrete-continuous domains for planning. J Artif Intell Res 27:235–297.
\bibitem{Kovacs2012} D. L. Kovacs: A Multi-Agent Extension of PDDL3.1, Proceedings of the 3rd Workshop on the International Planning Competition (IPC), ICAPS-2012, Atibaia, Brazil, 25-29 June 2012, pp. 19-27.
\bibitem{Harnad1990} Harnad, S. (1990). Symbol Grounding Problem. Physica, 42, 335–346. doi:10.4249/scholarpedia.2373.
\bibitem{Osipov2014} Osipov, G. S., Panov, A. I., Chudova, N. V. (2014). Behavior control as a function of consciousness. I. World model and goal setting. Journal of Computer and Systems Sciences International, 53(4), 517–529. doi:10.1134/S1064230714040121.
\bibitem{Ivanitsky1997} Ivanitsky, A. M. (1997). Information synthesis in key parts of the cerebral cortex as the basis of subjective experience. Neuroscience and Behavioral Physiology, 27(4), 414–426.
\bibitem{Edelman1987} Edelman, G. M. (1987). Neural Darwin-ism: The Theory Of Neuronal Group Selection. New York: Basic Books.

\bibitem{Lozano1979} Lozano-Pérez, T., Wesley, M.A.: An algorithm for planning collision-free paths among polyhedral obstacles. Communications of the ACM 22(10), 560–570 (1979).
\bibitem{Bhattacharya2008} Bhattacharya, P., Gavrilova, M. L. 2008. Roadmap-based path planning-Using the Voronoi diagram for a clearance-based shortest path. Robotics and Automa-tion Magazine, IEEE, 15(2), 58-66. 
\bibitem{Kallmann2010} Kallmann, M.: Navigation queries from triangular meshes. In: Boulic, R., Chrysanthou, Y., Komura, T. (eds.) MIG 2010. LNCS, vol. 6459, pp. 230–241. Springer, Heidelberg (2010).
\bibitem{Yap2002} Yap, P.: Grid-Based Path-Finding. In: Co-hen, R., Spencer, B. (eds.) Canadian AI 2002. LNCS (LNAI), vol. 2338, pp. 44–55. Springer, Heidelberg (2002).
\bibitem{Wooden2006} D.T. Wooden. Graph-based Path Planning for Mobile Robots, PhD thesis, Georgia Institute of Technology, 2006.
\bibitem{Elfes1989} Elfes, A.: Using occupancy grids for mobile robot perception and navigation. Computer 22(6), 46–57 (1989).
\bibitem{Dijkstra1959} Dijkstra, E. W. 1959. A note on two problems in connexion with graphs. Numerische mathematik, 1(1), 269-271.
\bibitem{Hart1968} Hart, P. E., Nilsson, N. J., Raphael, B. 1968. A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, 4(2), 100-107.
\bibitem{Likhachev2008} Likhachev, M., Stentz, A.: R* Search. In: Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence. AAAI Press, Menlo Park (2008).
\bibitem{Nash2007} Nash, A., Daniel, K., Koenig, S., Felner, A. 2007. Theta*: Any-Angle Path Planning on Grids. In Proceedings of the National Conference on Artificial Intelligence (Vol. 22, No. 2, p. 1177). Menlo Park, Calif.: AAAI Press.
\bibitem{Harabor2011} Harabor, D., and Grastien, A. 2011. Online graph pruning for pathfinding on grid maps. In AAAI-11.
\bibitem{Koenig2000} Koenig, S., Likhachev, M. 2000. D*Lite. In Proceedings of the National Conference on Artificial Intelligence AAAI.
\bibitem{Kuwata2009} Kuwata, Y., Karaman, S., Teo, J., Frazzoli, E., How, J. P., Fiore, G. 2009. Real-time motion planning with applications to autonomous urban driving. Control Systems Technology, IEEE Transactions on, 17(5), 1105-1118.
\bibitem{Kim2014} Kim, H., Kim, D., Shin, J. U., Kim, H., Myung, H. 2014. Angular rate-constrained path planning algorithm for unmanned surface vehicles. Ocean Engineering, 84, 37-44.
\bibitem{Yakovlev2015} Yakovlev, K., Baskin, E., Hramoin I. Grid-based angle-constrained path planning. In proceeding of the 38th German conference on Artificial Intelligence (KI-2015). 2015.
\bibitem{Standley2010} Standley, T. Finding optimal solutions to cooperative pathfinding problems. In AAAI, pages 173–178, 2010.
\bibitem{Wang2008} Wang, K.-H. C., Botea, A. (2008). Fast and Memory-Efficient Multi-Agent Pathfinding. In Proceedings of the International Conference on Automated Planning and Scheduling (ICAPS), pp. 380–387.
\bibitem{Silver2006} Silver, D. (2006). Cooperative pathfinding. AI Programming Wisdom, 3, 99–111.

\bibitem{Yakovlev2015a} Yakovlev K., Makarov D., Baskin E. UAV path planning technique under flight dynamics constraints // Scientific and Technical Information Processing, 5, 2015.
\bibitem{Leontyev2009} Leontyev, A. N. (2009). The Development of Mind. Kettering: Erythros Press and Media.
\bibitem{Vygotsky1986} Vygotsky, L. S. (1986). Thought and Language. MIT Press
\bibitem{Mountcastle1998} Mountcastle, V. B. (1998). Perceptual Neuroscience. The Cerebral Cortex. Cam-bridge: Harvard University Press.
\bibitem{George2009} George D., Hawkins J. Towards a Mathematical Theory of Cortical Microcircuits // PLoS Computational Biology. 2009. V. 5. № 10. P. 1–26.

\bibitem{Osipov2015} Osipov, G. S., Panov, A. I., Chudova, N. V. (2015). Behavior control as a function of consciousness. II. Synthesis of a Behavior Plan. Journal of Computer and Systems Sciences International, 54(5).

\bibitem{Bresenham1965} Bresenham, J. E. 1965. Algorithm for computer control of a digital plotter. IBM Systems journal, 4(1), 25-30.

\end{thebibliography}

\end{document}
