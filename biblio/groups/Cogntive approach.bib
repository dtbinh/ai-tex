Automatically generated by Mendeley Desktop 1.16.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Osipov2016,
author = {Осипов, Г. С.},
booktitle = {Гибридные и синергетические интеллектуальные системы: Материалы III Всероссийской Поспеловской конференции с международным участием},
editor = {Колесников, А. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Гибридные и синергетические интеллектуальные системы Материалы III Всероссийской Поспеловской конференции с международным участием/2016/Осипов - 2016.pdf:pdf},
keywords = {15-07-06214,osipov},
language = {russian},
mendeley-tags = {15-07-06214,osipov},
pages = {56--69},
publisher = {Издательство БФУ им. Иммануила Канта},
title = {{Знаковые модели как альтернатива символьным}},
year = {2016}
}
@article{Rolls2013,
abstract = {The mechanisms for pattern completion and pattern separation are described in the context of a theory of hippocampal function in which the hippocampal CA3 system operates as a single attractor or autoassociation network to enable rapid, one-trial, associations between any spatial location (place in rodents, or spatial view in primates) and an object or reward, and to provide for completion of the whole memory during recall from any part. The factors important in the pattern completion in CA3 together with a large number of independent memories stored in CA3 include a sparse distributed representation which is enhanced by the graded firing rates of CA3 neurons, representations that are independent due to the randomizing effect of the mossy fibers, heterosynaptic long-term depression as well as long-term potentiation in the recurrent collateral synapses, and diluted connectivity to minimize the number of multiple synapses between any pair of CA3 neurons which otherwise distort the basins of attraction. Recall of information from CA3 is implemented by the entorhinal cortex perforant path synapses to CA3 cells, which in acting as a pattern associator allow some pattern generalization. Pattern separation is performed in the dentate granule cells using competitive learning to convert grid-like entorhinal cortex firing to place-like fields. Pattern separation in CA3, which is important for completion of any one of the stored patterns from a fragment, is provided for by the randomizing effect of the mossy fiber synapses to which neurogenesis may contribute, by the large number of dentate granule cells each with a sparse representation, and by the sparse independent representations in CA3. Recall to the neocortex is achieved by a reverse hierarchical series of pattern association networks implemented by the hippocampo-cortical backprojections, each one of which performs some pattern generalization, to retrieve a complete pattern of cortical firing in higher-order cortical areas.},
author = {Rolls, Edmund T.},
doi = {10.3389/fnsys.2013.00074},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in systems neuroscience/2013/Rolls - 2013.pdf:pdf},
isbn = {1662-5137 (Print)$\backslash$r1662-5137 (Linking)},
issn = {1662-5137},
journal = {Frontiers in systems neuroscience},
keywords = {association network,attractor network,competitive network,episodic memory,hippocampus,hippocampus, pattern separation, pattern completio,pattern,pattern completio,pattern completion,pattern separation,recall},
number = {October},
pages = {74},
pmid = {24198767},
title = {{The mechanisms for pattern completion and pattern separation in the hippocampus}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3812781{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2013}
}
@article{Taatgen2005,
abstract = {Emerging parallel processing and increased flexibility during the acquisition of cognitive skills form a combination that is hard to reconcile with rule-based models that often produce brittle behavior. Rule-based models can exhibit these properties by adhering to 2 principles: that the model gradually learns task-specific rules from instructions and experience, and that bottom-up processing is used whenever possible. In a model of learning perfect time-sharing in dual tasks (Schumacher et al., 2001), speedup learning and bottom-up activation of instructions can explain parallel behavior. In a model of a complex dynamic task (Carnegie Mellon University Aegis Simulation Program [CMU-ASP], Anderson et al., 2004), parallel behavior is explained by the transition from serially organized instructions to rules that are activated by both top-down (goal-driven) and bottom-up (perceptually driven) factors. Parallelism lets the model opportunistically reorder instructions, leading to the gradual emergence of new task strategies.},
author = {Taatgen, Niels},
doi = {10.1207/s15516709cog0000_23},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive science/2005/Taatgen - 2005.pdf:pdf},
isbn = {0364-0213},
issn = {0364-0213},
journal = {Cognitive science},
keywords = {cog{\_}arch,cognitive architecture,complex systems,computer,dual tasking,human,instruction,interaction,knowledge,learning,psychology,representation,situated cognition,skill acquisition and learning,symbolic computational modeling},
mendeley-tags = {cog{\_}arch},
number = {3},
pages = {421--455},
pmid = {21702780},
title = {{Modeling parallelization and flexibility improvements in skill acquisition: from dual tasks to complex dynamic skills}},
volume = {29},
year = {2005}
}
@incollection{Palomino2016,
abstract = {This paper presents a novel attention-based cognitive architecture for a social robot. This architecture aims to join perception and reasoning considering a double interplay: the current task biases the perceptual process whereas perceived items determine the behaviours to be accomplished, considering the present context and role of the agent. Therefore, the proposed architecture represents a bidirectional solution to the perception-reasoning-action loop closing problem. The proposal is divided into two levels of performance, employing anObject-BasedVisual Attention model as perception system and a general purpose Planning Framework at the top deliberative level. The architecture has been tested using a real and unrestricted environment that involves a real robot, time-varying tasks and daily life situations.},
author = {Palomino, Antonio Jes{\'{u}}s and Marfil, Rebeca and Bandera, Juan Pedro and Bandera, Antonio},
booktitle = {Robot 2015: Second Iberian Robotics Conference},
doi = {10.1007/978-3-319-27149-1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Robot 2015 Second Iberian Robotics Conference/2016/Palomino et al. - 2016.pdf:pdf},
isbn = {978-3-319-27148-4},
keywords = {attention,attention model,bidirectional,cog{\_}arch,cognitive architecture,social robot},
mendeley-tags = {attention,cog{\_}arch},
pages = {721--732},
series = {Advances in Intelligent Systems and Computing},
title = {{A New Cognitive Architecture for Bidirectional Loop Closing}},
url = {http://link.springer.com/10.1007/978-3-319-27149-1},
year = {2016}
}
@article{Rensink2000,
author = {Rensink, Ronald A.},
doi = {10.1080/135062800394667},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Visual Cognition/2000/Rensink - 2000.pdf:pdf},
issn = {1350-6285},
journal = {Visual Cognition},
number = {1-3},
pages = {17--42},
title = {{The Dynamic Representation of Scenes}},
url = {http://www.tandfonline.com/doi/abs/10.1080/135062800394667},
volume = {7},
year = {2000}
}
@article{Blanke2015,
abstract = {Recent work in human cognitive neuroscience has linked self-consciousness to the processing of multisen- sory bodily signals (bodily self-consciousness [BSC]) in fronto-parietal cortex and more posterior temporo- parietal regions.Wehighlight the behavioral, neurophysiological, neuroimaging, and computational laws that subtend BSCin humans and non-human primates.Wepropose thatBSCincludes body-centered perception (hand, face, and trunk), based on the integration of proprioceptive, vestibular, and visual bodily inputs, and involves spatio-temporal mechanisms integrating multisensory bodily stimuli within peripersonal space (PPS). We develop four major constraints of BSC (proprioception, body-related visual information, PPS, and embodiment) and argue that the fronto-parietal and temporo-parietal processing of trunk-centered multisensory signals in PPS is of particular relevance for theoretical models and simulations of BSC and eventually of self-consciousness.},
author = {Blanke, Olaf and Slater, Mel and Serino, Andrea},
doi = {10.1016/j.neuron.2015.09.029},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neuron/2015/Blanke, Slater, Serino - 2015.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {1},
pages = {145--166},
publisher = {Elsevier Inc.},
title = {{Behavioral, Neural, and Computational Principles of Bodily Self-Consciousness}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315008181},
volume = {88},
year = {2015}
}
@article{Sun2012a,
abstract = {Cognitive architectures may serve as a good basis for building mind/brain-inspired, psychologically realistic cognitive agents for various applications that require or prefer human-like behaviour and performance. This article explores a well-established cognitive architecture CLARION and shows how its behaviour and performance capture human psychology at a detailed level. The model captures many psychological quasi-laws concerning categorisation, induction, uncertain reasoning, decision-making, and so on, which indicates human-like characteristics beyond what other models have been shown to be capable of. Thus, CLARION constitutes an advance in developing more psychologically realistic cognitive agents. [ABSTRACT FROM PUBLISHER]},
author = {Sun, Ron and H{\'{e}}lie, S{\'{e}}bastien},
doi = {10.1080/0952813X.2012.661236},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Journal of Experimental {\&} Theoretical Artificial Intelligence/2012/Sun, H{\'{e}}lie - 2012.pdf:pdf},
isbn = {5182763409},
issn = {0952-813X},
journal = {Journal of Experimental {\&} Theoretical Artificial Intelligence},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
number = {1},
pages = {65--92},
title = {{Psychologically realistic cognitive agents: taking human cognition seriously}},
volume = {25},
year = {2012}
}
@unpublished{Shumsky2015b,
author = {Шумский, С. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Шумский - 2015(2).pdf:pdf},
language = {russian},
pages = {40},
title = {{Реинжениринг архитектуры мозга: роль и взаимодействие основных подсистем}},
year = {2015}
}
@incollection{Albus2007,
author = {Albus, James and Barbera, Anthony},
booktitle = {Intelligent Vehicle Systems: A 4D/RCS Approach},
isbn = {9781600212604},
pages = {1--30},
publisher = {Nova Science Publishers, Inc.},
title = {{4D/RCS reference model architecture for unmanned ground vehicles}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84895238575{\&}partnerID=tZOtx3y1},
year = {2007}
}
@article{Madl2014,
author = {Madl, Tamas and Chen, Ke and Montaldi, Daniela and Trappl, Robert},
doi = {10.1016/j.neunet.2015.01.002},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural Networks/2014/Madl et al. - 2014.pdf:pdf},
issn = {0893-6080},
journal = {Neural Networks},
keywords = {computational cognitive modeling,spatial memory models},
pages = {18--43},
publisher = {Elsevier Ltd},
title = {{Computational cognitive models of spatial memory: a review}},
url = {http://dx.doi.org/10.1016/j.neunet.2015.01.002},
volume = {65},
year = {2014}
}
@inproceedings{Richter2012,
author = {Richter, Mathis and Sandamirskaya, Yulia and Schoner, Gregor},
booktitle = {2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/2012 IEEERSJ International Conference on Intelligent Robots and Systems (IROS)/2012/Richter, Sandamirskaya, Schoner - 2012.pdf:pdf},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
pages = {2457--2464},
publisher = {IEEE},
title = {{A robotic action selection and behavioral organization architecture inspired by human cognition}},
year = {2012}
}
@article{Coward2007,
abstract = {There has been much discussion on what a scientific theory of consciousness would look like, and even whether such a theory is possible. Some common misunderstandings of the nature of theories (e.g., in the physical sciences) have confused the discussion of theories concerning consciousness. Theories in the physical sciences establish hierarchies of descriptions that relate high-level descriptions of macro-level phenomena to detailed-level descriptions at a micro level. Detailed descriptions are usually more accurate but information-dense and therefore often beyond human comprehensibility (unless limited to tiny segments of a macro-level phenomenon). High-level descriptions are usually much less information-dense but more approximate. The ability to map between levels of description, and in particular the understanding of when a shift from a higher-level to a more detailed description is needed to achieve a desired degree of accuracy, is fundamental to an effective theory in any field. The form of such a theory of consciousness is sketched, and the limitations of some alternative approaches described.},
author = {Coward, L Andrew and Sun, Ron},
doi = {10.1016/j.neunet.2007.09.009},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural networks the official journal of the International Neural Network Society/2007/Coward, Sun - 2007.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Brain,Brain: physiology,Consciousness,Consciousness: physiology,Humans,Models,Neural Networks (Computer),Psychological},
number = {9},
pages = {947--54},
pmid = {17890054},
title = {{Hierarchical approaches to understanding consciousness.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17890054},
volume = {20},
year = {2007}
}
@inproceedings{Loula2012,
address = {Birmingham},
author = {Loula, Angelo and Queiroz, Jo{\~{a}}o},
booktitle = {AISB/IACAP World Congress 2012: Computational Philosophy, Part of Alan Turing Year 2012},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/AISBIACAP World Congress 2012 Computational Philosophy, Part of Alan Turing Year 2012/2012/Loula, Queiroz - 2012.pdf:pdf},
keywords = {semiotics},
mendeley-tags = {semiotics},
pages = {102129},
title = {{Synthetic Semiotics : on modelling and simulating the emergence of sign processes}},
year = {2012}
}
@article{Dubrovsky2008,
author = {Дубровский, Д. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Вопросы философии/2008/Дубровский - 2008.pdf:pdf},
journal = {Вопросы философии},
keywords = {consciousness},
language = {russian},
mendeley-tags = {consciousness},
number = {1},
title = {{Проблема ``другого сознания''}},
year = {2008}
}
@article{Wang2012,
abstract = {In this review, I briefly summarize current neurobiological studies of decision-making that bear on two general themes. The first focuses on the nature of neural representation and dynamics in a decision circuit. Experimental and computational results suggest that ramping-to-threshold in the temporal domain and trajectory of population activity in the state space represent a duality of perspectives on a decision process. Moreover, a decision circuit can display several different dynamical regimes, such as the ramping mode and the jumping mode with distinct defining properties. The second is concerned with the relationship between biologically-based mechanistic models and normative-type models. A fruitful interplay between experiments and these models at different levels of abstraction have enabled investigators to pose increasingly refined questions and gain new insights into the neural basis of decision-making. In particular, recent work on multi-alternative decisions suggests that deviations from rational models of choice behavior can be explained by established neural mechanisms. ?? 2012 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Wang, Xiao Jing},
doi = {10.1016/j.conb.2012.08.006},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Current Opinion in Neurobiology/2012/Wang - 2012.pdf:pdf},
isbn = {1873-6882 (Electronic)$\backslash$r0959-4388 (Linking)},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {6},
pages = {1039--1046},
pmid = {23026743},
publisher = {Elsevier Ltd},
title = {{Neural dynamics and circuit mechanisms of decision-making}},
url = {http://dx.doi.org/10.1016/j.conb.2012.08.006},
volume = {22},
year = {2012}
}
@article{Aoun2014,
author = {Aoun, Mario Antoine and Boukadoum, Mounir},
doi = {10.1109/ICCI-CC.2014.6921451},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/2014 IEEE 13th International Conference on Cognitive Informatics and Cognitive Computing/2014/Aoun, Boukadoum - 2014.pdf:pdf},
isbn = {978-1-4799-6081-1},
journal = {2014 IEEE 13th International Conference on Cognitive Informatics and Cognitive Computing},
keywords = {chaos control,chaotic spiking neural network,inputs to a pool,liquid,nds neuron,nonlinear transient computation,of,online signature verification,property,sp mentions that different,state machines,stdp},
pages = {126--132},
publisher = {Ieee},
title = {{Learning algorithm and neurocomputing architecture for NDS Neurons}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6921451},
year = {2014}
}
@article{Seth2008,
abstract = {The resurgent science of consciousness has been accompanied by a recent emphasis on the problem of measurement. Having dependable measures of consciousness is essential both for mapping experimental evidence to theory and for designing perspicuous experiments. Here, we review a series of behavioural and brain-based measures, assessing their ability to track graded consciousness and clarifying how they relate to each other by showing what theories are presupposed by each. We identify possible and actual conflicts among measures that can stimulate new experiments, and we conclude that measures must prove themselves by iteratively building knowledge in the context of theoretical frameworks. Advances in measuring consciousness have implications for basic cognitive neuroscience, for comparative studies of consciousness and for clinical applications.},
author = {Seth, Anil K. and Dienes, Zoltan and Cleeremans, Axel and Overgaard, Morten and Pessoa, Luiz},
doi = {10.1016/j.tics.2008.04.008},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in cognitive sciences/2008/Seth et al. - 2008.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Brain,Brain: physiology,Consciousness,Electroencephalography,Humans,Neuropsychology,Neuropsychology: methods,Social Behavior},
number = {8},
pages = {314--21},
pmid = {18606562},
title = {{Measuring consciousness: relating behavioural and neurophysiological approaches}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2767381{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {12},
year = {2008}
}
@inproceedings{Goertzel2014,
author = {Goertzel, Ben},
booktitle = {2014 International Joint Conference on Neural Networks (IJCNN)},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/2014 International Joint Conference on Neural Networks (IJCNN)/2014/Goertzel - 2014.pdf:pdf},
isbn = {9781479914845},
pages = {2587--2591},
title = {{How Might the Brain Represent Complex Symbolic Knowledge?}},
year = {2014}
}
@book{Vygotsky1987,
address = {New York},
author = {Vygotsky, L. S.},
editor = {Rieber, Robert W. and Carton, Aaron S.},
keywords = {psycho},
mendeley-tags = {psycho},
publisher = {Plenum Press},
title = {{The Collected Works of L. S. Vygotsky}},
year = {1987}
}
@incollection{Hepp1987,
author = {Hepp, K. and Henn, V.},
booktitle = {Physics in Living Matter},
editor = {Baeriswyl, Dionys and Droz, Michel and Malaspinas, Andreas and Martinoli, Piero},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Physics in Living Matter/1987/Hepp, Henn - 1987.pdf:pdf},
pages = {163--177},
title = {{Nonabelian Neurodynamics}},
year = {1987}
}
@article{Sanborn2010,
author = {Sanborn, Adam N. and Griffiths, Thomas L. and Shiffrin, Richard M.},
doi = {10.1016/j.cogpsych.2009.07.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Psychology/2010/Sanborn, Griffiths, Shiffrin - 2010.pdf:pdf},
issn = {00100285},
journal = {Cognitive Psychology},
number = {2},
pages = {63--106},
publisher = {Elsevier Inc.},
title = {{Uncovering mental representations with Markov chain Monte Carlo}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0010028509000449},
volume = {60},
year = {2010}
}
@incollection{Gippenreiter1998a,
address = {М.},
author = {Гиппенрейтер, Ю. Б.},
booktitle = {Введение в общую психологию. Курс лекций},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Введение в общую психологию. Курс лекций/1998/Гиппенрейтер - 1998.pdf:pdf},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
title = {{Психологическая теория деятельности. [Операциональная сторона деятельности]}},
year = {1998}
}
@article{Langley2009,
abstract = {In this paper, we examine the motivations for research on cognitive architectures and review some candidates that have been explored in the literature. After this, we consider the capabilities that a cognitive architecture should support, some properties that it should exhibit related to representation, organization, performance, and learning, and some criteria for evaluating such architectures at the systems level. In closing, we discuss some open issues that should drive future research in this important area. {\textcopyright} 2008.},
author = {Langley, Pat and Laird, John E. and Rogers, Seth},
doi = {10.1016/j.cogsys.2006.07.004},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Systems Research/2009/Langley, Laird, Rogers - 2009.pdf:pdf},
isbn = {1389-0417},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {Cognitive architectures,Cognitive processes,Intelligent systems},
number = {2},
pages = {141--160},
pmid = {1000185223},
publisher = {Elsevier B.V.},
title = {{Cognitive architectures: Research issues and challenges}},
url = {http://dx.doi.org/10.1016/j.cogsys.2006.07.004},
volume = {10},
year = {2009}
}
@article{George2009,
abstract = {The theoretical setting of hierarchical Bayesian inference is gaining acceptance as a framework for understanding cortical computation. In this paper, we describe how Bayesian belief propagation in a spatio-temporal hierarchical model, called Hierarchical Temporal Memory (HTM), can lead to a mathematical model for cortical circuits. An HTM node is abstracted using a coincidence detector and a mixture of Markov chains. Bayesian belief propagation equations for such an HTM node define a set of functional constraints for a neuronal implementation. Anatomical data provide a contrasting set of organizational constraints. The combination of these two constraints suggests a theoretically derived interpretation for many anatomical and physiological features and predicts several others. We describe the pattern recognition capabilities of HTM networks and demonstrate the application of the derived circuits for modeling the subjective contour effect. We also discuss how the theory and the circuit can be extended to explain cortical features that are not explained by the current model and describe testable predictions that can be derived from the model.},
author = {George, Dileep and Hawkins, Jeff},
doi = {10.1371/journal.pcbi.1000532},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS computational biology/2009/George, Hawkins - 2009.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Artificial Intelligence,Automated,Automated: methods,Bayes Theorem,Cerebral Cortex,Cerebral Cortex: physiology,Feedback,Markov Chains,Memory,Memory: physiology,Models,Neurological,Pattern Recognition,Pyramidal Cells,Pyramidal Cells: physiology,htm},
mendeley-tags = {htm},
number = {10},
pages = {e1000532},
pmid = {19816557},
title = {{Towards a mathematical theory of cortical micro-circuits}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2749218{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2009}
}
@book{Steyvers2003,
abstract = {Information about the structure of a causal system can come in the form of observational data-random samples of the system's autonomous behavior-or interventional data-samples conditioned on the particular values of one or more variables that have been experimentally manipulated. Here we study people's ability to infer causal structure from both observation and intervention, and to choose informative interventions on the basis of observational data. In three causal inference tasks, participants were to some degree capable of distinguishing between competing causal hypotheses on the basis of purely observational data. Performance improved substantially when participants were allowed to observe the effects of interventions that they performed on the systems. We develop computational models of how people infer causal structure from data and how they plan intervention experiments, based on the representational framework of causal graphical models and the inferential principles of optimal Bayesian decision-making and maximizing expected information gain. These analyses suggest that people can make rational causal inferences, subject to psychologically reasonable representational assumptions and computationally reasonable processing constraints. {\textcopyright} 2003 Cognitive Science Society, Inc. All rights reserved.},
author = {Steyvers, Mark and Tenenbaum, Joshua B. and Wagenmakers, Eric Jan and Blum, Ben},
booktitle = {Cognitive Science},
doi = {10.1016/S0364-0213(03)00010-7},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Science/2003/Steyvers et al. - 2003.pdf:pdf},
isbn = {1949824764},
issn = {03640213},
keywords = {Active learning,Bayesian models,Bayesian networks,Causal reasoning,Computer simulation,Decision making,Human experimentation,Hypothesis testing,Interventions,Observational learning,Rational inference,Structure learning,Web experiments},
number = {3},
pages = {453--489},
title = {{Inferring causal networks from observations and interventions}},
volume = {27},
year = {2003}
}
@article{Vartanov2011,
author = {Вартанов, А. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Нейрокомпьютеры разработка, применение/2011/Вартанов - 2011.pdf:pdf},
journal = {Нейрокомпьютеры: разработка, применение},
keywords = {coding,consciousness,meaning,semantics,sign},
language = {russian},
number = {12},
pages = {54--64},
title = {{Механизмы семантики: человек - нейрон - модель}},
year = {2011}
}
@inproceedings{Osipov1997a,
address = {Bratislava},
author = {Osipov, G. S.},
booktitle = {Proceedings of the Second Workshop on Applied Semiotics, Seventh International Conference on Artificial Intelligence and Information-Control Systems of Robots (AIICSR'97)},
keywords = {osipov},
mendeley-tags = {osipov},
pages = {27--34},
title = {{Applied Semiotics and Intelligent Control}},
year = {1997}
}
@article{2015,
abstract = {Предложена процедура экспериментального исследования, позволяющего выявить склонность испытуемого к выдвижению гипотез, относящихся к тому или иному типу картины мира. Методика измерения рациональности может быть построена как метод исключение четвёртого лишнего на материале, имеющем концептуальную основу, но допускающем как проекцию, так и функциональную интерпретацию. В такой методике испытуемому должна быть предоставлена возможность воспроизвести привычный для него ход мыслей (констатирующая серия), изменить смысл производимой интеллектуальной операции и, возможно, найти иные способы обобщения (формирующая серия), отрефлексировать основания предпочитаемого способа обобщения (контрольная серия). В соответствии с этими требованиями была создана методика, направленная на выявление ведущего типа картины мира. Проведено исследование различий по личностным опросникам и тестам между сформированными в процессе экспериментального исследования группами. Описаны характерные для разных групп способы обоснования обобщений.},
author = {Чудова, Н. В.},
journal = {Искусственный интеллект и принятие решений},
keywords = {15-07-06214,psycho},
language = {russian},
mendeley-tags = {15-07-06214,psycho},
number = {1},
pages = {(В печати)},
title = {{Исследование особенностей обобщений, характерных для разных типов картины мира}},
year = {2016}
}
@incollection{Dobnik2013,
author = {Dobnik, Simon and Cooper, Robin},
booktitle = {Constraint Solving and Language Processing},
doi = {10.1007/978-3-642-41578-4_5},
editor = {Duchier, Denys and Parmentier, Yannick},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Constraint Solving and Language Processing/2013/Dobnik, Cooper - 2013.pdf:pdf},
keywords = {action,formal semantics,language,learning and classification,perception,scriptions,spatial de-},
pages = {70--91},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Modelling language, action, and perception in Type Theory with Records}},
year = {2013}
}
@book{Vygotsy1986,
author = {Vygotsky, L. S.},
keywords = {psycho},
mendeley-tags = {psycho},
pages = {344},
publisher = {MIT Press},
title = {{Thought and Language}},
year = {1986}
}
@article{Buschman2015,
abstract = {The brain has a limited capacity and therefore needs mechanisms to selectively enhance the information most relevant to one's current behavior. We refer to these mechanisms as "attention." Attention acts by increasing the strength of selected neural representations and preferentially routing them through the brain's large-scale network. This is a critical component of cognition and therefore has been a central topic in cognitive neuroscience. Here we review a diverse literature that has studied attention at the level of behavior, networks, circuits, and neurons. We then integrate these disparate results into a unified theory of attention.},
author = {Buschman, Timothy J and Kastner, Sabine},
doi = {10.1016/j.neuron.2015.09.017},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neuron/2015/Buschman, Kastner - 2015.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {1},
pages = {127--144},
pmid = {26447577},
publisher = {Elsevier Inc.},
title = {{From Behavior to Neural Dynamics: An Integrated Theory of Attention}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26447577 http://dx.doi.org/10.1016/j.neuron.2015.09.017},
volume = {88},
year = {2015}
}
@unpublished{Lamme2005,
author = {Lamme, Victor A. F.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2005/Lamme - 2005.pdf:pdf},
pages = {1--12},
title = {{Can neuroscience reveal the true nature of consciousness?}},
year = {2005}
}
@article{Steels2006,
author = {Steels, Luc},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/IEEE Intelligent Systems/2006/Steels - 2006.pdf:pdf},
journal = {IEEE Intelligent Systems},
pages = {32--38},
title = {{Semiotic dynamics for embodied agents}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1637348},
volume = {213},
year = {2006}
}
@incollection{Vygotsky1984,
address = {М.},
author = {Выготский, Л. С.},
booktitle = {Собрание сочинений: В 6 т.},
editor = {Ярошевский, М. Г.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Собрание сочинений В 6 т/1984/Выготский - 1984.pdf:pdf},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {91--318},
publisher = {Педагогика},
title = {{Учение об эмоциях. Историко-пихологическое исследование}},
volume = {6},
year = {1984}
}
@article{2010,
abstract = {Проанализирована эволюция поколений роботов, сформулированы требования к роботам четвертого поколения как когнитивным агентам. Показано, что важнейшим качеством когнитивного агента является ситуативное гранулирование информации, необходимое для работы в условиях неопределенности. В контексте построения пространственных гранул введена статическая пространственная логика для моделирования взаимодействия робота с внешней средой. Исследованы варианты распространения нечетких лингвистических ограничений в задачах анализа про- странственной ситуации.},
author = {Калуцкая, А. П. and Тарасов, В. Б.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Программные продукты и системы/2010/Калуцкая, Тарасов - 2010.pdf:pdf},
journal = {Программные продукты и системы},
keywords = {автономный агент,взаимодействие агента со средой,зические логики,когнитивный робот,логики расстояний и направлений,обобщенные ограничения,пространственные логики,псевдофи-,среда},
number = {2},
pages = {111--115},
title = {{Моделирование взаимодействия робота с внешней средой на основе пространственных логик и распространения ограничений}},
year = {2010}
}
@book{Edelman1987,
address = {New York},
author = {Edelman, G. M.},
pages = {400},
publisher = {Basic Books},
title = {{Neural Darwinism: The Theory Of Neuronal Group Selection}},
year = {1987}
}
@inproceedings{Cubek2015,
author = {Cubek, Richard and Ertel, Wolfgang},
booktitle = {Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, Washington, USA, May 26-30, 2015},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, Washington, USA, May 26-30, 2015/2015/Cubek, Ertel - 2015.pdf:pdf},
isbn = {9781479969234},
pages = {2592--2597},
publisher = {IEEE},
title = {{High-Level Learning from Demonstration with Conceptual Spaces and Subspace Clustering}},
year = {2015}
}
@article{Lieto2016,
abstract = {We overview the main historical and technological elements characterising the rise, the fall and the recent renaissance of the cognitive approaches to Artificial Intelligence and provide some insights and suggestions about the future directions and challenges that, in our opinion, this discipline needs to face in the next years.},
author = {Lieto, Antonio and Radicioni, Daniele P.},
doi = {10.1016/j.cogsys.2016.02.002},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Systems Research/2016/Lieto, Radicioni - 2016.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {Artificial intelligence,Cognitive systems,Computational models of cognition,Epistemology of the artificial},
pages = {1--3},
publisher = {Elsevier B.V.},
title = {{From human to artificial cognition and back: New perspectives on cognitively inspired AI systems}},
url = {http://dx.doi.org/10.1016/j.cogsys.2016.02.002},
volume = {39},
year = {2016}
}
@techreport{Laird2015,
author = {Laird, John E. and Congdon, Clare Bates},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Laird, Congdon - 2015.pdf:pdf},
institution = {University of Michigan},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
title = {{The Soar User's Manual: Version 9.5.0}},
year = {2015}
}
@article{DeFelipe2012,
author = {DeFelipe, Javier},
doi = {10.3389/fnana.2012.00022},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in Neuroanatomy/2012/DeFelipe - 2012.pdf:pdf},
issn = {16625129},
journal = {Frontiers in Neuroanatomy},
keywords = {Cerebral Cortex,cortical processes,cortical unit,macrocolumn's function,minicolumns,neocortical column},
language = {English},
publisher = {Frontiers},
title = {{The neocortical column}},
url = {http://journal.frontiersin.org/Journal/10.3389/fnana.2012.00022/abstract},
volume = {6},
year = {2012}
}
@unpublished{FranciscoE.DeSousaWebber,
author = {Webber, Francisco},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Webber - 2015.pdf:pdf},
title = {{Semantic Folding Theory}},
year = {2015}
}
@incollection{Obuhov2008,
author = {Обухов, Д. К.},
booktitle = {Вопросы морфологии XXI века},
editor = {Костюкевич, С. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Вопросы морфологии XXI века/2008/Обухов - 2008.pdf:pdf},
language = {russian},
number = {1},
pages = {200--223},
title = {{Современные представления о развитии, структуре и эволюции неокортекса конечного мозга млекопитающих животных и человека}},
year = {2008}
}
@article{Allgaiera,
author = {Albus, James S.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/International Journal of Machine Consciousness/2010/Albus - 2010.pdf:pdf},
journal = {International Journal of Machine Consciousness},
keywords = {brain,eureqa,fmri,neuroimaging,symbolic regression},
number = {2},
pages = {193--211},
title = {{Reverse Engineering the Brain}},
volume = {2},
year = {2010}
}
@article{Evans2013,
abstract = {Dual-process and dual-system theories in both cognitive and social psychology have been subjected to a number of recently published criticisms. However, they have been attacked as a category, incorrectly assuming there is a generic version that applies to all. We identify and respond to 5 main lines of argument made by such critics. We agree that some of these arguments have force against some of the theories in the literature but believe them to be overstated. We argue that the dual-processing distinction is supported by much recent evidence in cognitive science. Our preferred theoretical approach is one in which rapid autonomous processes (Type 1) are assumed to yield default responses unless intervened on by distinctive higher order reasoning processes (Type 2). What defines the difference is that Type 2 processing supports hypothetical thinking and load heavily on working memory.},
author = {Evans, Jonathan and Stanovich, K E},
doi = {10.1177/1745691612460685},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Perspectives on Psychological Science/2013/Evans, Stanovich - 2013.pdf:pdf},
isbn = {1745-6916$\backslash$n1745-6924},
issn = {1745-6916},
journal = {Perspectives on Psychological Science},
keywords = {Dual process theory,Dual systems,Individual differences,Rationality,Working memory},
number = {3},
pages = {223--241},
pmid = {26172965},
title = {{Dual-process theories of higher cognition: Advancing the debate}},
volume = {8},
year = {2013}
}
@article{Osipov2002c,
author = {Осипов, Г. С.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Новости искусственного интеллекта/2002/Осипов - 2002.pdf:pdf},
journal = {Новости искусственного интеллекта},
keywords = {osipov},
language = {russian},
mendeley-tags = {osipov},
number = {6},
pages = {3--7},
title = {{От ситуационного управления к прикладной семиотике}},
year = {2002}
}
@inproceedings{Raue2015,
abstract = {The problem of how infants learn to associate visual inputs, speech, and internal symbolic representation has long been of interest in Psychology, Neuroscience, and Artificial Intelligence. A priori, both visual inputs and auditory inputs are complex analog signals with a large amount of noise and context, and lacking of any segmentation information. In this paper, we address a simple form of this problem: the association of one visual input and one auditory input with each other. We show that the presented model learns both segmentation, recognition and symbolic representation under two simple assumptions: (1) that a symbolic representation exists, and (2) that two different inputs represent the same symbolic structure. Our approach uses two Long Short-Term Memory (LSTM) networks for multimodal sequence learning and recovers the internal symbolic space using an EM-style algorithm. We compared our model against LSTM in three different multimodal datasets: digit, letter and word recognition. The performance of our model reached similar results to LSTM.},
author = {Raue, Federico and Breuel, Thomas M. and Liwicki, Marcus},
booktitle = {Proceedings of the NIPS Workshop on Cognitive Computation: Integrating Neural and Symbolic Approaches},
editor = {Besold, Tarek R. and d'Avila Garcez, Artur and Marcus, Gary F. and Miikkulainen, Risto},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the NIPS Workshop on Cognitive Computation Integrating Neural and Symbolic Approaches/2015/Raue, Breuel, Liwicki - 2015.pdf:pdf},
pages = {1--9},
title = {{Symbol Grounding in Multimodal Sequences using Recurrent Neural Networks}},
year = {2015}
}
@book{Krasnoschekova2007,
address = {СПб.},
author = {Краснощекова, Е. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2007/Краснощекова - 2007.pdf:pdf},
language = {russian},
pages = {130},
publisher = {Издательство СпбГУ},
title = {{Модульная организация нервных центров}},
year = {2007}
}
@article{Rao2004,
abstract = {A large number of human psychophysical results have been successfully explained in recent years using Bayesian models. However, the neural implementation of such models remains largely unclear. In this article, we show that a network architecture commonly used to model the cerebral cortex can implement Bayesian inference for an arbitrary hidden Markov model. We illustrate the approach using an orientation discrimination task and a visual motion detection task. In the case of orientation discrimination, we show that the model network can infer the posterior distribution over orientations and correctly estimate stimulus orientation in the presence of significant noise. In the case of motion detection, we show that the resulting model network exhibits direction selectivity and correctly computes the posterior probabilities over motion direction and position. When used to solve the well-known random dots motion discrimination task, the model generates responses that mimic the activities of evidence-accumulating neurons in cortical areas LIP and FEF. The framework we introduce posits a new interpretation of cortical activities in terms of log posterior probabilities of stimuli occurring in the natural world.},
author = {Rao, Rajesh P N},
doi = {10.1162/08997660460733976},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural computation/2004/Rao - 2004.pdf:pdf},
isbn = {08997660460733976},
issn = {0899-7667},
journal = {Neural computation},
number = {1},
pages = {1--38},
pmid = {15006021},
title = {{Bayesian computation in recurrent neural circuits}},
volume = {16},
year = {2004}
}
@unpublished{Intelligence2012,
author = {Chella, Antonio and Manzotti, Ricardo},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2012/Chella, Manzotti - 2012.pdf:pdf},
pages = {2--3},
title = {{Strong Artificial Intelligence and Consciousness}},
year = {2012}
}
@article{Barsalou2008,
abstract = {Grounded cognition rejects traditional views that cognition is computation on amodal symbols in a modular system, independent of the brain's modal systems for perception, action, and introspection. Instead, grounded cognition proposes that modal simulations, bodily states, and situated action underlie cognition. Accumulating behavioral and neural evidence supporting this view is reviewed from research on perception, memory, knowledge, language, thought, social cognition, and development. Theories of grounded cognition are also reviewed, as are origins of the area and common misperceptions of it. Theoretical, empirical, and methodological issues are raised whose future treatment is likely to affect the growth and impact of grounded cognition.},
author = {Barsalou, Lawrence W},
doi = {10.1146/annurev.psych.59.103006.093639},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Annual review of psychology/2008/Barsalou - 2008.pdf:pdf},
isbn = {0-7695-2786-8},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {cognitive architecture,imagery,psycho,representation,simulation},
mendeley-tags = {psycho},
pages = {617--645},
pmid = {17705682},
title = {{Grounded cognition}},
volume = {59},
year = {2008}
}
@article{Pospelov1996,
author = {Поспелов, Д. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Программные продукты и системы/1996/Поспелов - 1996.pdf:pdf},
journal = {Программные продукты и системы},
language = {russian},
number = {3},
pages = {10--13},
title = {{Прикладная семиотика и искусственный интеллект}},
year = {1996}
}
@inproceedings{Vityaev2012b,
address = {Ростов-на-Дону},
author = {Витяев, Е. Е.},
booktitle = {Материалы XVI Международной конференции по нейрокибернетике (24-28 сентября)},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Материалы XVI Международной конференции по нейрокибернетике (24-28 сентября)/2012/Витяев - 2012.pdf:pdf},
language = {russian},
pages = {81--84},
title = {{Формальная модель нейрона, обеспечивающая непротиворечивость предсказаний}},
volume = {2},
year = {2012}
}
@article{Bruce2009,
abstract = {A proposal for saliency computation within the visual cortex is put forth based on the premise that localized saliency computation serves to maximize information sampled from one's environment. The model is built entirely on computational constraints but nevertheless results in an architecture with cells and connectivity reminiscent of that appearing in the visual cortex. It is demonstrated that a variety of visual search behaviors appear as emergent properties of the model and therefore basic principles of coding and information transmission. Experimental results demonstrate greater efficacy in predicting fixation patterns across two different data sets as compared with competing models.},
author = {Bruce, Neil D. B. and Tsotsos, John K.},
doi = {10.1167/9.3.5},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Journal of Vision/2009/Bruce, Tsotsos - 2009.pdf:pdf},
issn = {1534-7362},
journal = {Journal of Vision},
number = {9},
pages = {1--24},
pmid = {19757944},
title = {{Saliency, attention, and visual search: An information theoretic approach}},
url = {http://journalofvision.org/9/3/5/article.aspx},
volume = {3},
year = {2009}
}
@article{Solovyeva2015,
abstract = {In this work we reveal and explore a new class of attractor neural networks, based on inborn connections provided by model molecular markers, the molecular marker based attractor neural networks (MMBANN). We have explored conditions for the existence of attractor states, critical relations between their parameters and the spectrum of single neuron models, which can implement the MMBANN. Besides, we describe functional models (perceptron and SOM) which obtain significant advantages, while using MMBANN. In particular, the perceptron based on MMBANN, gets specificity gain in orders of error probabilities values, MMBANN SOM obtains real neurophysiological meaning, the number of possible grandma cells increases 1000- fold with MMBANN. Each set of markers has a metric, which is used to make connections between neurons containing the markers. The resulting neural networks have sets of attractor states, which can serve as finite grids for representation of variables in computations. These grids may show dimensions of d = 0, 1, 2,... We work with static and dynamic attractor neural networks of dimensions d = 0 and d = 1. We also argue that the number of dimensions which can be represented by attractors of activities of neural networks with the number of elements N=104 does not exceed 8.},
archivePrefix = {arXiv},
arxivId = {1508.01060},
author = {Solovyeva, Ksenia P and Karandashev, Iakov M and Zhavoronkov, Alex and Dunin-Barkowski, Witali L.},
doi = {10.3389},
eprint = {1508.01060},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Front. Syst. Neurosci/2015/Solovyeva et al. - 2015.pdf:pdf},
issn = {1662-5137},
journal = {Front. Syst. Neurosci.},
keywords = {Hopfield networks,bump attractor,cortical column,dynamic attractor,hopfield networks,innate connections,neural networks,self-organizing mapping},
pmid = {26778977},
title = {{Models of Innate Neural Attractors and Their Applications for Neural Information Processing}},
volume = {9},
year = {2015}
}
@article{Tabor2013,
abstract = {Human participants and recurrent ("connectionist") neural networks were both trained on a categorization system abstractly similar to natural language systems involving irregular ("strong") classes and a default class. Both the humans and the networks exhibited staged learning and a generalization pattern reminiscent of the Elsewhere Condition (Kiparsky, 1973). Previous connectionist accounts of related phenomena have often been vague about the nature of the networks' encoding systems. We analyzed our network using dynamical systems theory, revealing topological and geometric properties that can be directly compared with the mechanisms of non-connectionist, rule-based accounts. The results reveal that the networks "contain" structures related to mechanisms posited by rule-based models, partly vindicating the insights of these models. On the other hand, they support the one mechanism (OM), as opposed to the more than one mechanism (MOM), view of symbolic abstraction by showing how the appearance of MOM behavior can arise emergently from one underlying set of principles. The key new contribution of this study is to show that dynamical systems theory can allow us to explicitly characterize the relationship between the two perspectives in implemented models.},
author = {Tabor, Whitney and Cho, Pyeong W and Dankowicz, Harry},
doi = {10.1111/cogs.12072},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive science/2013/Tabor, Cho, Dankowicz - 2013.pdf:pdf},
issn = {1551-6709},
journal = {Cognitive science},
keywords = {Adult,Computer Simulation,Concept Formation,Concept Formation: physiology,Female,Generalization (Psychology),Generalization (Psychology): physiology,Humans,Learning,Learning: physiology,Male,Models,Problem Solving,Problem Solving: physiology,Psychological},
number = {7},
pages = {1193--227},
pmid = {23931713},
title = {{Birth of an abstraction: a dynamical systems account of the discovery of an elsewhere principle in a category learning task}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23931713},
volume = {37},
year = {2013}
}
@article{Hawes2007,
abstract = {We present integration mechanisms for combining heterogeneous components in a situated information processing system, illustrated by a cognitive robot able to collaborate with a human and display some understanding of its surroundings. These mechanisms include an architectural schema that encourages parallel and incremental information processing, and a method for binding information from distinct representations that when faced with rapid change in the world can maintain a coherent, though distributed, view of it. Provisional results are demonstrated in a robot combining vision, manipulation, language, planning and reasoning capabilities interacting with a human and manipulable objects.},
author = {Hawes, Nick and Sloman, Aaron and Wyatt, Jeremy and Zillich, Michael and Jacobsson, Henrik and Kruijff, Geert-jan M and Brenner, Michael and Berginc, Gregor and Skoˇ, Danijel},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Intelligence/2007/Hawes et al. - 2007.pdf:pdf},
isbn = {978-1-57735-323-2},
journal = {Intelligence},
pages = {1548--1553},
title = {{Towards an Integrated Robot with Multiple Cognitive Functions}},
url = {http://www.aaai.org/Papers/AAAI/2007/AAAI07-245.pdf},
volume = {22},
year = {2007}
}
@book{Pospelov1986,
address = {М.},
author = {Поспелов, Д. А.},
language = {russian},
pages = {288},
publisher = {Наука},
title = {{Ситуационное управление: теория и практика}},
year = {1986}
}
@article{Pfister2014,
author = {Bauer, Roman and Zubler, Frederic and Pfister, Sabina and Hauri, Andreas and Pfeiffer, Michael and Muir, Dylan R and Douglas, Rodney J},
doi = {10.1371/journal.pcbi.1003994},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLOS Computational Biology/2014/Bauer et al. - 2014.pdf:pdf},
journal = {PLOS Computational Biology},
number = {12},
pages = {e1003994},
title = {{Developmental Self-Construction and -Configuration of Functional Neocortical Neuronal Networks}},
volume = {10},
year = {2014}
}
@article{Chernavsky2012c,
abstract = {Рассматривается одна из возможных схем нейропроцессорной конструкции, способной решать задачи, традиционно относимые к мышлению и творчеству. Выделена подсистема, обрабатывающая образную информацию; ее важная составляющая — ―размытое множество‖, содержащее всю образную информацию, доступную системе. Выделена подсистема, способная решать логические задачи. Подсистема распознавания процесса и построения прогноза позволяет ввести понятие континуального времени. Показано, что решение творческих задач (при недостатке информации или противоречивости алгоритмов) в символьной подсистеме невозможно и требует обращения к размытому (образному) множеству.},
author = {Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А. and Чернавская, О. Д.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Сложны/2012/Чернавский et al. - 2012.pdf:pdf},
journal = {Сложны},
keywords = {мышление,научное творчество,нейропроцессор,самоорганизация,символьная система},
language = {russian},
number = {4},
pages = {25--37},
title = {{Процесс мышления в контексте динамической теории информации. Часть III: один из вариантов конструкции нейропроцессоров для моделирования процесса мышления}},
volume = {3},
year = {2012}
}
@article{Fernando2013,
abstract = {How do human infants learn the causal dependencies between events? Evidence suggests that this remarkable feat can be achieved by observation of only a handful of examples. Many computational models have been produced to explain how infants perform causal inference without explicit teaching about statistics or the scientific method. Here, we propose a spiking neuronal network implementation that can be entrained to form a dynamical model of the temporal and causal relationships between events that it observes. The network uses spike-time dependent plasticity, long-term depression, and heterosynaptic competition rules to implement Rescorla-Wagner-like learning. Transmission delays between neurons allow the network to learn a forward model of the temporal relationships between events. Within this framework, biologically realistic synaptic plasticity rules account for well-known behavioral data regarding cognitive causal assumptions such as backwards blocking and screening-off. These models can then be run as emulators for state inference. Furthermore, this mechanism is capable of copying synaptic connectivity patterns between neuronal networks by observing the spontaneous spike activity from the neuronal circuit that is to be copied, and it thereby provides a powerful method for transmission of circuit functionality between brain regions.},
author = {Fernando, Chrisantha},
doi = {10.1111/cogs.12073},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive science/2013/Fernando - 2013.pdf:pdf},
issn = {1551-6709},
journal = {Cognitive science},
keywords = {backwards blocking,causal inference,groups,neuronal replicator hypothesis,polychronous,rational process model,screening-off},
number = {8},
pages = {1426--70},
pmid = {23957457},
title = {{From blickets to synapses: inferring temporal causal networks by observation}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23957457},
volume = {37},
year = {2013}
}
@book{Steels2012,
editor = {Steels, Luc and Hild, Manfred},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2012/Unknown - 2012.pdf:pdf},
isbn = {9781461430636},
pages = {276},
publisher = {Springer US},
title = {{Language Grounding in Robots}},
year = {2012}
}
@incollection{Bagchi2015,
abstract = {The brain is a neurological device capable to carry out distributed computation and express cognition. The computational models of consciousness and cognition have potential applications in bio-inspired computing paradigm. This paper proposes a computational model of consciousness as a cognitive function following neurophysiology and elements of distributed computing. It is illustrated that the distributed computational model of consciousness has a basis in the quantum mechanical models in explaining the neurological cognitive functions. The transitions between the computing model and quantum basis are explained and analyzed considering different linear Hermitian operators.},
author = {Bagchi, Susmit},
booktitle = {Artificial Intelligence and Soft Computing},
doi = {10.1007/978-3-642-13208-7},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Artificial Intelligence and Soft Computing/2015/Bagchi - 2015.pdf:pdf},
isbn = {9783642132070},
keywords = {cognition,consciousness,distributed computing,hermitian,quantum mechanics},
mendeley-tags = {consciousness},
pages = {71--78},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{On the Convergence of Quantum and Distributed Computational Models of Consciousness}},
url = {http://www.springerlink.com/content/15202tv751321p51/},
year = {2015}
}
@book{Khomskaya2005,
address = {СПб.},
edition = {3-е изд.},
editor = {Хомская, Е. Д.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Unknown - 2011.pdf:pdf},
isbn = {5469006204},
language = {russian},
pages = {992},
publisher = {Питер},
title = {{Нейропсихология: Хрестоматия}},
year = {2011}
}
@article{Vavrecka2014,
author = {Vavre{\v{c}}ka, Michal and Farka{\v{s}}, Igor},
doi = {10.1007/s12559-013-9212-5},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Computation/2014/Vavre{\v{c}}ka, Farka{\v{s}} - 2014.pdf:pdf},
issn = {18669956},
journal = {Cognitive Computation},
keywords = {Multimodal representations,Self-organizing map,Spatial phrases,Symbol grounding,Unsupervised learning},
number = {1},
pages = {101--112},
title = {{A Multimodal Connectionist Architecture for Unsupervised Grounding of Spatial Language}},
volume = {6},
year = {2014}
}
@article{Unknown,
author = {Давлетбакова, З. Л.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Современные проблемы науки и образования/2013/Давлетбакова - 2013.pdf:pdf},
journal = {Современные проблемы науки и образования},
keywords = {fuzzy inference,fuzzy logic,geographic information systems,objects,planning,spatial description of,the problem of territorial},
number = {6},
pages = {1--8},
title = {{Построение модели обработки пространственной информации на основе методов нечеткой логики}},
year = {2013}
}
@article{Lakhman2013,
author = {Лахман, К. В. and Бурцев, М. С.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Математическая биология и биоинформатика/2013/Лахман, Бурцев - 2013.pdf:pdf},
journal = {Математическая биология и биоинформатика},
language = {russian},
number = {2},
pages = {419--431},
title = {{Механизмы кратковременной памяти в целенаправленном поведении нейросетевых агентов}},
volume = {8},
year = {2013}
}
@article{Dipoppa2013,
abstract = {Cognitive effort leads to a seeming cacophony of brain oscillations. For example, during tasks engaging working memory (WM), specific oscillatory frequency bands modulate in space and time. Despite ample data correlating such modulation to task performance, a mechanistic explanation remains elusive. We propose that flexible control of neural oscillations provides a unified mechanism for the rapid and controlled transitions between the computational operations required by WM. We show in a spiking network model that modulating the input oscillation frequency sets the network in different operating modes: rapid memory access and load is enabled by the beta-gamma oscillations, maintaining a memory while ignoring distractors by the theta, rapid memory clearance by the alpha. The various frequency bands determine the dynamic gating regimes enabling the necessary operations for WM, whose succession explains the need for the complex oscillatory brain dynamics during effortful cognition.},
author = {Dipoppa, Mario and Gutkin, Boris S},
doi = {10.1073/pnas.1303270110},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences of the United States of America/2013/Dipoppa, Gutkin - 2013.pdf:pdf},
isbn = {1303270110},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Biological Clocks,Biological Clocks: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Cognition,Cognition: physiology,Humans,Memory,Memory: physiology,Models, Neurological,Neurons,Neurons: physiology},
number = {31},
pages = {12828--33},
pmid = {23858465},
title = {{Flexible frequency control of cortical oscillations enables computations required for working memory.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3732977{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {110},
year = {2013}
}
@article{Luria1977,
author = {Лурия, A. Р.},
journal = {Вопросы философии},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
number = {9},
pages = {68--77},
title = {{О месте психологии в ряду социальных и биологических наук}},
year = {1977}
}
@inproceedings{Foltyn2006,
abstract = {Multi-agent systems penetrate into interesting domains of computing with limited resources, programme code reusability and automated code generation. This paper presents general framework of Reflective-Cognitive agent architecture which enables the agent to alter its own code in runtime according to the changes in the environment. We also present results of architecture implementation showing the plausibility of created prototype.},
author = {Foltyn, Lukas and Tozicka, Jan and Rollo, Milan and Pechoucek, Michal and Jisl, Pavel},
booktitle = {Proceedings - DIS 2006: IEEE Workshop on Distributed Intelligent Systems - Collective Intelligence and Its Applications},
doi = {10.1109/DIS.2006.62},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings - DIS 2006 IEEE Workshop on Distributed Intelligent Systems - Collective Intelligence and Its Applications/2006/Foltyn et al. - 2006.pdf:pdf},
isbn = {076952589X},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
pages = {326--334},
title = {{Reflective-cognitive architecture: From abstract concept to self-adapting agent}},
year = {2006}
}
@incollection{Sowa2011,
author = {Sowa, John F},
booktitle = {Conceptual Structures for Discovering Knowledge},
editor = {Andrews, Simon and Polovina, Simon and Hill, Richard and Akhgar, Babak},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Conceptual Structures for Discovering Knowledge/2011/Sowa - 2011.pdf:pdf},
pages = {35--49},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Cognitive Architectures For Conceptual Structures}},
year = {2011}
}
@article{Augello2015,
abstract = {Evaluation is a key factor of creativity: for this reason it should be integrated into a cognitive architecture of a creative artificial agent. The approach illustrated in this paper uses the Psi model, and describes the framework for introducing internal and external evaluations, and how they influence demands and motivation of the artificial agent. Internal evaluation mechanisms drive the creative process, and influence competence of the creative agent. External evaluation acts through certainty, and requires interaction with human users that express both opinions and some subjective quantitative evaluations on the final artwork. The system uses natural language processing techniques in order to infer the satisfaction and the emotional impact of the final product obtained by the creative agent.},
author = {Augello, Agnese and Infantino, Ignazio and Pilato, Giovanni and Rizzo, Riccardo and Vella, Filippo},
doi = {10.1016/j.bica.2014.11.013},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2015/Augello et al. - 2015.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Artificial artist,Computational creativity,Creativity evaluation},
pages = {29--37},
publisher = {Elsevier B.V.},
title = {{Creativity evaluation in a cognitive architecture}},
url = {http://dx.doi.org/10.1016/j.bica.2014.11.013},
volume = {11},
year = {2015}
}
@article{DeWolf2011,
abstract = {Our empirical, neuroscientific understanding of biological motor systems has been rapidly growing in recent years. However, this understanding has not been systematically mapped to a quantitative characterization of motor control based in control theory. Here, we attempt to bridge this gap by describing the neural optimal control hierarchy (NOCH), which can serve as a foundation for biologically plausible models of neural motor control. The NOCH has been constructed by taking recent control theoretic models of motor control, analyzing the required processes, generating neurally plausible equivalent calculations and mapping them on to the neural structures that have been empirically identified to form the anatomical basis of motor control. We demonstrate the utility of the NOCH by constructing a simple model based on the identified principles and testing it in two ways. First, we perturb specific anatomical elements of the model and compare the resulting motor behavior with clinical data in which the corresponding area of the brain has been damaged. We show that damaging the assigned functions of the basal ganglia and cerebellum can cause the movement deficiencies seen in patients with Huntington's disease and cerebellar lesions. Second, we demonstrate that single spiking neuron data from our model's motor cortical areas explain major features of single-cell responses recorded from the same primate areas. We suggest that together these results show how NOCH-based models can be used to unify a broad range of data relevant to biological motor control in a quantitative, control theoretic framework.},
author = {DeWolf, T and Eliasmith, C},
doi = {10.1088/1741-2560/8/6/065009},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Journal of Neural Engineering/2011/DeWolf, Eliasmith - 2011.pdf:pdf},
isbn = {1741-2552},
issn = {1741-2560},
journal = {Journal of Neural Engineering},
number = {6},
pages = {065009},
pmid = {22056418},
title = {{The neural optimal control hierarchy for motor control}},
volume = {8},
year = {2011}
}
@book{Nukolls2003,
address = {М.},
author = {Николлс, Дж. Г. and Мартин, А. Р. and Валлас, Б. Дж. and Фукс, П. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2003/Николлс et al. - 2003.pdf:pdf},
isbn = {5354001625},
language = {russian},
pages = {672},
publisher = {Едиториал УРСС},
title = {{От нейрона к мозгу}},
translator = {Балабан, П. М. and Галкин, А. В. and Гиниатуллин, Р. А. and Хазипов, Р. Н. and Хируг, Л. С.},
year = {2003}
}
@article{Zhang2015,
author = {Zhang, Yunfeng and Paik, Jaehyon and Pirolli, Peter},
doi = {10.1111/tops.12143},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Topics in Cognitive science/2015/Zhang, Paik, Pirolli - 2015.pdf:pdf},
journal = {Topics in Cognitive science},
keywords = {change detection,cognitive,counterfactual reasoning,modeling,optimal foraging,reinforcement learning},
number = {2},
pages = {368--381},
title = {{Reinforcement Learning and Counterfactual Reasoning Explain Adaptive Behavior in a Changing Environment}},
volume = {7},
year = {2015}
}
@article{Crawford2016,
author = {Crawford, Eric and Gingerich, Matthew and Eliasmith, Chris},
doi = {10.1111/cogs.12261},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Science/2016/Crawford, Gingerich, Eliasmith - 2016.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {biologically plausible,connectionism,knowledge representation,neural network,scaling,vector symbolic architecture,wordnet},
number = {4},
pages = {782--821},
pmid = {26173464},
title = {{Biologically Plausible, Human-Scale Knowledge Representation}},
url = {http://doi.wiley.com/10.1111/cogs.12261},
volume = {40},
year = {2016}
}
@article{Thomason2016,
author = {Thomason, Jesse and Sinapov, Jivko and Svetlik, Maxwell and Stone, Peter and Mooney, Raymond J},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/International Joint Conference on Artificial Intelligence (IJCAI)/2016/Thomason et al. - 2016.pdf:pdf},
journal = {International Joint Conference on Artificial Intelligence (IJCAI)},
keywords = {Robotics and Vision},
pages = {3477--3483},
title = {{Learning Multi-Modal Grounded Linguistic Semantics by Playing “ I Spy ”}},
year = {2016}
}
@article{Barsalou1999,
abstract = {Prior to the twentieth century, theories of knowledge were inherently perceptual. Since then, developments in logic, statistics, and programming languages have inspired amodal theories that rest on principles fundamentally different from those underlying perception. In addition, perceptual approaches have become widely viewed as untenable because they are assumed to implement recording systems, not conceptual systems. A perceptual theory of knowledge is developed here in the context of current cognitive science and neuroscience. During perceptual experience, association areas in the brain capture bottom-up patterns of activation in sensory-motor areas. Later, in a top-down manner, association areas partially reactivate sensory-motor areas to implement perceptual symbols. The storage and reactivation of perceptual symbols operates at the level of perceptual components--not at the level of holistic perceptual experiences. Through the use of selective attention, schematic representations of perceptual components are extracted from experience and stored in memory (e.g., individual memories of green, purr, hot). As memories of the same component become organized around a common frame, they implement a simulator that produces limitless simulations of the component (e.g., simulations of purr). Not only do such simulators develop for aspects of sensory experience, they also develop for aspects of proprioception (e.g., lift, run) and introspection (e.g., compare, memory, happy, hungry). Once established, these simulators implement a basic conceptual system that represents types, supports categorization, and produces categorical inferences. These simulators further support productivity, propositions, and abstract concepts, thereby implementing a fully functional conceptual system. Productivity results from integrating simulators combinatorially and recursively to produce complex simulations. Propositions result from binding simulators to perceived individuals to represent type-token relations. Abstract concepts are grounded in complex simulations of combined physical and introspective events. Thus, a perceptual theory of knowledge can implement a fully functional conceptual system while avoiding problems associated with amodal symbol systems. Implications for cognition, neuroscience, evolution, development, and artificial intelligence are explored.},
author = {Barsalou, L. W.},
doi = {10.1017/S0140525X99252144},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/The Behavioral and brain sciences/1999/Barsalou - 1999.pdf:pdf},
isbn = {0140-525X},
issn = {0140525X},
journal = {The Behavioral and brain sciences},
keywords = {analogue processing,and much more,categories,concepts,frames,imagery,images,in the power of,knowledge,much infe-,perception,psycho,pursuits makes learned men,representation,representations,rior to the average,sensory-motor,simulation,symbol grounding,symbol systems,the habit of abstract,visualization},
mendeley-tags = {psycho},
number = {4},
pages = {577--609; discussion 610--660},
pmid = {11301525},
title = {{Perceptual symbol systems}},
volume = {22},
year = {1999}
}
@article{Shapiro2003,
abstract = {The GLAIR grounded layered architecture with integrated reasoning for cognitive robots and intelligent autonomous agents has been used in a series of projects in which Cassie, the SNePS cognitive agent, has been incorporated into hardware- or software-simulated cognitive robots. In this paper, we present an informal, but coherent, overview of the GLAIR approach to anchoring the abstract symbolic terms that denote an agent's mental entities in the lower-level structures used by the embodied agent to operate in the real (or simulated) world. We discuss anchoring in the domains of: perceivable entities and properties, actions, time, and language.},
author = {Shapiro, Stuart C. and Ismail, Haythem O.},
doi = {10.1016/S0921-8890(02)00352-4},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Robotics and Autonomous Systems/2003/Shapiro, Ismail - 2003.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {anchoring,autonomous agents,cognitive robotics,symbol grounding},
number = {2-3},
pages = {97--108},
title = {{Anchoring in a grounded layered architecture with integrated reasoning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0921889002003524},
volume = {43},
year = {2003}
}
@article{Langley2009a,
abstract = {In this paper, we review Icarus, a cognitive architecture that utilizes hierarchical skills and concepts for reactive execution in physical environments. In addition, we present two extensions to the framework. The first involves the incorporation of means-ends analysis, which lets the system compose known skills to solve novel problems. The second involves the storage of new skills that are based on successful means-ends traces. We report experimental studies of these mechanisms on three distinct domains. Our results suggest that the two methods interact to acquire useful skill hierarchies that generalize well and that reduce the effort required to handle new tasks. We conclude with a discussion of related work on learning and prospects for additional research, including extending the framework to cover developmental phenomena. ?? 2008 Elsevier B.V. All rights reserved.},
author = {Langley, Pat and Choi, Dongkyu and Rogers, Seth},
doi = {10.1016/j.cogsys.2008.07.003},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Systems Research/2009/Langley, Choi, Rogers - 2009.pdf:pdf},
isbn = {1389-0417},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {Cognitive architecture,Hierarchical skills,Incremental learning,Problem solving,Reactive control,cog{\_}arch,icarus},
mendeley-tags = {cog{\_}arch,icarus},
number = {4},
pages = {316--332},
title = {{Acquisition of hierarchical reactive skills in a unified cognitive architecture}},
volume = {10},
year = {2009}
}
@book{Edelmen1981,
address = {М.},
author = {Эделмен, Дж. and Маунткасл, В.},
editor = {Соколов, Е. Н.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/1981/Эделмен, Маунткасл - 1981.pdf:pdf},
language = {russian},
pages = {135},
publisher = {Мир},
title = {{Разумный мозг}},
translator = {Алексеенко, Н. Ю.},
year = {1981}
}
@article{Blouw2015,
abstract = {The reconciliation of theories of concepts based on prototypes, exemplars, and theory-like structures is a longstanding problem in cognitive science. In response to this problem, researchers have recently tended to adopt either hybrid theories that combine various kinds of representational structure, or eliminative theories that replace concepts with a more finely grained taxonomy of mental representations. In this paper, we describe an alternative approach involving a single class of mental representations called "semantic pointers." Semantic pointers are symbol-like representations that result from the compression and recursive binding of perceptual, lexical, and motor representations, effectively integrating traditional connectionist and symbolic approaches. We present a computational model using semantic pointers that replicates experimental data from categorization studies involving each prior paradigm. We argue that a framework involving semantic pointers can provide a unified account of conceptual phenomena, and we compare our framework to existing alternatives in accounting for the scope, content, recursive combination, and neural implementation of concepts.},
author = {Blouw, Peter and Solodkin, Eugene and Thagard, Paul and Eliasmith, Chris},
doi = {10.1111/cogs.12265},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Science/2015/Blouw et al. - 2015.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {categorization,computational modeling,concepts,mental representation,neural computation,semantics},
pages = {n/a--n/a},
pmid = {26235459},
title = {{Concepts as Semantic Pointers: A Framework and Computational Model}},
url = {http://doi.wiley.com/10.1111/cogs.12265},
year = {2015}
}
@article{Zhdan2009,
author = {Ждан, А. Н.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Методология и история психологии/2009/Ждан - 2009.pdf:pdf},
journal = {Методология и история психологии},
language = {russian},
number = {1},
pages = {47--60},
title = {{Пути и принципы исследования сознания в истории психологии}},
volume = {4},
year = {2009}
}
@article{Bonasso1997,
abstract = {This paper describes an implementation of the 3T robot architecture which has been under development for the last eight years. The architecture uses three levels of abstraction and description languages which are compatible between levels. The makeup of the architecture helps to coordinate planful activities with real-time behaviours for dealing with dynamic environments. In recent years, other architectures have been created with similar attributes but two features distinguish the 3T architecture: (1) a variety of useful software tools have been created to help implement this architecture on multiple real robots; and (2) this architecture, or parts of it, have been implemented on a variety of very different robot systems using different processors, operating systems, effectors and sensor suites.},
author = {Bonasso, Peter R. and Firby, Peter R. and Gat, Erann and Kortenkamp, David and Miller, David P. and Slack, Mark G.},
doi = {10.1080/095281397147103},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Journal of Experimental {\&} Theoretical Artificial Intelligence/1997/Bonasso et al. - 1997.pdf:pdf},
isbn = {0952813971},
issn = {0952-813X},
journal = {Journal of Experimental {\&} Theoretical Artificial Intelligence},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
number = {2-3},
pages = {237--256},
title = {{Experiences with an architecture for intelligent, reactive agents}},
url = {http://www.tandfonline.com/doi/abs/10.1080/095281397147103},
volume = {9},
year = {1997}
}
@article{Ivanitsky1996,
author = {Иваницкий, А. М.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Журнал высшей нервной деятельности/1996/Иваницкий - 1996.pdf:pdf},
journal = {Журнал высшей нервной деятельности},
language = {russian},
number = {2},
pages = {241--282},
title = {{Мозговая основа субъективных переживаний: гипотеза информационного синтеза}},
volume = {46},
year = {1996}
}
@article{Chernavsky2012a,
author = {Чернавская, О. Д. and Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Сложные системы/2012/Чернавская et al. - 2012(2).pdf:pdf},
journal = {Сложные системы},
language = {russian},
number = {3},
pages = {46--65},
title = {{Процесс мышления в контексте динамической теории информации. Часть II: понятие «образ» и «символ» как инструменты моделирования процесса мышления средствами нейрокомпьютинга}},
volume = {2},
year = {2012}
}
@incollection{Samsonovich2011,
abstract = {This short work is a follow-up on the review of the online Comparative Table of Cognitive Architectures, published in the BICA 2010 Proceedings. While the original review listed architectures and their features in one uniform format, the primary goal here is to go through feature-by-feature comparison across architectures and to see what features are shared, unique or missing in particular cases, in hope to understand what is needed in order to make a leap forward. This analysis is followed by consideration of the universal learner critical mass problem. {\textcopyright} 2011 The authors and IOS Press. All rights reserved.},
author = {Samsonovich, Alexei V.},
booktitle = {Biologically Inspired Cognitive Architectures 2011},
doi = {10.3233/978-1-60750-959-2-469},
editor = {Samsonovich, A.V. and Johannsdottir, K.R.},
isbn = {9781607509585},
issn = {09226389},
keywords = {Cognitive architectures,cog{\_}arch,critical mass,universal learner},
mendeley-tags = {cog{\_}arch},
pages = {469--479},
publisher = {IOS Press},
series = {Frontiers in Artificial Intelligence and Applications},
title = {{Comparative analysis of implemented cognitive architectures}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80155148671{\&}partnerID=tZOtx3y1},
year = {2011}
}
@inproceedings{DePenning2011,
abstract = {In real-world applications, the effective integration of learning and reasoning in a cognitive agent model is a difficult task. However, such integration may lead to a better understanding, use and con- struction of more realistic models. Unfortunately, existing models are either oversimplified or require much processing time, which is unsuitable for online learning and reasoning. Currently, con- trolled environments like training simulators do not effectively integrate learning and reasoning. In par- ticular, higher-order concepts and cognitive abili- ties have many unknown temporal relations with the data, making it impossible to represent such re- lationships by hand. We introduce a novel cogni- tive agent model and architecture for online learn- ing and reasoning that seeks to effectively repre- sent, learn and reason in complex training envi- ronments. The agent architecture of the model combines neural learning with symbolic knowledge representation. It is capable of learning new hy- potheses from observed data, and infers new be- liefs based on these hypotheses. Furthermore, it deals with uncertainty and errors in the data using a stochastic inference model in the spirit of Bayesian inference. The validation of the model on real-time simulations and the results presented here indicate the promise of the approach when performing online learning and reasoning in real-world scenar- ios, with possible applications in a range of areas.},
author = {de Penning, L. and d'Avila Garcez, A.S. and Lamb, Luis C. and Meyer, John-Jules},
booktitle = {Proceedings of the 20th International Joint Conference on Artificial Intelligence},
doi = {10.5591/978-1-57735-516-8/IJCAI11-278},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the 20th International Joint Conference on Artificial Intelligence/2011/de Penning et al. - 2011.pdf:pdf},
isbn = {978-1-57735-514-4},
pages = {1653--1658},
title = {{A Neural-Symbolic Cognitive Agent for Online Learning and Reasoning}},
year = {2011}
}
@inproceedings{Poudade2006,
author = {Poudade, Julien and Landwerlin, Lionel and Paroubek, Patrick},
booktitle = {ECAI 2006: 17th European Conference on Artificial Intelligence},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/ECAI 2006 17th European Conference on Artificial Intelligence/2006/Poudade, Landwerlin, Paroubek - 2006.pdf:pdf},
pages = {51--55},
title = {{Cognitive situated agents learn to name actions}},
year = {2006}
}
@article{Raghubir2006,
abstract = {This paper examines centrality of physical position as a cue that leads to systematic biases in people' decisions to retain or eliminate a participant from a group. Termed the "center-stage" effect, we argue that people use their belief that "important people sit in the middle" as a schematic cue that they substitute for individuating performance information for individuals who occupy central positions when the goal is to eliminate all but one of the group members. This leads to the errors of those in center-positions being overlooked: or making them the "centers-of-inattention." Study 1 examines people's lay beliefs regarding positions using two stylized placement tasks (a group interview and classroom seating scenarios). These suggest that people believe that more attention is paid to those in the center than those on the extremes. Study 2 tests the center-stage effect using observational data from a real television show, The Weakest Link. Results show that players assigned at random to central positions are more likely to win the game than those in extreme positions. Study 3, a laboratory experiment manipulating attention paid to the game shows that observers overlook the errors of players in the center to a greater extent than the errors of players in extreme positions. Study 4 replicates the game in the laboratory with direct process measures to show that players playing the game make the same error. Study 5 shows that in a stylized group interview setting, participants who believe that "important people sit in the middle" find the performance of candidates in the extreme position easier to recall than the performance of those in the central position, and are more likely to choose them. Study 6 shows that the "center-stage" effects are weaker when the end-game rule allows for two (vs one) contestants to be retained. Overall results converge to show that the use of the "center-stage" heuristic substitutes for the effortful processing of individuating information, leading to a biased (favorable) assessment of people in the center. Implications for decision-making are discussed. ?? 2005 Elsevier Inc. All rights reserved.},
author = {Raghubir, Priya and Valenzuela, Ana},
doi = {10.1016/j.obhdp.2005.06.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Organizational Behavior and Human Decision Processes/2006/Raghubir, Valenzuela - 2006.pdf:pdf},
isbn = {07495978},
issn = {07495978},
journal = {Organizational Behavior and Human Decision Processes},
keywords = {Perceptual biases,Performance appraisal,Salience effects,Visual information processing},
number = {1},
pages = {66--80},
title = {{Center-of-inattention: Position biases in decision-making}},
volume = {99},
year = {2006}
}
@article{Sokolov2004,
author = {Соколов, Е. Н.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Психология. Журнал Высшей школы экономики/2004/Соколов - 2004.pdf:pdf},
journal = {Психология. Журнал Высшей школы экономики},
language = {russian},
number = {2},
pages = {3--15},
title = {{Нейроны сознания}},
volume = {1},
year = {2004}
}
@article{Helie2014,
abstract = {This survey paper discusses the topic of autonomous learning in psychologically-oriented cognitive architectures and reviews some of the most popular cognitive architectures used in psychology, namely ACT-R, Soar, and Clarion. Autonomous learning is critical in the development of cognitive agents, and several learning-related desiderata useful for 'psychological' cognitive architectures are proposed. This article shows that all the reviewed cognitive architectures include some form of explicit ('symbolic') and implicit ('subsymbolic') learning. Additionally, ACT-R and Clarion are shown to include a top-down learning algorithm (from explicit to implicit), and Clarion also includes a bottom-up learning process (from implicit to explicit). Two simulation examples are presented with each cognitive architecture to illustrate the autonomous learning capacities of each modeling paradigm. While Clarion is more autonomous (requiring less a priori knowledge), Soar and ACT-R have so far been used in more complex tasks. The presentation concludes with some general considerations for future work. {\textcopyright} 2014 Elsevier Ltd.},
author = {H{\'{e}}lie, S{\'{e}}bastien and Sun, Ron},
doi = {10.1016/j.newideapsych.2014.03.002},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/New Ideas in Psychology/2014/H{\'{e}}lie, Sun - 2014.pdf:pdf},
isbn = {0732-118X},
issn = {0732118X},
journal = {New Ideas in Psychology},
month = {aug},
number = {1},
pages = {37--55},
title = {{Autonomous learning in psychologically-oriented cognitive architectures: A survey}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0732118X14000154},
volume = {34},
year = {2014}
}
@article{Lallee2013a,
abstract = {Understanding the world involves extracting the regularities that define the interaction of the behaving organism within this world, and computing the statistical structure characterizing these regularities. This can be based on contingencies of phenomena at various scales ranging from correlations between sensory signals (e.g., motor-proprioceptive loops) to high-level conceptual links (e.g., vocabulary grounding). Multiple cortical areas contain neurons whose receptive fields are tuned for signals co-occurring in multiple modalities. Moreover, the hierarchical organization of the cortex, described within the Convergence Divergence Zone framework, defines an ideal architecture to extract and make use of contingency at increasing levels of complexity. We present an artificial neural network model of the early cortical amodal computations, which we have demonstrated on the humanoid robot iCub. This model explains and predicts findings in neurophysiology and neuropsychology along with being an efficient tool to control the robot. In particular, through exploratory use of the body, the system learns a form of body schema in terms of specific modalities (e.g., arm proprioception, gaze proprioception, vision) and their multimodal contingencies. Once multimodal contingencies have been learned, the system is capable of generating and exploiting internal representations or mental images based on inputs in one of these multiple dimensions. The system thus provides insight on a possible neural substrate for mental imagery within the context of multimodal convergence.},
author = {Lallee, Stephane and {Ford Dominey}, Peter},
doi = {10.1177/1059712313488423},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Adaptive Behavior/2013/Lallee, Ford Dominey - 2013.pdf:pdf},
isbn = {1059712313488},
issn = {1059-7123},
journal = {Adaptive Behavior},
keywords = {NeuroModels,body schema,language,proprioception,robot,self-organizing map,vision},
mendeley-tags = {NeuroModels},
number = {4},
pages = {12},
title = {{Multi-modal convergence maps: From body schema and self-representation to mental imagery}},
volume = {21},
year = {2013}
}
@article{Chernigovskaya2008,
author = {Черниговская, Т В},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Разумное поведение и язык/2008/Черниговская - 2008.pdf:pdf},
journal = {Разумное поведение и язык},
language = {russian},
number = {1},
pages = {289--306},
title = {{Что делает нас людьми: почему непременно рекурсивные правила?}},
year = {2008}
}
@article{Izhikevich2008,
abstract = {The understanding of the structural and dynamic complexity of mammalian brains is greatly facilitated by computer simulations. We present here a detailed large-scale thalamocortical model based on experimental measures in several mammalian species. The model spans three anatomical scales. (i) It is based on global (white-matter) thalamocortical anatomy obtained by means of diffusion tensor imaging (DTI) of a human brain. (ii) It includes multiple thalamic nuclei and six-layered cortical microcircuitry based on in vitro labeling and three-dimensional reconstruction of single neurons of cat visual cortex. (iii) It has 22 basic types of neurons with appropriate laminar distribution of their branching dendritic trees. The model simulates one million multicompartmental spiking neurons calibrated to reproduce known types of responses recorded in vitro in rats. It has almost half a billion synapses with appropriate receptor kinetics, short-term plasticity, and long-term dendritic spike-timing-dependent synaptic plasticity (dendritic STDP). The model exhibits behavioral regimes of normal brain activity that were not explicitly built-in but emerged spontaneously as the result of interactions among anatomical and dynamic processes. We describe spontaneous activity, sensitivity to changes in individual neurons, emergence of waves and rhythms, and functional connectivity on different scales.},
author = {Izhikevich, Eugene M. and Edelman, Gerald M.},
doi = {10.1073/pnas.0712231105},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences of the United States of America/2008/Izhikevich, Edelman - 2008.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Action Potentials,Animals,Biological,Brain,Brain: anatomy {\&} histology,Cats,Cerebral Cortex,Cerebral Cortex: anatomy {\&} histology,Computer Simulation,Humans,Mammals,Models,Neurological,Neurons,Synapses,Thalamic Nuclei,Visual Cortex,Visual Cortex: anatomy {\&} histology},
number = {9},
pages = {3593--8},
pmid = {18292226},
title = {{Large-scale model of mammalian thalamocortical systems}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2265160{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {105},
year = {2008}
}
@unpublished{Shumsky2015a,
author = {Шумский, С. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Шумский - 2015.pdf:pdf},
language = {russian},
pages = {1--31},
title = {{Язык и мозг: как человек понимает речь}},
year = {2015}
}
@article{Corbetta2008,
abstract = {Survival can depend on the ability to change a current course of action to respond to potentially advantageous or threatening stimuli. This "reorienting" response involves the coordinated action of a right hemisphere dominant ventral frontoparietal network that interrupts and resets ongoing activity and a dorsal frontoparietal network specialized for selecting and linking stimuli and responses. At rest, each network is distinct and internally correlated, but when attention is focused, the ventral network is suppressed to prevent reorienting to distracting events. These different patterns of recruitment may reflect inputs to the ventral attention network from the locus coeruleus/norepinephrine system. While originally conceptualized as a system for redirecting attention from one object to another, recent evidence suggests a more general role in switching between networks, which may explain recent evidence of its involvement in functions such as social cognition.},
author = {Corbetta, Maurizio and Patel, Gaurav and Shulman, Gordon L},
doi = {10.1016/j.neuron.2008.04.017},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neuron/2008/Corbetta, Patel, Shulman - 2008.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Attention,Attention: physiology,Brain,Brain: physiology,Cognition,Cognition: physiology,Environment,Humans,Nerve Net,Nerve Net: physiology,Orientation,Orientation: physiology},
number = {3},
pages = {306--24},
pmid = {18466742},
title = {{The reorienting system of the human brain: from environment to theory of mind}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2441869{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {58},
year = {2008}
}
@article{Subagdja2015,
author = {Subagdja, Budhitama and Tan, Ah-Hwee},
doi = {10.1016/j.neucom.2015.02.038},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neurocomputing/2015/Subagdja, Tan - 2015.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Adaptive resonance theory,Episodic memory,Transitive inference},
pages = {1--14},
publisher = {Elsevier},
title = {{Neural modeling of sequential inferences and learning over episodic memory}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231215001873},
year = {2015}
}
@book{2004,
address = {М.},
editor = {Астапов, В. М. and Микадзе, Ю. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2004/Unknown - 2004.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2004/Unknown - 2004(2).pdf:pdf},
isbn = {5929201358},
language = {russian},
pages = {80},
publisher = {ПЕР СЭ},
title = {{Атлас ``Нервная система человека. Строение и нарушения''}},
year = {2004}
}
@article{Habenschuss2013,
abstract = {Experimental data from neuroscience suggest that a substantial amount of knowledge is stored in the brain in the form of probability distributions over network states and trajectories of network states. We provide a theoretical foundation for this hypothesis by showing that even very detailed models for cortical microcircuits, with data-based diverse nonlinear neurons and synapses, have a stationary distribution of network states and trajectories of network states to which they converge exponentially fast from any initial state. We demonstrate that this convergence holds in spite of the non-reversibility of the stochastic dynamics of cortical microcircuits. We further show that, in the presence of background network oscillations, separate stationary distributions emerge for different phases of the oscillation, in accordance with experimentally reported phase-specific codes. We complement these theoretical results by computer simulations that investigate resulting computation times for typical probabilistic inference tasks on these internally stored distributions, such as marginalization or marginal maximum-a-posteriori estimation. Furthermore, we show that the inherent stochastic dynamics of generic cortical microcircuits enables them to quickly generate approximate solutions to difficult constraint satisfaction problems, where stored knowledge and current inputs jointly constrain possible solutions. This provides a powerful new computing paradigm for networks of spiking neurons, that also throws new light on how networks of neurons in the brain could carry out complex computational tasks such as prediction, imagination, memory recall and problem solving.},
author = {Habenschuss, Stefan and Jonke, Zeno and Maass, Wolfgang},
doi = {10.1371/journal.pcbi.1003311},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS Computational Biology/2013/Habenschuss, Jonke, Maass - 2013.PDF:PDF},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {11},
pages = {e1003311},
pmid = {24244126},
title = {{Stochastic Computations in Cortical Microcircuit Models}},
volume = {9},
year = {2013}
}
@unpublished{Smith2015,
author = {Smith, J E},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Smith - 2015.pdf:pdf},
pages = {1--82},
title = {{Biologically Plausible Spiking Neural Networks}},
year = {2015}
}
@article{Pierce2009,
author = {Пирс, Ч. С.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Вестник Томского государственного университета/2009/Пирс - 2009.pdf:pdf},
journal = {Вестник Томского государственного университета},
keywords = {semiotics},
language = {russian},
mendeley-tags = {semiotics},
number = {3},
pages = {88--95},
title = {{Что такое знак}},
translator = {Аргамакова, А. А.},
volume = {7},
year = {2009}
}
@incollection{Engeler2008,
author = {Engeler, Erwin},
booktitle = {Algebraic Biology. Lecture Notes in Computer Science},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Algebraic Biology. Lecture Notes in Computer Science/2008/Engeler - 2008.pdf:pdf},
keywords = {combinatory algebra,emergent properties,functional structures,models of consciousness,neural nets},
pages = {96--109},
publisher = {Springer Berlin Heidelberg},
title = {{Neural Algebra and Consciousness : A Theory of Structural Functionality in Neural Nets}},
year = {2008}
}
@article{Frintrop2010,
author = {Frintrop, Simone and Rome, Erich and Christensen, Henrik I.},
doi = {10.1145/1658349.1658355},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/ACM Transactions on Applied Perception/2010/Frintrop, Rome, Christensen - 2010.pdf:pdf},
issn = {15443558},
journal = {ACM Transactions on Applied Perception},
number = {1},
pages = {1--39},
title = {{Computational visual attention systems and their cognitive foundations}},
url = {http://portal.acm.org/citation.cfm?doid=1658349.1658355},
volume = {7},
year = {2010}
}
@phdthesis{George2008,
author = {George, Dileep},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2008/George - 2008.pdf:pdf},
keywords = {htm},
mendeley-tags = {htm},
number = {June},
pages = {191},
school = {Stanford University},
title = {{How the Brain Might Work: a Hierarchical and Temporal Model for Learning and Recognition}},
year = {2008}
}
@article{Fu2014a,
author = {Fu, XiaoLan and Cai, LianHong and Liu, Ye YongJin and Jia, Jia and Chen, WenFeng and Yi, Zhang and Zhao, GuoZhen and Liu, Ye YongJin and Wu, ChangXu},
doi = {10.1007/s11432-013-4911-9},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Science China Information Sciences/2014/Fu et al. - 2014.pdf:pdf},
issn = {1674-733X},
journal = {Science China Information Sciences},
keywords = {NeuroModels,computational cognition model,judgment,memory,perception},
language = {english},
mendeley-tags = {NeuroModels},
number = {3},
pages = {1--15},
title = {{A computational cognition model of perception, memory, and judgment}},
url = {http://link.springer.com/10.1007/s11432-013-4911-9},
volume = {57},
year = {2014}
}
@article{Sorli2005,
author = {Sorli, Amrit and Sorli, Ilaria},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Electonic Journal of Theoretical Physics/2005/Sorli, Sorli - 2005.pdf:pdf},
journal = {Electonic Journal of Theoretical Physics},
keywords = {conscious experience,consciousness,rational experience,time,watching the mind},
pages = {1--5},
title = {{Consciousness as a Research Tool into Space and Time}},
volume = {6},
year = {2005}
}
@article{Lorincz2015b,
abstract = {Ever since the discovery of columnar structures, their function remained enigmatic. As a potential explanation for this puzzling function, we introduce the 'Columnar Machine'. We join two neural network types, Structured Sparse Coding (SSC) of generative nature exploiting sparse groups of neurons and Feed-Forward Networks (FFNs) into one architecture. Memories supporting recognition can be quickly loaded into SSC via supervision or can be learned by SSC in a self-organized manner. However, SSC evaluation is slow. We train FFNs for predicting the sparse groups and then the representation is computed by fast undercomplete methods. This two step procedure enables fast estimation of the overcomplete group sparse representations. The suggested architecture works fast and it is biologically plausible. Beyond the function of the minicolumnar structure it may shed light onto the role of fast feed-forward inhibitory thalamocortical channels and cortico-cortical feed-back connections. We demonstrate the method for natural image sequences where we exploit temporal structure and for a cognitive task where we explain the meaning of unknown words from their contexts.},
author = {Lorincz, Andras and Milacski, Zoltan and Pinter, Bal{\'{a}}zs and Vero, Anita L.},
doi = {10.1016/j.bica.2015.10.003},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2016/Lorincz et al. - 2016.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Feed-forward inhibition,Minicolumns,Sparsity,Structured representation},
pages = {19--33},
title = {{Columnar Machine: Fast estimation of structured sparse codes}},
volume = {15},
year = {2016}
}
@article{Erlich1997,
author = {Эрлих, А. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Программные продукты и системы/1997/Эрлих - 1997.pdf:pdf},
journal = {Программные продукты и системы},
language = {russian},
number = {3},
title = {{Прикладная семиотика и управление сложными объектами}},
year = {1997}
}
@book{Homskaya2015,
address = {СПб.},
author = {Хомская, Е. Д.},
edition = {4-е изд.},
language = {russian},
pages = {496},
publisher = {Питер},
title = {{Нейропсихология: Учебник для вузов}},
year = {2015}
}
@book{Luria1973,
author = {Luria, A.R.},
pages = {400},
publisher = {Basic Books},
title = {{The Working Brain: An Introduction To Neuropsychology}},
year = {1973}
}
@article{Navalpakkam2005,
abstract = {We propose a computational model for the task-specific guidance of visual attention in real-world scenes. Our model emphasizes four aspects that are important in biological vision: determining task-relevance of an entity, biasing attention for the low-level visual features of desired targets, recognizing these targets using the same low-level features, and incrementally building a visual map of task-relevance at every scene location. Given a task definition in the form of keywords, the model first determines and stores the task-relevant entities in working memory, using prior knowledge stored in long-term memory. It attempts to detect the most relevant entity by biasing its visual attention system with the entity's learned low-level features. It attends to the most salient location in the scene, and attempts to recognize the attended object through hierarchical matching against object representations stored in long-term memory. It updates its working memory with the task-relevance of the recognized entity and updates a topographic task-relevance map with the location and relevance of the recognized entity. The model is tested on three types of tasks: single-target detection in 343 natural and synthetic images, where biasing for the target accelerates target detection over twofold on average; sequential multiple-target detection in 28 natural images, where biasing, recognition, working memory and long term memory contribute to rapidly finding all targets; and learning a map of likely locations of cars from a video clip filmed while driving on a highway. The model's performance on search for single features and feature conjunctions is consistent with existing psychophysical data. These results of our biologically-motivated architecture suggest that the model may provide a reasonable approximation to many brain processes involved in complex task-driven visual behaviors.},
author = {Navalpakkam, Vidhya and Itti, Laurent},
doi = {10.1016/j.visres.2004.07.042},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Vision research/2005/Navalpakkam, Itti - 2005.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Attention,Attention: physiology,Cues,Humans,Memory,Memory: physiology,Models,Pattern Recognition,Psychological,Psychophysics,Recognition (Psychology),Recognition (Psychology): physiology,Visual,Visual Perception,Visual Perception: physiology},
number = {2},
pages = {205--31},
pmid = {15581921},
title = {{Modeling the influence of task on attention}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15581921},
volume = {45},
year = {2005}
}
@article{Manuscript2014a,
author = {Pfeiffer, Brad E. and Foster, David J.},
doi = {10.1038/nature12112.Hippocampal},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature/2013/Pfeiffer, Foster - 2013.pdf:pdf},
journal = {Nature},
number = {7447},
pages = {74--79},
title = {{Hippocampal place cell sequences depict future paths to remembered goals}},
volume = {497},
year = {2013}
}
@article{Chudova2014,
author = {Чудова, Н. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Искусственный интеллект и принятие решений/2014/Чудова - 2014.pdf:pdf},
journal = {Искусственный интеллект и принятие решений},
keywords = {12-07-00611,psycho},
language = {russian},
mendeley-tags = {12-07-00611,psycho},
number = {3},
pages = {40--45},
title = {{Переработка опыта как функция Образа мира}},
year = {2014}
}
@article{Cisek2007,
author = {Cisek, P.},
doi = {10.1098/rstb.2007.2054},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Philosophical Transactions of the Royal Society B Biological Sciences/2007/Cisek - 2007.pdf:pdf},
issn = {0962-8436},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {action selection,cerebral cortex,computational modelling,decision making},
number = {1485},
pages = {1585--1599},
title = {{Cortical mechanisms of action selection: the affordance competition hypothesis}},
url = {http://rstb.royalsocietypublishing.org/cgi/doi/10.1098/rstb.2007.2054},
volume = {362},
year = {2007}
}
@article{Thilakarathne2015,
author = {Thilakarathne, Dilhan J.},
doi = {10.1016/j.bica.2015.04.010},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2015/Thilakarathne - 2015(2).pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {prior and retrospective,situation awareness},
publisher = {Elsevier B.V.},
title = {{Modelling of situation awareness with perception, attention, and prior and retrospective awareness}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X15000195},
year = {2015}
}
@book{Velichkovsky2006a,
address = {М.},
author = {Величковский, Б. М.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2006/Величковский - 2006.pdf:pdf},
isbn = {5893572173},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {448},
publisher = {Смысл},
title = {{Когнитивная наука: Основы психологии познания: в 2 т.}},
volume = {1},
year = {2006}
}
@article{Itti2001,
abstract = {Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention.},
author = {Itti, L and Koch, C},
doi = {10.1038/35058500},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature reviews. Neuroscience/2001/Itti, Koch - 2001.pdf:pdf},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Attention,Attention: physiology,Computer Simulation,Humans,Models,Neurological,Neurons,Neurons: metabolism,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
number = {3},
pages = {194--203},
pmid = {11256080},
title = {{Computational modelling of visual attention}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11256080},
volume = {2},
year = {2001}
}
@article{Yan2014,
abstract = {The accessibility verification of the assembly/disassembly plays an important role in the process of product design. In the last decade, the sampling based motion planners have been successfully applied to solve the accessibility verification. However, the narrow passage which is a common problem in the assembly tasks is still a bottleneck. Meanwhile, the requirement of perception and emotion assessment drives the interaction between users and automatic path planners in the virtual assembly process. In this paper, a curve matching method is used to explore the implicit relationship between the topological information of scenarios and the motion of objects, based on which an interactive motion planning framework that can learn from experience is constructed. Our framework consists of two main processes: a learning process and a motion generation process. In the former process, the motion segment (a part of motion path) and its related scenario segment (a part of workspace passed through by the object) are gathered, after an interactive motion planning process finds a collision-free motion path or reaches the conclusion of inaccessibility. According to the similarity between the skeletons of scenario segments, the gathered scenario segments and motion segments are organized by a hierarchical structure in the motion library. The latter process permits users to control only one point in the workspace for the selection of a new scenario, and then the similar scenarios are retrieved from the motion library, to help quickly detect the connectivity of the new scenario and generate a repaired motion path to guide users with feasible manipulations. We highlight the performance of our framework on a challenging problem in 2D, in which a non-convex object passes through a cluttered environment filled with randomly shaped and located non-convex obstacles.},
author = {Yan, Yu and Poirson, Emilie and Bennis, Fouad},
doi = {10.1016/j.cad.2014.07.007},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Computer-Aided Design/2014/Yan, Poirson, Bennis - 2014.pdf:pdf},
issn = {00104485},
journal = {Computer-Aided Design},
keywords = {accessibility verification,assembly path planning},
pages = {23--38},
publisher = {Elsevier Ltd},
title = {{An interactive motion planning framework that can learn from experience}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0010448514001584},
volume = {59},
year = {2014}
}
@inproceedings{Osipov2015a,
abstract = {Рассматривается модель картины мира субъекта деятельности. Модель опирается на понятие знака (Пирс, Фреге, Поспелов), достаточно широко используемое в психологии, в частности, в культурно-исторической теории Л.С. Выготского. Показывается, что предложенная модель коррелирует с идеей повторного входа возбуждения в проекционную кору как основы психических функций, высказанной в работах А.М. Иваницкого (Иваницкий, 1976), Эдельмана (Эдельман, 1981), Дж. Десмедта и К.Томберга (1995), Дж. Грея (1995) и других. Для этого уточняется понятие знака, рассматриваются процедуры формирования знаков и самоорганизации на множестве знаков.},
author = {Осипов, Г. С.},
booktitle = {Нейронауки и благополучие общества: технологические, экономические, биомедицинские и гуманитарные аспекты: Сборник материалов конференции},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Нейронауки и благополучие общества технологические, экономические, биомедицинские и гуманитарные аспекты Сборник материалов конференции/2015/Осипов - 2015.pdf:pdf},
keywords = {15-07-06214,osipov},
language = {russian},
mendeley-tags = {15-07-06214,osipov},
pages = {103},
publisher = {РИЦ МГГУ им. М.А. Шолохова},
title = {{Знаковая модель картины мира и её нейрофизиологические основания}},
year = {2015}
}
@article{VandenHeuvel2013,
abstract = {The human brain shows several characteristics of an efficient communication network architecture, including short communication paths and the existence of modules interlinked by a small set of highly connected regions. Studies of structural networks comprising macroscopic white matter projections have shown that these putative hubs are densely interconnected, giving rise to a spatially distributed and topologically central collective called the “rich club.” In parallel, studies of intrinsic brain activity have consistently revealed distinct functional communities or resting-state networks (RSNs), indicative of specialized processing and segregation of neuronal information. However, the pattern of structural connectivity interconnecting these functional RSNs and how such inter-RSN structural connections might bring about functional integration between RSNs remain largely unknown. Combining high-resolution diffusion weighted imaging with resting-state fMRI, we present novel evidence suggesting that the rich club structure plays a central role in cross-linking macroscopic RSNs of the human brain. Rich club hub nodes were present in all functional networks, accounted for a large proportion of “connector nodes,” and were found to coincide with regions in which multiple networks overlap. In addition, a large proportion of all inter-RSN connections were found to involve rich club nodes, and these connections participated in a disproportionate number of communication paths linking nodes in different RSNs. Our findings suggest that the brain's rich club serves as a macroscopic anatomical substrate to cross-link functional networks and thus plays an important role in the integration of information between segregated functional domains of the human cortex.},
author = {van den Heuvel, M. P. and Sporns, O.},
doi = {10.1523/JNEUROSCI.2128-13.2013},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Journal of Neuroscience/2013/van den Heuvel, Sporns - 2013.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {36},
pages = {14489--14500},
title = {{An Anatomical Substrate for Integration among Functional Networks in Human Cortex}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2128-13.2013},
volume = {33},
year = {2013}
}
@unpublished{Project2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1505.02142v1},
author = {Billaudelle, Sebastian and Ahmad, Subutai},
eprint = {arXiv:1505.02142v1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Billaudelle, Ahmad - 2015.pdf:pdf},
keywords = {htm},
mendeley-tags = {htm},
pages = {1--10},
title = {{Porting HTM Models to the Heidelberg Neuromorphic Computing Platform}},
year = {2015}
}
@article{Wyatt2010,
author = {Wyatt, Jeremy L. and Aydemir, Alper and Brenner, Michael and Hanheide, Marc and Hawes, Nick and Jensfelt, Patric and Kristan, Matej and Kruijff, Geert-jan M. and Lison, Pierre and Pronobis, Andrzej and Sjoo, Kristoffer and Vrecko, Alen and Sj, Kristoffer and Zender, Hendrik and Zillich, Michael and Skocaj, Danijel},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/IEEE Transactions on Autonomous Mental Development/2010/Wyatt et al. - 2010.pdf:pdf},
journal = {IEEE Transactions on Autonomous Mental Development},
number = {4},
pages = {282--303},
title = {{Self-Understanding {\&} Self-Extension: A Systems and Representational Approach}},
volume = {2},
year = {2010}
}
@article{Tononi2015,
abstract = {The science of consciousness has made great strides by focusing on the be- havioural and neuronal correlates of experience. However, while such correlates are important for progress to occur, they are not enough if we are to understand even basic facts, for example, why the cerebral cortex gives rise to consciousness but the cerebellum does not, though it has even more neurons and appears to be just as complicated. Moreover, corre- lates are of little help in many instances where we would like to know if consciousness is present: patients with a few remaining islands of function- ing cortex, preterm infants, non-mammalian species and machines that are rapidly outperforming people at driving, recognizing faces and objects, and answering difficult questions. To address these issues, we need not only more data but also a theory of consciousness—one that says what experience is and what type of physical systems can have it. Integrated infor- mation theory (IIT) does so by starting from experience itself via five phenomenological axioms: intrinsic existence, composition, information, inte- gration and exclusion. From these it derives five postulates about the properties required of physical mechanisms to support consciousness. The theory provides a principled account of both the quantity and the quality of an individual experience (a quale), and a calculus to evaluate whether or not a particular physical system is conscious and of what. Moreover, IIT can explain a range of clinical and laboratory findings, makes a number of testable predictions and extrapolates to a number of problematic conditions. The theory holds that consciousness is a fundamental property possessed by physical systems having specific causal properties. It predicts that consciousness is graded, is common among biological organisms and can occur in some very simple systems. Conversely, it predicts that feed-for- ward networks, even complex ones, are not conscious, nor are aggregates such as groups of individuals or heaps of sand. Also, in sharp contrast to widespread functionalist beliefs, IIT implies that digital computers, even if their behaviour were to be functionally equivalent to ours, and even if they were to run faithful simulations of the human brain, would experience next to nothing.},
author = {Tononi, Giulio and Koch, Christof},
doi = {10.1098/rstb.2014.0167},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Philosophical Transactions of the Royal Society of London B Biological Sciences/2015/Tononi, Koch - 2015.pdf:pdf},
journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
keywords = {awareness,causation,cerebral cortex,consciousness,existence,mind body problem,neuronal correlates of consciousness},
mendeley-tags = {consciousness},
number = {1668},
pages = {20140167},
title = {{Consciousness: here, there and everywhere?}},
volume = {370},
year = {2015}
}
@book{Luria2003,
address = {М.},
author = {Лурия, A. Р.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2003/Лурия - 2003.pdf:pdf},
isbn = {5769510137},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {384},
publisher = {Издательский центр Академия},
title = {{Основы нейропсихологии}},
year = {2003}
}
@book{Leontyev2009,
abstract = {this is a compendium of most of Leontyev's work.},
address = {Kettering},
author = {Leontyev, A. N.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2009/Leontyev - 2009.pdf:pdf},
isbn = {9780980542868},
keywords = {psycho},
mendeley-tags = {psycho},
pages = {428},
publisher = {Erythros Press and Media},
title = {{The Development of Mind}},
url = {http://marxists.org/archive/leontev/works/development-mind.pdf},
year = {2009}
}
@article{Fischer2012,
abstract = {There is much recent interest in the idea that we represent our knowledge together with the sensory and motor features that were activated during its acquisition. This paper reviews the evidence for such "embodiment" in the domain of numerical cognition, a traditional stronghold of abstract theories of knowledge representation. The focus is on spatial-numerical associations, such as the SNARC effect (small numbers are associated with left space, larger numbers with right space). Using empirical evidence from behavioral research, I first describe sensory and motor biases induced by SNARC, thus identifying numbers as embodied concepts. Next, I propose a hierarchical relationship between grounded, embodied, and situated aspects of number knowledge. This hierarchical conceptualization helps to understand the variety of SNARC-related findings and yields testable predictions about numerical cognition. I report several such tests, ranging from cross-cultural comparisons of horizontal and vertical SNARC effects (Shaki and Fischer in J Exp Psychol Hum Percept Perform 38(3):804-809, 2012) to motor cortical activation studies in adults with left- and right-hand counting preferences (Tschentscher et al. in NeuroImage 59:3139-3148, 2012). It is concluded that the diagnostic features for each level of the proposed hierarchical knowledge representation, together with the spatial associations of numbers, make the domain of numerical knowledge an ideal testing ground for embodied cognition research.},
author = {Fischer, Martin H.},
doi = {10.1007/s10339-012-0477-5},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Processing/2012/Fischer - 2012.pdf:pdf},
isbn = {1612-4790 (Electronic)},
issn = {16124782},
journal = {Cognitive Processing},
keywords = {Embodied cognition,Grounded cognition,Numerical cognition,SNARC effect},
pages = {161--164},
pmid = {22802036},
title = {{A hierarchical view of grounded, embodied, and situated numerical cognition}},
volume = {13},
year = {2012}
}
@article{Mensky2005,
author = {Менский, М. Б.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/2005/Менский - 2005.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {4},
pages = {413--435},
title = {{Концепция сознания в контексте квантовой механики}},
volume = {175},
year = {2005}
}
@article{Paraense2016,
abstract = {In this work, we present a distributed cognitive architecture used to control the traffic in an urban network. This architecture relies on a machine consciousness approach – Global Work- space Theory – in order to use competition and broadcast, allowing a group of local traffic con- trollers to interact, resulting in a better group performance. The main idea is that the local controllers usually perform a purely reactive behavior, defining the times of red and green lights, according just to local information. These local controllers compete in order to define which of them is experiencing the most critical traffic situation. The controller in the worst condition gains access to the global workspace, further broadcasting its condition (and its loca- tion) to all other controllers, asking for their help in dealing with its situation. This call from the controller accessing the global workspace will cause an interference in the reactive local behavior, for those local controllers with some chance in helping the controller in a critical con- dition, by containing traffic in its direction. This group behavior, coordinated by the global workspace strategy, turns the once reactive behavior into a kind of deliberative one. We show that this strategy is capable of improving the overall mean travel time of vehicles flowing through the urban network. A consistent gain in performance with the ‘‘Artificial Consciousness” traffic signal controller during all simulation time, throughout different simulated scenarios, could be observed, ranging from around 13.8{\%} to more than 21{\%}.},
author = {Paraense, Andr{\'{e}} Luis O. and Raizer, Klaus and Gudwin, Ricardo R.},
doi = {10.1016/j.bica.2015.10.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2016/Paraense, Raizer, Gudwin - 2016.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {consciousness,global workspace theory,machine consciousness,traffic lights control},
mendeley-tags = {consciousness},
pages = {61--73},
title = {{A machine consciousness approach to urban traffic control}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X15000614},
volume = {15},
year = {2016}
}
@article{Lochmann2011,
abstract = {Perception is about making sense, that is, understanding what events in the outside world caused the sensory observations. Consistent with this intuition, many aspects of human behavior confronting noise and ambiguity are well explained by principles of causal inference. Extending these insights, recent studies have applied the same powerful set of tools to perceptual processing at the neural level. According to these approaches, microscopic neural structures solve elementary probabilistic tasks and can be combined to construct hierarchical predictive models of the sensory input. This framework suggests that variability in neural responses reflects the inherent uncertainty associated with sensory interpretations and that sensory neurons are active predictors rather than passive filters of their inputs. Causal inference can account parsimoniously and quantitatively for non-linear dynamical properties in single synapses, single neurons and sensory receptive fields.},
author = {Lochmann, Timm and Deneve, Sophie},
doi = {10.1016/j.conb.2011.05.018},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Current opinion in neurobiology/2011/Lochmann, Deneve - 2011.pdf:pdf},
issn = {1873-6882},
journal = {Current opinion in neurobiology},
keywords = {Action Potentials,Action Potentials: physiology,Cerebral Cortex,Cerebral Cortex: cytology,Concept Formation,Concept Formation: physiology,Humans,Models,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurological,Perception,Perception: physiology,Probability,Sensation,Sensory Receptor Cells,Sensory Receptor Cells: physiology},
number = {5},
pages = {774--81},
pmid = {21742484},
publisher = {Elsevier Ltd},
title = {{Neural processing as causal inference}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21742484},
volume = {21},
year = {2011}
}
@misc{Bialek2002,
abstract = {We all are fascinated by the phenomena of intelligent behavior, as generated both by our own brains and by the brains of other animals. As physicists we would like to understand if there are some general principles that govern the structure and dynamics of the neural circuits that underlie these phenomena. At the molecular level there is an extraordinary universality, but these mechanisms are surprisingly complex. This raises the question of how the brain selects from these diverse mechanisms and adapts to compute "the right thing" in each context. One approach is to ask what problems the brain really solves. There are several examples - from the ability of the visual system to count photons on a dark night to our gestalt recognition of statistical tendencies toward symmetry in random patterns - where the performance of the system in fact approaches some fundamental physical or statistical limits. This suggests that some sort of optimization principles may be at work, and there are examples where these principles have been formulated clearly and generated predictions which are confirmed in new experiments; a central theme in this work is the matching of the coding and computational strategies of the brain to the statistical structure of the world around us. Extension of these principles to the problem of learning leads us into interesting theoretical questions about how to measure the complexity of the data from which we learn and the complexity of the models that we use in learning, as well as opening some new opportunities for experiment. This combination of theoretical and experimental work gives us some new (if still speculative) perspectives on classical problems and controversies in cognition.},
archivePrefix = {arXiv},
arxivId = {physics/0205030},
author = {Bialek, William},
booktitle = {http://arxiv.org/abs/physics/0205030},
eprint = {0205030},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/httparxiv.orgabsphysics0205030/2002/Bialek - 2002.pdf:pdf},
number = {July 2001},
pages = {1--85},
primaryClass = {physics},
title = {{Thinking about the brain}},
url = {http://arxiv.org/abs/physics/0205030},
urldate = {2014-09-27},
year = {2002}
}
@inproceedings{Rohrbein2007,
author = {Rohrbein, Florian and Eggert, Julian and Korner, Edgar},
booktitle = {ICCM-2007-Eighth International Conference on Cognitivy Modeling},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/ICCM-2007-Eighth International Conference on Cognitivy Modeling/2007/Rohrbein, Eggert, Korner - 2007.pdf:pdf},
keywords = {biologically,columnar-like nodes and do,cortical column,detailed modeling of the,knowledge representation,not target at a,relational structures,single cortical column,the},
pages = {307--312},
title = {{Prototypical Relations for Cortex-Inspired Semantic Representations}},
year = {2007}
}
@incollection{Kawato2009,
author = {Kawato, M.},
booktitle = {Encyclopedia of Neuroscience},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Encyclopedia of Neuroscience/2009/Kawato - 2009.pdf:pdf},
pages = {757--767},
title = {{Cerebellum: Models}},
volume = {2},
year = {2009}
}
@book{Aimone2014,
abstract = {The discovery of new cell types, such as grid and time cells, in the hippocampal formation has been accompanied by major anatomical and theoretical insights in the years. This book provides comprehensive, up-to-date information ...},
author = {Aimone, James B and Deng, Wei and Gage, Fred H},
booktitle = {Space, Time and Memory in the Hippocampal Formation},
doi = {10.1007/978-3-7091-1292-2},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Space, Time and Memory in the Hippocampal Formation/2014/Aimone, Deng, Gage - 2014.pdf:pdf},
isbn = {978-3-7091-1291-5},
pages = {409--429},
title = {{Space,Time and Memory in the Hippocampal Formation}},
url = {http://link.springer.com/10.1007/978-3-7091-1292-2},
year = {2014}
}
@article{Binder2011,
abstract = {Semantic memory includes all acquired knowledge about the world and is the basis for nearly all human activity, yet its neurobiological foundation is only now becoming clear. Recent neuroimaging studies demonstrate two striking results: the participation of modality-specific sensory, motor, and emotion systems in language comprehension, and the existence of large brain regions that participate in comprehension tasks but are not modality-specific. These latter regions, which include the inferior parietal lobe and much of the temporal lobe, lie at convergences of multiple perceptual processing streams. These convergences enable increasingly abstract, supramodal representations of perceptual experience that support a variety of conceptual functions including object recognition, social cognition, language, and the remarkable human capacity to remember the past and imagine the future.},
author = {Binder, Jeffrey R. and Desai, Rutvik H.},
doi = {10.1016/j.tics.2011.10.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in cognitive sciences/2011/Binder, Desai - 2011.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Animals,Brain,Brain Mapping,Brain: anatomy {\&} histology,Brain: physiology,Humans,Memory,Memory: physiology,Neurobiology,Semantics,Verbal Learning,Verbal Learning: physiology},
number = {11},
pages = {527--36},
pmid = {22001867},
publisher = {Elsevier Ltd},
title = {{The neurobiology of semantic memory}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3350748{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {15},
year = {2011}
}
@article{Chalita2016,
author = {Chalita, Mario Andr{\'{e}}s and Lis, Diego and Caverzasi, Agust{\'{i}}n},
doi = {10.1016/j.bica.2016.03.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2016/Chalita, Lis, Caverzasi - 2016.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {reinforcement learning},
pages = {45--63},
title = {{Reinforcement learning in a bio-connectionist model based in the thalamo-cortical neural circuit}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X16300159},
year = {2016}
}
@incollection{Vityaev1997,
address = {Новосибирск},
author = {Витяев, Е. Е.},
booktitle = {Модели когнитивных процессов},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Модели когнитивных процессов/1997/Витяев - 1997.pdf:pdf},
language = {russian},
pages = {9--52},
publisher = {Институт математики им. С.Л. Соболев},
series = {Вычислительные системы},
title = {{Целеполагание как принцип работы мозга}},
year = {1997}
}
@article{Litvak2009,
abstract = {In this letter, we develop and simulate a large-scale network of spiking neurons that approximates the inference computations performed by graphical models. Unlike previous related schemes, which used sum and product operations in either the log or linear domains, the current model uses an inference scheme based on the sum and maximization operations in the log domain. Simulations show that using these operations, a large-scale circuit, which combines populations of spiking neurons as basic building blocks, is capable of finding close approximations to the full mathematical computations performed by graphical models within a few hundred milliseconds. The circuit is general in the sense that it can be wired for any graph structure, it supports multistate variables, and it uses standard leaky integrate-and-fire neuronal units. Following previous work, which proposed relations between graphical models and the large-scale cortical anatomy, we focus on the cortical microcircuitry and propose how anatomical and physiological aspects of the local circuitry may map onto elements of the graphical model implementation. We discuss in particular the roles of three major types of inhibitory neurons (small fast-spiking basket cells, large layer 2/3 basket cells, and double-bouquet neurons), subpopulations of strongly interconnected neurons with their unique connectivity patterns in different cortical layers, and the possible role of minicolumns in the realization of the population-based maximum operation.},
author = {Litvak, Shai and Ullman, Shimon},
doi = {10.1162/neco.2009.05-08-783},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural computation/2009/Litvak, Ullman - 2009.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
number = {11},
pages = {3010--3056},
pmid = {19686065},
title = {{Cortical circuitry implementing graphical models}},
volume = {21},
year = {2009}
}
@article{Sandamirskaya2013,
abstract = {Dynamic Field Theory (DFT) is an established framework for modeling embodied cognition. In DFT, elementary cognitive functions such as memory formation, formation of grounded representations, attentional processes, decision making, adaptation, and learning emerge from neuronal dynamics. The basic computational element of this framework is a Dynamic Neural Field (DNF). Under constraints on the time-scale of the dynamics, the DNF is computationally equivalent to a soft winner-take-all (WTA) network, which is considered one of the basic computational units in neuronal processing. Recently, it has been shown how a WTA network may be implemented in neuromorphic hardware, such as analog Very Large Scale Integration (VLSI) device. This paper leverages the relationship between DFT and soft WTA networks to systematically revise and integrate established DFT mechanisms that have previously been spread among different architectures. In addition, I also identify some novel computational and architectural mechanisms of DFT which may be implemented in neuromorphic VLSI devices using WTA networks as an intermediate computational layer. These specific mechanisms include the stabilization of working memory, the coupling of sensory systems to motor dynamics, intentionality, and autonomous learning. I further demonstrate how all these elements may be integrated into a unified architecture to generate behavior and autonomous learning.},
author = {Sandamirskaya, Yulia},
doi = {10.3389/fnins.2013.00276},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in neuroscience/2014/Sandamirskaya - 2014.pdf:pdf},
issn = {1662-4548},
journal = {Frontiers in neuroscience},
keywords = {Dynamic Neural Fields,autonomous learning,cognitive neuromorphic architecture,neural dynamics,soft winner take all},
pages = {276},
pmid = {24478620},
title = {{Dynamic neural fields as a step toward cognitive neuromorphic architectures}},
url = {http://journal.frontiersin.org/Journal/10.3389/fnins.2013.00276/abstract$\backslash$nhttp://www.ncbi.nlm.nih.gov/pmc/articles/PMC3898057/},
volume = {7},
year = {2014}
}
@article{Sun2006,
abstract = {This paper describes how meta-cognitive processes (i.e., the self monitoring and regulating of cognitive processes) may be captured within a cognitive architecture Clarion. Some currently popular cognitive architectures lack sufficiently complex built-in meta-cognitive mechanisms. However, a sufficiently complex meta-cognitive mechanism is important, in that it is an essential part of cognition and without it, human cognition may not function properly. We contend that such a meta-cognitive mechanism should be an integral part of a cognitive architecture. Thus, such a mechanism has been developed within the Clarion cognitive architecture. The paper demonstrates how human data of two meta-cognitive experiments are simulated using Clarion. The simulations show that the meta-cognitive processes represented by the experimental data (and beyond) can be adequately captured within the Clarion framework. ?? 2005 Elsevier B.V. All rights reserved.},
author = {Sun, Ron and Zhang, Xi and Mathews, Robert},
doi = {10.1016/j.cogsys.2005.09.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Systems Research/2006/Sun, Zhang, Mathews - 2006.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {Cognitive modeling,Metacognition,Neural networks},
number = {4},
pages = {327--338},
title = {{Modeling meta-cognition in a cognitive architecture}},
volume = {7},
year = {2006}
}
@article{Dehaene2014,
author = {Dehaene, Stanislas and Charles, Lucie and King, Jean-R{\'{e}}mi and Marti, S{\'{e}}bastien},
doi = {10.1016/j.conb.2013.12.005},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Current Opinion in Neurobiology/2014/Dehaene et al. - 2014.pdf:pdf},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {1947},
pages = {76--84},
title = {{Toward a computational theory of conscious processing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0959438813002298},
volume = {25},
year = {2014}
}
@article{Goertzel2009,
abstract = {We describe an integrative cognitive architecture for human-like, human-level, embodied general intelligence, founded on integrating the OpenCogPrime framework for cognition, language and high-level learning with a hierarchical temporal memory for lower-level perception and action. The core conceptual principle of the architecture is "cognitive synergy", wherein different components are specifically integrated in such a way as to compensate for each others scalability weaknesses. The current, preliminary implementation of the architecture to control a Nao robot is described, and contrasted with prior work using OpenCogPrime to control virtual agents in virtual worlds; and future plans for achieving greater intelligence via instructing the Nao in a "robot preschool" context are reviewed.},
author = {Goertzel, Ben and Garis, Hugo De and Pennachin, Cassio and Geisweiller, Nil},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of ICCI-09/2009/Goertzel et al. - 2009.pdf:pdf},
journal = {Proceedings of ICCI-09},
pages = {1--12},
title = {{Opencog prime: A cognitive synergy based architecture for embodied artificial general intelligence}},
year = {2009}
}
@article{Kim2013,
author = {Kim, Jong-Hwan and Choi, Seung-Hwan and Park, In-Won and Zaheer, Sheir Afgen},
doi = {10.1109/MCI.2013.2264573},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/IEEE Computational Intelligence Magazine/2013/Kim et al. - 2013.pdf:pdf},
journal = {IEEE Computational Intelligence Magazine},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
number = {3},
pages = {70--84},
title = {{Intelligence Technology for Robots That Think}},
volume = {8},
year = {2013}
}
@article{Chernavsky2012b,
author = {Чернавская, О. Д. and Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Сложные системы/2012/Чернавская et al. - 2012.pdf:pdf},
journal = {Сложные системы},
language = {russian},
number = {2},
pages = {25--41},
title = {{Процесс мышления в контексте динамической теории информации. Часть I. Цели и задачи мышления}},
volume = {1},
year = {2012}
}
@article{Klampfl2013,
abstract = {Numerous experimental data suggest that simultaneously or sequentially activated assemblies of neurons play a key role in the storage and computational use of long-term memory in the brain. However, a model that elucidates how these memory traces could emerge through spike-timing-dependent plasticity (STDP) has been missing. We show here that stimulus-specific assemblies of neurons emerge automatically through STDP in a simple cortical microcircuit model. The model that we consider is a randomly connected network of well known microcircuit motifs: pyramidal cells with lateral inhibition. We show that the emergent assembly codes for repeatedly occurring spatiotemporal input patterns tend to fire in some loose, sequential manner that is reminiscent of experimentally observed stereotypical trajectories of network states. We also show that the emergent assembly codes add an important computational capability to standard models for online computations in cortical microcircuits: the capability to integrate information from long-term memory with information from novel spike inputs.},
author = {Klampfl, Stefan and Maass, Wolfgang},
doi = {10.1523/JNEUROSCI.5044-12.2013},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/The Journal of neuroscience the official journal of the Society for Neuroscience/2013/Klampfl, Maass - 2013.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {1529-2401},
journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Memory,Memory: physiology,Models,Neural Networks (Computer),Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology},
number = {28},
pages = {11515--11529},
pmid = {23843522},
title = {{Emergence of dynamic memory traces in cortical microcircuit models through STDP.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23843522},
volume = {33},
year = {2013}
}
@article{Ring2011,
abstract = {This paper addresses the problem of continual learning [1] in a new way, combining multi-modular reinforcement learning with inspiration from the motor cortex to produce a unique perspective on hierarchical behavior. Most reinforcement-learning agents represent policies monolithically using a single table or function approximator. In those cases where the policies are split among a few different modules, these modules are related to each other only in that they work together to produce the agent's overall policy. In contrast, the brain appears to organize motor behavior in a two-dimensional map, where nearby locations represent similar behaviors. This representation allows the brain to build hierarchies of motor behavior that correspond not to hierarchies of subroutines but to regions of the map such that larger regions correspond to more general behaviors. Inspired by the benefits of the brain's representation, the system presented here is a first step and the first attempt toward the two-dimensional organization of learned policies according to behavioral similarity. We demonstrate a fully autonomous multi-modular system designed for the constant accumulation of ever more sophisticated skills (the continual-learning problem). The system can split up a complex task among a large number of simple modules such that nearby modules correspond to similar policies. The eventual goal is to develop and use the resulting organization hierarchically, accessing behaviors by their location and extent in the map.},
author = {Ring, Mark and Schaul, Tom and Schmidhuber, Juergen},
doi = {10.1109/DEVLRN.2011.6037326},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/2011 IEEE International Conference on Development and Learning, ICDL 2011/2011/Ring, Schaul, Schmidhuber - 2011.pdf:pdf},
isbn = {9781612849904},
issn = {2161-9476},
journal = {2011 IEEE International Conference on Development and Learning, ICDL 2011},
pages = {1--8},
title = {{The two-dimensional organization of behavior}},
volume = {2},
year = {2011}
}
@article{DePaula2015,
abstract = {A standard approach in the simulation of language evolution is the use of Language Games to model communicative interactions between intelligent agents. Usually, in such language games, an agent uses the results from its perceptual layer to categorize and to conceptualize world objects, a process named categorization. In this paper, we develop an approach to the categorization process, where the decomposition of reality in meaningful experiences is co- evolved with the lexicon formation in the language game. This approach brings some insights on how meaning might be assigned to symbols, in a dynamic and continuously changing environ- ment being experienced by an agent. In order to do that, we use Barsalou's notion of mental simulation and Ga ¨rdenfors' notion of conceptual spaces such that, together with ESOM neural networks, a cognitive architecture can be developed, where mental concepts formation and lexicon formation are able to co-evolve during a language game. The performance of our cog- nitive architecture is evaluated and the results show that the architecture is able to fulfill its semantics function, by allowing a population of agents to exchange the meaning of linguistic symbols during a naming game, without relying on ‘‘a priori” categorization scheme provided by an external expert or a set of examples for training a neural network in a previous discrim- ination game. These results, beyond bringing evidence on potential ways for symbols to get meaning on a biologically realistic way, open a set of possibilities for further uses of conceptual spaces on a much more complex problem: the grounding of a grammatical language.},
author = {de Paula, Suelen M. and Gudwin, Ricardo R.},
doi = {10.1016/j.bica.2015.09.006},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2015/de Paula, Gudwin - 2015.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
pages = {73--85},
publisher = {Elsevier B.V.},
title = {{Evolving conceptual spaces for symbol grounding in language games}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X15000493},
volume = {14},
year = {2015}
}
@inproceedings{Drix2014,
author = {Drix, Damien and Hafner, Verena V},
booktitle = {Joint IEEE International Conference on Development and Learning},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Joint IEEE International Conference on Development and Learning/2014/Drix, Hafner - 2014.pdf:pdf},
isbn = {9781479975402},
pages = {374--378},
title = {{Learning proprioceptive and motor features}},
year = {2014}
}
@article{Fallis2013,
author = {Петровский, В. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Московский психотерапевтический журнал/2008/Петровский - 2008.pdf:pdf},
journal = {Московский психотерапевтический журнал},
keywords = {icle},
number = {1},
pages = {64--90},
title = {{Индивидуальность, саморегуляция, гармония}},
year = {2008}
}
@article{John2013,
abstract = {The classical dichotomy between cognition and emotion equated the first with rationality or logic and the second with irrational behaviors. The idea that cognition and emotion are separable, antagonistic forces competing for dominance of mind has been hard to displace despite abundant evidence to the contrary. For instance, it is now known that a pathological absence of emotion leads to profound impairment of decision making. Behavioral observations of this kind are corroborated at the mechanistic level: neuroanatomical studies reveal that brain areas typically described as underlying either cognitive or emotional processes are linked in ways that imply complex interactions that do not resemble a simple mutual antagonism. Instead, physiological studies and network simulations suggest that top-down signals from prefrontal cortex realize "cognitive control" in part by either suppressing or promoting emotional responses controlled by the amygdala, in a way that facilitates adaptation to changing task demands. Behavioral, anatomical, and physiological data suggest that emotion and cognition are equal partners in enabling a continuum or matrix of flexible behaviors that are subserved by multiple brain regions acting in concert. Here we focus on neuroanatomical data that highlight circuitry that structures cognitive-emotional interactions by directly or indirectly linking prefrontal areas with the amygdala. We also present an initial computational circuit model, based on anatomical, physiological, and behavioral data to explicitly frame the learning and performance mechanisms by which cognition and emotion interact to achieve flexible behavior.},
author = {John, Yohan J and Bullock, Daniel and Zikopoulos, Basilis and Barbas, Helen},
doi = {10.3389/fnhum.2013.00101},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in human neuroscience/2013/John et al. - 2013.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {1,amygdala,cognition,cognition into adaptive perception-action,computational neuroscience,emotions,integrating emotion and,introduction,network,neural,neuroanatomy,ofc,orbitofrontal cortex,orbitofrontal cortex (OFC),thalamic ret,thalamic reticular nucleus},
number = {April},
pages = {101},
pmid = {23565082},
title = {{Anatomy and computational modeling of networks underlying cognitive-emotional interaction}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3613599{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2013}
}
@incollection{Gippenreiter1998b,
address = {М.},
author = {Гиппенрейтер, Ю. Б.},
booktitle = {Введение в общую психологию. Курс лекций},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Введение в общую психологию. Курс лекций/1998/Гиппенрейтер - 1998(2).pdf:pdf},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
title = {{Психологическа теори де тельности. [Мотивационный аспект]}},
year = {1998}
}
@article{Tkacheva2010,
author = {Ткачева, Л. О.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Вестник СПбГУ/2010/Ткачева - 2010.pdf:pdf},
journal = {Вестник СПбГУ},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
number = {2},
pages = {378--387},
title = {{Воздействие фрактальных динамических изображений на функциональное состояние человека}},
volume = {12},
year = {2010}
}
@article{Alexander2011,
abstract = {The medial prefrontal cortex (mPFC) and especially anterior cingulate cortex is central to higher cognitive function and many clinical disorders, yet its basic function remains in dispute. Various competing theories of mPFC have treated effects of errors, conflict, error likelihood, volatility and reward, using findings from neuroimaging and neurophysiology in humans and monkeys. No single theory has been able to reconcile and account for the variety of findings. Here we show that a simple model based on standard learning rules can simulate and unify an unprecedented range of known effects in mPFC. The model reinterprets many known effects and suggests a new view of mPFC, as a region concerned with learning and predicting the likely outcomes of actions, whether good or bad. Cognitive control at the neural level is then seen as a result of evaluating the probable and actual outcomes of one's actions.},
author = {Alexander, William H and Brown, Joshua W},
doi = {10.1038/nn.2921},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature neuroscience/2011/Alexander, Brown - 2011.pdf:pdf},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Animals,Brain Mapping,Choice Behavior,Choice Behavior: physiology,Cognition,Cognition: physiology,Computer Simulation,Computer-Assisted,Conflict (Psychology),Humans,Image Processing,Magnetic Resonance Imaging,Models,Movement,Movement: physiology,Neurological,Oxygen,Oxygen: blood,Photic Stimulation,Predictive Value of Tests,Prefrontal Cortex,Prefrontal Cortex: blood supply,Prefrontal Cortex: physiology,Reward,Time Factors,Visual Perception},
number = {10},
pages = {1338--44},
pmid = {21926982},
publisher = {Nature Publishing Group},
title = {{Medial prefrontal cortex as an action-outcome predictor}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3183374{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {14},
year = {2011}
}
@article{Trafton2013,
abstract = {We presentACT-R/E (Adaptive Character of Thought-Rational / Embodied), a cognitive architecture for human-robot interaction. Our reason for using ACT-R/E is two-fold. First, ACT-R/E enables researchers to build good embodied models of people to understand how and why people think the way they do. Then, we leverage that knowledge of people by using it to predict what a person will do in different situations; e.g., that a person may forget something and may need to be reminded or that a person cannot see everything the robot sees. We also discuss methods of how to evaluate a cognitive architecture and show numerous, empirically validated examples of ACT-R/E models.},
author = {Trafton, Gregory J. and Hiatt, Laura M. and Harrison, Anthony M. and Tamborello, Franklin P. and Khemlani, Sangeet S. and Schultz, Alan C.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Journal of Human-Robot Interaction/2013/Trafton et al. - 2013.pdf:pdf},
issn = {21630364},
journal = {Journal of Human-Robot Interaction},
keywords = {Human-robot interaction,cognitive architectures,cognitive modeling},
number = {1},
pages = {30--54},
title = {{ACT-R/E: An embodied cognitive architecture for Human-Robot Interaction}},
volume = {2},
year = {2013}
}
@article{Parkhurst2002,
abstract = {A biologically motivated computational model of bottom-up visual selective attention was used to examine the degree to which stimulus salience guides the allocation of attention. Human eye movements were recorded while participants viewed a series of digitized images of complex natural and artificial scenes. Stimulus dependence of attention, as measured by the correlation between computed stimulus salience and fixation locations, was found to be significantly greater than that expected by chance alone and furthermore was greatest for eye movements that immediately follow stimulus onset. The ability to guide attention of three modeled stimulus features (color, intensity and orientation) was examined and found to vary with image type. Additionally, the effect of the drop in visual sensitivity as a function of eccentricity on stimulus salience was examined, modeled, and shown to be an important determiner of attentional allocation. Overall, the results indicate that stimulus-driven, bottom-up mechanisms contribute significantly to attentional guidance under natural viewing conditions.},
author = {Parkhurst, Derrick and Law, Klinton and Niebur, Ernst},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Vision research/2002/Parkhurst, Law, Niebur - 2002.pdf:pdf},
issn = {0042-6989},
journal = {Vision research},
keywords = {Analysis of Variance,Attention,Attention: physiology,Biological,Computer Simulation,Eye Movements,Eye Movements: physiology,Female,Humans,Male,Models,Normal Distribution,Visual Perception,Visual Perception: physiology},
number = {1},
pages = {107--23},
pmid = {11804636},
title = {{Modeling the role of salience in the allocation of overt visual attention}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11804636},
volume = {42},
year = {2002}
}
@article{Damerow2016,
abstract = {Most current approaches to scene understanding lack the capability to adapt object and situation models to behavioral needs not anticipated by the human system designer. Here, we give a detailed description of a system architecture for self-referential autonomous learning which enables the refinement of object and situation models during operation in order to optimize behavior. This includes structural learning of hierarchical models for situations and behaviors that is triggered by a mismatch between expected and actual action outcome. Besides proposing architectural concepts, we also describe a first implementation of our system within a simulated traffic scenario to demonstrate the feasibility of our approach.},
author = {Damerow, Florian and Knoblauch, Andreas and K{\"{o}}rner, Ursula and Eggert, Julian and K{\"{o}}rner, Edgar},
doi = {10.1007/s12559-016-9407-7},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Computation/2016/Damerow et al. - 2016.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {autonomous learning {\'{a}} hierarchical,self-referential control {\'{a}} scene,situation model,understanding {\'{a}}},
pages = {1--17},
title = {{Toward Self-Referential Autonomous Learning of Object and Situation Models}},
url = {http://link.springer.com/10.1007/s12559-016-9407-7},
year = {2016}
}
@book{Laird2012,
author = {Laird, John E.},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
pages = {374},
publisher = {MIT Press},
title = {{The Soar Cognitive Architecture}},
year = {2012}
}
@article{Chella2003,
abstract = {This paper deals with the anchoring of one of the most influential symbolic formalisms used in cognitive robotics, namely the situation calculus, to a conceptual representation of dynamic scenarios. Our proposal is developed with reference to a cognitive architecture for robot vision. An experimental setup is presented, aimed at obtaining intelligent monitoring operations of a robotic finger starting from visual data. ?? 2003 Elsevier Science B.V. All rights reserved.},
author = {Chella, A. and Frixione, M. and Gaglio, S.},
doi = {10.1016/S0921-8890(02)00358-5},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Robotics and Autonomous Systems/2003/Chella, Frixione, Gaglio - 2003.pdf:pdf},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {Action representation,Anchoring,Conceptual spaces,Robot vision,Situation calculus},
number = {2-3},
pages = {175--188},
title = {{Anchoring symbols to conceptual spaces: The case of dynamic scenarios}},
volume = {43},
year = {2003}
}
@article{Schultheis2011,
abstract = {Mental spatial knowledge processing often uses spatio-analogical or quasipictorial representation structures such as spatial mental models or mental images. The cognitive architecture Casimir is designed to provide a framework for computationally modeling human spatial knowledge processing relying on these kinds of representation formats. In this article, we present an overview of Casimir and its components. We briefly describe the long-term memory component and the interaction with external diagrammatic representations. Particular emphasis is placed on Casimir's working memory and control mechanisms. Regarding working memory, we describe the conceptual foundations and the processing mechanisms employed in mental spatial reasoning. With respect to control, we explain how it is realized as a distributed, emergent facility within Casimir.},
author = {Schultheis, Holger and Barkowsky, Thomas},
doi = {10.1111/j.1756-8765.2011.01151.x},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Topics in Cognitive Science/2011/Schultheis, Barkowsky - 2011.pdf:pdf},
isbn = {17568757},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {Casimir,Cognitive architectures,Computational modeling,Mental imagery,Spatial mental models,Spatial reasoning},
number = {4},
pages = {778--795},
pmid = {25164510},
title = {{Casimir: An architecture for mental spatial knowledge processing}},
volume = {3},
year = {2011}
}
@book{Velichkovsky2006b,
address = {М.},
author = {Величковский, Б. М.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2006/Величковский - 2006(2).pdf:pdf},
isbn = {5893572173},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {432},
publisher = {Смысл},
title = {{Когнитивная наука: Основы психологии познания: в 2 т.}},
volume = {2},
year = {2006}
}
@article{Rawlinson2012,
abstract = {The Memory-Prediction Framework (MPF) and its Hierarchical-Temporal Memory implementation (HTM) have been widely applied to unsupervised learning problems, for both classification and prediction. To date, there has been no attempt to incorporate MPF/HTM in reinforcement learning or other adaptive systems; that is, to use knowledge embodied within the hierarchy to control a system, or to generate behaviour for an agent. This problem is interesting because the human neocortex is believed to play a vital role in the generation of behaviour, and the MPF is a model of the human neocortex.We propose some simple and biologically-plausible enhancements to the Memory-Prediction Framework. These cause it to explore and interact with an external world, while trying to maximize a continuous, time-varying reward function. All behaviour is generated and controlled within the MPF hierarchy. The hierarchy develops from a random initial configuration by interaction with the world and reinforcement learning only. Among other demonstrations, we show that a 2-node hierarchy can learn to successfully play "rocks, paper, scissors" against a predictable opponent.},
author = {Rawlinson, David and Kowadlo, Gideon},
doi = {10.1371/journal.pone.0029264},
editor = {Vasilaki, Eleni},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PloS one/2012/Rawlinson, Kowadlo - 2012.pdf:pdf},
issn = {1932-6203},
journal = {PloS one},
keywords = {Adaptation,Algorithms,Behavior,Behavior: physiology,Humans,Learning,Learning: physiology,Memory,Memory: physiology,Models,Neocortex,Neocortex: physiology,NeuroModels,Neurological,Pattern Recognition,Psychological,Psychological: physiology,Reinforcement (Psychology),Reward,User-Computer Interface,Visual,Visual: physiology},
mendeley-tags = {NeuroModels},
number = {1},
pages = {e29264},
pmid = {22272231},
publisher = {Public Library of Science},
title = {{Generating adaptive behaviour within a memory-prediction framework}},
url = {http://dx.plos.org/10.1371/journal.pone.0029264},
volume = {7},
year = {2012}
}
@article{Petersen2015a,
abstract = {Most accounts of human cognitive architectures have focused on computational accounts of cognition while making little contact with the study of anatomical structures and physiological processes. Arenewed convergence between neurobiology and cognition is well under way. A promising area arises from the overlap between systems/cognitive neuroscience on the one side and the discipline of network science on the other. Neuroscience increasingly adopts network tools and concepts to describe the operation of collections of brain regions. Beyond just providing illustrative metaphors, network science offers a theoretical framework for approaching brain structure and function as a multi-scale system composed of networks of neurons, cir- cuits, nuclei, cortical areas, and systems of areas. This paper views large-scale networks at the level of areas and systems, mostly on the basis of data from human neuroimaging, and how this view of network structure and function has begun to illuminate our understanding of the biological basis of cognitive architectures.},
author = {Petersen, Steven E. and Sporns, Olaf},
doi = {10.1016/j.neuron.2015.09.027},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neuron/2015/Petersen, Sporns - 2015.pdf:pdf},
issn = {08966273},
journal = {Neuron},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
number = {1},
pages = {207--219},
publisher = {Elsevier Inc.},
title = {{Brain Networks and Cognitive Architectures}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315008168},
volume = {88},
year = {2015}
}
@unpublished{Ahmad,
author = {Ahmad, Subutai and Cui, Yuwei},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Ahmad, Cui - 2015.pdf:pdf},
keywords = {htm},
mendeley-tags = {htm},
pages = {1--27},
title = {{Annotated Bibliography for HTM Researchers}},
year = {2015}
}
@incollection{Taylor,
author = {Taylor, Neill R. and Panchev, Christo and Hartley, Matthew and Kasderidis, Stathis and Taylor, John G.},
booktitle = {Artificial Neural Networks - ICANN 2006},
editor = {Kollias, Stefanos D. and Stafylopatis, Andreas and Duch, W{\l}odzis{\l}aw and Oja, Erkki},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Artificial Neural Networks - ICANN 2006/2006/Taylor et al. - 2006.pdf:pdf},
pages = {592--601},
publisher = {Springer-Verlag},
title = {{Occlusion , Attention and Object Representations}},
year = {2006}
}
@article{Donnarumma2015,
abstract = {Distributed and hierarchical models of control are nowadays popular in computational modeling and robotics. In the artificial neural network literature, complex behaviors can be produced by composing elementary building blocks or motor primitives, possibly organized in a layered structure. However, it is still unknown how the brain learns and encodes multiple motor primitives, and how it rapidly reassembles, sequences and switches them by exerting cognitive control. In this paper we advance a novel proposal, a hierarchical programmable neural network architecture, based on the notion of programmability and an interpreter-programmer computational scheme. In this approach, complex (and novel) behaviors can be acquired by embedding multiple modules (motor primitives) in a single, multi-purpose neural network. This is supported by recent theories of brain functioning in which skilled behaviors can be generated by combining functional different primitives embedded in ‘‘reusable'' areas of ‘‘recycled'' neurons. Such neuronal substrate supports flexible cognitive control, too. Modules are seen as interpreters of behaviors having controlling input parameters, or programs that encode structures of networks to be interpreted. Flexible cognitive control can be exerted by a programmer module feeding the interpreters with appropriate input parameters, without modifying connectivity. Our results in a multiple T-maze robotic scenario show how this computational framework provides a robust, scalable and flexible scheme that can be iterated at different hierarchical layers permitting to learn, encode and control multiple qualitatively different behaviors.},
author = {Donnarumma, F. and Prevete, R. and de Giorgio, A. and Montone, G. and Pezzulo, G.},
doi = {10.1177/1059712315609412},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Adaptive Behavior/2015/Donnarumma et al. - 2015.pdf:pdf},
issn = {1059-7123},
journal = {Adaptive Behavior},
keywords = {cognitive control,distributed representation,hierarchical organization,neuronal reuse,programming neural networks},
pages = {(In press)},
title = {{Learning programs is better than learning dynamics: A programmable neural network hierarchical architecture in a multi-task scenario}},
url = {http://adb.sagepub.com/cgi/doi/10.1177/1059712315609412},
year = {2015}
}
@article{Dehaene2015,
abstract = {A sequence of images, sounds, or words can be stored at several levels of detail, from specific items and their timing to abstract structure. We propose a taxonomy of five distinct cerebral mechanisms for sequence coding: transitions and timing knowledge, chunking, ordinal knowledge, algebraic patterns, and nested tree structures. In each case, we review the available experimental paradigms and list the behavioral and neural signatures of the systems involved. Tree structures require a specific recursive neural code, as yet unidentified by electrophysiology, possibly unique to humans, and which may explain the singularity of human language and cognition.},
author = {Dehaene, Stanislas and Meyniel, Florent and Wacongne, Catherine and Wang, Liping and Pallier, Christophe},
doi = {10.1016/j.neuron.2015.09.019},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neuron/2015/Dehaene et al. - 2015.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {1},
pages = {2--19},
pmid = {26447569},
publisher = {Elsevier Inc.},
title = {{The Neural Representation of Sequences: From Transition Probabilities to Algebraic Patterns and Linguistic Trees}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26447569 http://dx.doi.org/10.1016/j.neuron.2015.09.019},
volume = {88},
year = {2015}
}
@inproceedings{Licato2015,
abstract = {The ability to generate explanations of perceived events and of one's own actions is of central importance to how we make sense of the world. When modeling explanation generation, one common tactic used by cognitive systems is to construct a linkage of previously created cause- effect pairs. But where do such cause-effect pairs come from in the first place, and how can they be created automatically by cognitive systems? In this paper, we discuss the development of causal representations in children, by analyzing the literature surrounding a Piagetian experiment, and show how the conditions making cause-effect pair creation possi- ble can start to be modeled using a combination of feature-extraction techniques and the structured knowledge representation in the hybrid cognitive architecture CLARION. We create a task in PAGI World for learning causality, and make this task available for download.},
author = {Licato, John and Marton, Nick and Dong, Boning and Sun, Ron and Bringsjord, Selmer},
booktitle = {Proceedings of the 3rd International Workshop on Artificial Intelligence and Cognition},
editor = {Lieto, Antonio and Battaglino, Cristina and Radicioni, Daniele P. and Sanguinetti, Manuela},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the 3rd International Workshop on Artificial Intelligence and Cognition/2015/Licato et al. - 2015.pdf:pdf},
keywords = {analogy,clarion,cognitive architecture,explanation},
pages = {29--39},
series = {CEUR Workshop Proceedings},
title = {{Modeling the Creation and Development of Cause-Effect Pairs for Explanation Generation in a Cognitive Architecture}},
year = {2015}
}
@article{Fitch2014,
abstract = {Progress in understanding cognition requires a quantitative, theoretical framework, grounded in the other natural sciences and able to bridge between implementational, algorithmic and computational levels of explanation. I review recent results in neuroscience and cognitive biology that, when combined, provide key components of such an improved conceptual framework for contemporary cognitive science. Starting at the neuronal level, I first discuss the contemporary realization that single neurons are powerful tree-shaped computers, which implies a reorientation of computational models of learning and plasticity to a lower, cellular, level. I then turn to predictive systems theory (predictive coding and prediction-based learning) which provides a powerful formal framework for understanding brain function at a more global level. Although most formal models concerning predictive coding are framed in associationist terms, I argue that modern data necessitate a reinterpretation of such models in cognitive terms: as model-based predictive systems. Finally, I review the role of the theory of computation and formal language theory in the recent explosion of comparative biological research attempting to isolate and explore how different species differ in their cognitive capacities. Experiments to date strongly suggest that there is an important difference between humans and most other species, best characterized cognitively as a propensity by our species to infer tree structures from sequential data. Computationally, this capacity entails generative capacities above the regular (finite-state) level; implementationally, it requires some neural equivalent of a push-down stack. I dub this unusual human propensity "dendrophilia", and make a number of concrete suggestions about how such a system may be implemented in the human brain, about how and why it evolved, and what this implies for models of language acquisition. I conclude that, although much remains to be done, a neurally-grounded framework for theoretical cognitive science is within reach that can move beyond polarized debates and provide a more adequate theoretical future for cognitive biology. {\textcopyright} 2014.},
author = {Fitch, W. Tecumseh},
doi = {10.1016/j.plrev.2014.04.005},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Physics of Life Reviews/2014/Fitch - 2014.pdf:pdf},
issn = {15710645},
journal = {Physics of Life Reviews},
keywords = {Cognitive science,Comparative cognition,Computational neuroscience,Formal language theory,Mathematical psychology,Neurolinguistics},
number = {3},
pages = {329--364},
pmid = {24969660},
publisher = {Elsevier B.V.},
title = {{Toward a computational framework for cognitive biology: Unifying approaches from cognitive neuroscience and comparative cognition}},
url = {http://dx.doi.org/10.1016/j.plrev.2014.04.005},
volume = {11},
year = {2014}
}
@article{Deco2015,
abstract = {The brain regulates information flow by balancing the segregation and integration of incoming stimuli to facilitate flexible cognition and behaviour. The topological features of brain networks - in particular, network communities and hubs - support this segregation and integration but do not provide information about how external inputs are processed dynamically (that is, over time). Experiments in which the consequences of selective inputs on brain activity are controlled and traced with great precision could provide such information. However, such strategies have thus far had limited success. By contrast, recent whole-brain computational modelling approaches have enabled us to start assessing the effect of input perturbations on brain dynamics in silico.},
author = {Deco, Gustavo and Tononi, Giulio and Boly, Melanie and Kringelbach, Morten L},
doi = {10.1038/nrn3963},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature reviews. Neuroscience/2015/Deco et al. - 2015.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$r1471-003X (Linking)},
issn = {1471-0048},
journal = {Nature reviews. Neuroscience},
number = {7},
pages = {430--439},
pmid = {26081790},
publisher = {Nature Publishing Group},
title = {{Rethinking segregation and integration: contributions of whole-brain modelling}},
url = {http://www.nature.com.sire.ub.edu/nrn/journal/v16/n7/full/nrn3963.html},
volume = {16},
year = {2015}
}
@article{Tononi1998,
abstract = {Conventional approaches to understanding consciousness are generally concerned with the contribution of specific brain areas or groups of neurons. By contrast, it is considered here what kinds of neural processes can account for key properties of conscious experience. Applying measures of neural integration and complexity, together with an analysis of extensive neurological data, leads to a testable proposal-the dynamic core hypothesis-about the properties of the neural substrate of consciousness.},
author = {Tononi, G and Edelman, G M},
doi = {10.1126/science.282.5395.1846},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Science/1998/Tononi, Edelman - 1998.pdf:pdf},
isbn = {0036-8075},
issn = {0036-8075},
journal = {Science},
keywords = {consciousness},
mendeley-tags = {consciousness},
number = {1998},
pages = {1846--1851},
pmid = {9836628},
title = {{Consciousness and complexity}},
volume = {282},
year = {1998}
}
@article{Sergin2011,
abstract = {В статье рассматриваются нейробиологические механизмы сознания и мышления. Показано, что процессы автоотождествления в коре головного мозга могут порождать явное представление внешних и внутренних событий. Явное символьное представление сенсорных данных может порождать сенсорное осознание. Явное символьное представление результатов операционной активности мозга может порождать мысль. Если зрительное осознание – это видение внешних событий, то мысль – это видение результатов операционной активности мозга ("внутренний взор"). Явное символьное представление внутренних данных позволяет произвольно управлять ими как обособленными объектами. Произвольное управление данными возможно посредством аппарата внутреннего сенсорно-моторного повторения. Примерами произвольного управления словами, символами или образами являются вербальное и зрительное повторение. Процедура повторения обеспечивает последовательность и непрерывность процесса рассуждений, его связанность и однозначность. Развиваемая концепция дает внутренне согласованное объяснение широкого разнообразия феноменов сознательной деятельности мозга, от осознания и мысли до воображения, рефлексии, гипноза и медитации, обнаруживая единство казалось бы совершенно различных психических явлений и универсальность нейробиологических механизмов их формирования.},
author = {Сергин, В .Я.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Психологический журнал Международного университета природы, общества и человека Дубна/2011/Сергин - 2011.pdf:pdf},
journal = {Психологический журнал Международного университета природы, общества и человека "Дубна"},
keywords = {consciousness,мысль,сенсорное осознание,сознательное восприяти},
language = {russian},
mendeley-tags = {consciousness},
number = {2},
pages = {7--34},
title = {{Сознание и мышление: нейробиологические механизмы}},
year = {2011}
}
@inproceedings{Karpov2015a,
author = {Карпов, В. Э.},
booktitle = {Интегрированные модели и мягкие вычисления в искусственном интеллекте. Сб. научных трудов VIII-й Международной научно-технической конференции (Коломна, 18-20 мая 2015 г.). В 2-х томах},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Интегрированные модели и мягкие вычисления в искусственном интеллекте. Сб. научных трудов VIII-й Международной научно-техническ. В 2-х томах/2015/Карпов - 2015.pdf:pdf},
pages = {504--514},
publisher = {Физматлит},
title = {{Знак-ориентированный механизм локального взаимодействия между роботами}},
volume = {2},
year = {2015}
}
@techreport{Hawkins2011,
author = {Hawkins, Jeff and Ahmad, Subutai and Dubinsky, Donna},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Hawkins, Ahmad, Dubinsky - 2011.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Hawkins, Ahmad, Dubinsky - 2011(2).pdf:pdf},
institution = {Numenta},
keywords = {htm},
mendeley-tags = {htm},
pages = {1--68},
title = {{Hiearachical Temporal Memory including HTM Cortical Learning Algorithms}},
year = {2011}
}
@article{Besold2015,
abstract = {After a human-level AI-oriented overview of the status quo in neural-symbolic integration, two research programs aiming at overcoming long-standing challenges in the field are suggested to the community: The first program targets a better understanding of foundational differences and relationships on the level of computational complexity between symbolic and subsymbolic computation and representation, potentially providing explanations for the empirical differences between the paradigms in application scenarios and a foothold for subsequent attempts at overcoming these. The second program suggests a new approach and computational architecture for the cognitively-inspired anchoring of an agent's learning, knowledge formation, and higher reasoning abilities in real-world interactions through a closed neural-symbolic acting/sensing-processing-reasoning cycle, potentially providing new foundations for future agent architectures, multi-agent systems, robotics, and cognitive systems and facilitating a deeper understanding of the development and interaction in human-technological settings.},
author = {Besold, Tarek R. and Kuhnberger, Kai Uwe},
doi = {10.1016/j.bica.2015.09.003},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2015/Besold, Kuhnberger - 2015.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Agent architectures,Cognitive architectures,Complexity theory,Neural-symbolic integration,Research program},
pages = {97--110},
title = {{Towards integrated neural-symbolic systems for human-level AI: Two research programs helping to bridge the gaps}},
volume = {14},
year = {2015}
}
@article{Sun2013,
abstract = {This paper explores an approach for autonomous generation of symbolic representations from an agent's subsymbolic activities within the agent-environment interaction. The paper describes a psychologically plausible general framework and its various methods for autonomously creating symbolic representations. The symbol generation is accomplished within, and is intrinsic to, a generic and comprehensive cognitive architecture for capturing a wide variety of psychological processes (namely, CLARION). This work points to ways of obtaining more psychologically/cognitively realistic symbolic and subsymbolic representations within the framework of a cognitive architecture, and accentuates the relevance of such an approach to cognitive science and psychology.},
author = {Sun, Ron},
doi = {10.1080/09515089.2012.711035},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Philosophical Psychology/2013/Sun - 2013.pdf:pdf},
issn = {0951-5089},
journal = {Philosophical Psychology},
number = {6},
pages = {888--912},
title = {{Autonomous generation of symbolic representations through subsymbolic activities}},
volume = {26},
year = {2013}
}
@article{Kuznetcova2012b,
author = {Кузнецова, Ю. М.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Труды Института системного анализа/2012/Кузнецова - 2012.pdf:pdf},
journal = {Труды Института системного анализа},
keywords = {12-07-00611,lingvo},
language = {russian},
mendeley-tags = {12-07-00611,lingvo},
number = {3},
pages = {116--131},
title = {{Понимание и проблемы языкового выражения смысла}},
volume = {62},
year = {2012}
}
@article{Botvinick2009a,
abstract = {Research on human and animal behavior has long emphasized its hierarchical structure-the divisibility of ongoing behavior into discrete tasks, which are comprised of subtask sequences, which in turn are built of simple actions. The hierarchical structure of behavior has also been of enduring interest within neuroscience, where it has been widely considered to reflect prefrontal cortical functions. In this paper, we reexamine behavioral hierarchy and its neural substrates from the point of view of recent developments in computational reinforcement learning. Specifically, we consider a set of approaches known collectively as hierarchical reinforcement learning, which extend the reinforcement learning paradigm by allowing the learning agent to aggregate actions into reusable subroutines or skills. A close look at the components of hierarchical reinforcement learning suggests how they might map onto neural structures, in particular regions within the dorsolateral and orbital prefrontal cortex. It also suggests specific ways in which hierarchical reinforcement learning might provide a complement to existing psychological models of hierarchically structured behavior. A particularly important question that hierarchical reinforcement learning brings to the fore is that of how learning identifies new action routines that are likely to provide useful building blocks in solving a wide range of future problems. Here and at many other points, hierarchical reinforcement learning offers an appealing framework for investigating the computational and neural underpinnings of hierarchically structured behavior.},
author = {Botvinick, Matthew M. and Niv, Yael and Barto, Andrew C.},
doi = {10.1016/j.cognition.2008.08.011},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognition/2009/Botvinick, Niv, Barto - 2009.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {Animals,Humans,Models,Nerve Net,Nerve Net: physiology,Prefrontal Cortex,Prefrontal Cortex: physiology,Problem Solving,Problem Solving: physiology,Psychological,Reinforcement (Psychology)},
number = {3},
pages = {262--80},
pmid = {18926527},
title = {{Hierarchically organized behavior and its neural foundations: a reinforcement learning perspective}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2783353{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {113},
year = {2009}
}
@article{Acedo2015,
author = {Acedo, L. and Lamprianidou, E. and Mora{\~{n}}o, J.-a. and Villanueva-Oller, J. and Villanueva, R.-J.},
doi = {10.1016/j.physa.2015.05.017},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Physica A Statistical Mechanics and its Applications/2015/Acedo et al. - 2015.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
language = {english},
pages = {111--119},
publisher = {Elsevier B.V.},
title = {{Firing patterns in a random network cellular automata model of the brain}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S037843711500432X},
volume = {435},
year = {2015}
}
@article{Kuznetcova2016,
abstract = {В работе обсуждается специфика функционирования концепта «картина мира» в различных сферах научного дискурса. Выделены три основных аспекта его содержания, актуализация которых является предметоспецифичной: организация знаний, полученных на основании определенной научной парадигмы; структура, образованная определенными разновидностями объектов; зафиксированный опыт, опосредующий дальнейшее взаимодействие с реальностью. Характерный для методологического и естественнонаучного дискурса подход к картине мира как к результату рефлексии познавательной деятельности может быть в целом противопоставлен гуманитарному, где картина мира выступает в качестве предмета познания.},
author = {Кузнецова, Ю. М.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Искусственный интеллект и принятие решений/2016/Кузнецова - 2016.pdf:pdf},
journal = {Искусственный интеллект и принятие решений},
keywords = {15-07-06214,lingvo,psycho,гуманитарное знание,естественные науки,картина мира,научный дискурс},
language = {russian},
mendeley-tags = {15-07-06214,lingvo,psycho},
number = {1},
pages = {(В печати)},
title = {{Концепт "Картина мира" в современном русскоязычном научном дискурсе}},
year = {2016}
}
@article{Osovec1983,
author = {Осовец, С. М. and Гинзбург, Д. А. and Гурфинкель, В. С. and Зенков, Л. Р. and Латаш, Л. П. and Малкин, В. Б. and Мельничук, П. В. and Пастернак, Е. Б.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/1983/Осовец et al. - 1983.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {1},
pages = {103--150},
title = {{Электрическая активность мозга: механизмы и интерпретация}},
volume = {141},
year = {1983}
}
@article{Botvinick2012,
abstract = {The hierarchical structure of human and animal behavior has been of critical interest in neuroscience for many years. Yet understanding the neural processes that give rise to such structure remains an open challenge. In recent research, a new perspective on hierarchical behavior has begun to take shape, inspired by ideas from machine learning, and in particular the framework of hierarchical reinforcement learning. Hierarchical reinforcement learning builds on traditional reinforcement learning mechanisms, extending them to accommodate temporally extended behaviors or subroutines. The resulting computational paradigm has begun to influence both theoretical and empirical work in neuroscience, conceptually aligning the study of hierarchical behavior with research on other aspects of learning and decision making, and giving rise to some thought-provoking new findings. ?? 2012.},
author = {Botvinick, Matthew Michael},
doi = {10.1016/j.conb.2012.05.008},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Current Opinion in Neurobiology/2012/Botvinick - 2012.pdf:pdf},
isbn = {0818653302},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {6},
pages = {956--962},
pmid = {22695048},
publisher = {Elsevier Ltd},
title = {{Hierarchical reinforcement learning and decision making}},
url = {http://dx.doi.org/10.1016/j.conb.2012.05.008},
volume = {22},
year = {2012}
}
@book{Vityaev2006,
address = {Новосибирск},
author = {Витяев, Е. Е.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2006/Витяев - 2006.pdf:pdf},
language = {russian},
pages = {293},
publisher = {Новосиб. гос. ун-т},
title = {{Извлечение знаний из данных. Компьютерное познание. Модели когнитивных процессов: Монография}},
year = {2006}
}
@article{Tetzlaff2013,
abstract = {Memory storage in the brain relies on mechanisms acting on time scales from minutes, for long-term synaptic potentiation, to days, for memory consolidation. During such processes, neural circuits distinguish synapses relevant for forming a long-term storage, which are consolidated, from synapses of short-term storage, which fade. How time scale integration and synaptic differentiation is simultaneously achieved remains unclear. Here we show that synaptic scaling - a slow process usually associated with the maintenance of activity homeostasis - combined with synaptic plasticity may simultaneously achieve both, thereby providing a natural separation of short- from long-term storage. The interaction between plasticity and scaling provides also an explanation for an established paradox where memory consolidation critically depends on the exact order of learning and recall. These results indicate that scaling may be fundamental for stabilizing memories, providing a dynamic link between early and late memory formation processes.},
author = {Tetzlaff, Christian and Kolodziejski, Christoph and Timme, Marc and Tsodyks, Misha and W{\"{o}}rg{\"{o}}tter, Florentin},
doi = {10.1371/journal.pcbi.1003307},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS computational biology/2013/Tetzlaff et al. - 2013.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Computational Biology,Long-Term,Long-Term: physiology,Memory,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Short-Term,Short-Term: physiology,Synapses,Synapses: physiology},
number = {10},
pages = {e1003307},
pmid = {24204240},
title = {{Synaptic scaling enables dynamically distinct short- and long-term memory formation}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3814677{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {9},
year = {2013}
}
@misc{Regier2001,
abstract = {The present paper grounds the linguistic cdategorization of space in aspects of visual perception; specifically, the structure of projective spatial terms such as above are grounded in the process of attention and in vector-sum coding of overall direction. This is formalized in the attentional vector-sum (AVS) model. This computational model accurately predicts linguistic acceptability judgments for spatial terms, under a variety of spatial configurations. In 7 experiments, the predictions of the AVS model are tested against those of 3 competing models. The results support the AVS model and disconfirm its competitors. The authors conclude that the structure of linguistic spatial categories can be partially explained in terms of independently motivated perceptual processes.},
author = {Regier, T. and Carlson, L. A.},
booktitle = {Journal of experimental psychology: General},
doi = {10.1037/0096-3445.130.2.273},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Journal of experimental psychology General/2001/Regier, Carlson - 2001.pdf:pdf},
isbn = {0096-3445 (Print)$\backslash$r0022-1015 (Linking)},
issn = {0096-3445},
number = {2},
pages = {273--298},
pmid = {11409104},
title = {{Grounding spatial language in perception: an empirical and computational investigation}},
volume = {130},
year = {2001}
}
@book{Mountcastle1998,
address = {Cambridge},
author = {Mountcastle, V. B.},
pages = {512},
publisher = {Harvard University Press},
title = {{Perceptual Neuroscience. The Cerebral Cortex}},
year = {1998}
}
@article{Friederici2015,
abstract = {In animal models the neural basis of cognitive and executive processes has been studied extensively at various hierarchical levels from microcircuits to distributed functional networks. This work already provides compelling evidence that diverse cognitive functions are based on similar basic neuronal mechanisms. More recent data suggest that even cognitive functions realized only in human brains rely on these canonical neuronal mechanisms. Here we argue that language, like other cognitive functions, depends on distributed computations in specialized cortical areas forming large-scale dynamic networks and examine to what extent empirical results support this view.},
author = {Friederici, Angela D. and Singer, Wolf},
doi = {10.1016/j.tics.2015.03.012},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in Cognitive Sciences/2015/Friederici, Singer - 2015.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {language,neural networks,oscillation},
number = {6},
pages = {329--338},
title = {{Grounding language processing on basic neurophysiological principles}},
url = {http://www.sciencedirect.com/science/article/pii/S1364661315000741},
volume = {19},
year = {2015}
}
@article{Chudova2015,
author = {Чудова, Н. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Труды Института Системного Анализа РАН/2015/Чудова - 2015.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Труды Института Системного Анализа РАН/2015/Чудова - 2015(2).pdf:pdf},
journal = {Труды Института Системного Анализа РАН},
keywords = {12-07-00611,13-06-00658,psycho},
language = {russian},
mendeley-tags = {12-07-00611,13-06-00658,psycho},
number = {1},
title = {{Агрессивность и конструктивное мышление}},
volume = {65},
year = {2015}
}
@article{Baars2005,
abstract = {Global workspace (GW) theory emerged from the cognitive architecture tradition in cognitive science. Newell and co-workers were the first to show the utility of a GW or "blackboard" architecture in a distributed set of knowledge sources, which could cooperatively solve problems that no single constituent could solve alone. The empirical connection with conscious cognition was made by Baars (1988, 2002). GW theory generates explicit predictions for conscious aspects of perception, emotion, motivation, learning, working memory, voluntary control, and self systems in the brain. It has similarities to biological theories such as Neural Darwinism and dynamical theories of brain functioning. Functional brain imaging now shows that conscious cognition is distinctively associated with wide spread of cortical activity, notably toward frontoparietal and medial temporal regions. Unconscious comparison conditions tend to activate only local regions, such as visual projection areas. Frontoparietal hypometabolism is also implicated in unconscious states, including deep sleep, coma, vegetative states, epileptic loss of consciousness, and general anesthesia. These findings are consistent with the GW hypothesis, which is now favored by a number of scientists and philosophers.},
author = {Baars, Bernard J},
doi = {10.1016/S0079-6123(05)50004-9},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Progress in brain research/2005/Baars - 2005.pdf:pdf},
isbn = {1925283267},
issn = {0079-6123},
journal = {Progress in brain research},
keywords = {Cognition,Cognition: physiology,Consciousness,Consciousness: physiology,Humans,Models,Neurosciences,Psychological},
pages = {45--53},
pmid = {16186014},
title = {{Global workspace theory of consciousness: toward a cognitive neuroscience of human experience.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16186014},
volume = {150},
year = {2005}
}
@book{Lewandowski2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
booktitle = {The effects of brief mindfulness intervention on acute pain experience: An examination of individual difference},
doi = {10.1017/CBO9781107415324.004},
editor = {Lewandowski, Clare M.},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/The effects of brief mindfulness intervention on acute pain experience An examination of individual difference/2015/Unknown - 2015.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
pages = {1308},
pmid = {25246403},
publisher = {Springer Netherlands},
title = {{International Handbook of Semiotics}},
year = {2015}
}
@book{Vygotsky1999,
address = {М.},
author = {Выготский, Л. С.},
edition = {Изд. 5-е, },
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/1999/Выготский - 1999.doc:doc},
pages = {352},
publisher = {Издательство "Лабиринт"},
title = {{Мышление и речь}},
year = {1999}
}
@article{Doya2000a,
abstract = {The classical notion that the basal ganglia and the cerebellum are dedicated to motor control has been challenged by the accumulation of evidence revealing their involvement in non- motor, cognitive functions. From a computational viewpoint, it has been suggested that the cerebellum, the basal ganglia, and the cerebral cortex are specialized for different types of learning: namely, supervised learning, reinforcement learning and unsupervised learning, respectively. This idea of learning- oriented specialization is helpful in understanding the complementary roles of the basal ganglia and the cerebellum in motor control and cognitive functions},
author = {Doya, Kenji},
doi = {10.1016/S0959-4388(00)00153-7},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Current Opinion in Neurobiology/2000/Doya - 2000.pdf:pdf},
isbn = {0959-4388},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
pages = {732--739},
pmid = {11240282},
title = {{Complementary roles of basal ganglia and cerebellum in learning and motor control}},
volume = {10},
year = {2000}
}
@unpublished{Velichkovsky2015,
author = {Величковский, Б. М.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Величковский - 2015.pdf:pdf},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {1--11},
title = {{Что такое « сознание »?}},
year = {2015}
}
@article{Plebe2016a,
abstract = {Neural computation has an influential role in the study of human capacities and behaviors. It has been the dominant approach in the vision science of the last half century, and it is currently one of the fundamental methods of investigation for most higher cognitive func- tions. Yet, neurocomputational approaches to moral behavior are lacking. Computational modeling in general has been scarcely pursued in morality, and existent non-neural attempts have failed to account for the mental processes involved in morality. In this paper we argue that recently the situation has evolved in a way that subverted the insufficient knowledge on the basic organization of moral cognition in brain circuits, making the project of modeling morality in neurocomputational terms feasible. We will present an original architecture that combines reinforcement learning and Hebbian learning, aimed at simulating forms of moral behavior in a simple artificial context. The relationship between language and morality is controversial. In the analytic tradition of philosophy, morality is essentially the lan- guage of morals. On the other side, current cognitive ethology has shown how non human species display behaviors that are surprisingly similar to those prescribed by human ethics. Nevertheless, morality in humans is deeply entrenched with language, and the semantics of words like ‘wrong' resists consensual explanations. The model here proposed includes an auditory processing pathway, with the purpose of showing how the coding of ‘‘wrong”, even if highly simplified with respect to its rich content in natural language, can emerge in the course of moral learning.},
author = {Plebe, Alessio},
doi = {10.1016/j.cogsys.2015.12.012},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Systems Research/2016/Plebe - 2016.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {amygdala,moral cognition,neural computation,orbitofrontal cortex,self-organization},
pages = {4--14},
title = {{What is ‘wrong' in a neural model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1389041716000085},
volume = {39},
year = {2016}
}
@article{Borisyuk2004,
abstract = {We develop a new oscillatory model that combines consecutive selection of objects and discrimination between new and familiar objects. The model works with visual information and fulfils the following operations: (1) separation of different objects according to their spatial connectivity; (2) consecutive selection of objects located in the visual field into the attention focus; (3) extraction of features; (4) representation of objects in working memory; (5) novelty detection of objects. The functioning of the model is based on two main principles: the synchronization of oscillators through phase-locking and resonant increase of the amplitudes of oscillators if they work in-phase with other oscillators. The results of computer simulation of the model are described for visual stimuli representing printed words.},
author = {Borisyuk, Roman M and Kazanovich, Yakov B},
doi = {10.1016/j.neunet.2004.03.005},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural networks the official journal of the International Neural Network Society/2004/Borisyuk, Kazanovich - 2004.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Attention,Attention: physiology,Computer Simulation,Discrimination Learning,Discrimination Learning: physiology,Humans,Mathematics,Memory,Memory: physiology,Models,Neurological,Photic Stimulation,Photic Stimulation: methods,Psychological,Signal Detection,Visual Perception,Visual Perception: physiology},
number = {7},
pages = {899--915},
pmid = {15312834},
title = {{Oscillatory model of attention-guided object selection and novelty detection}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15312834},
volume = {17},
year = {2004}
}
@article{Treur2016,
author = {Treur, Jan},
doi = {10.1016/j.bica.2016.02.002},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2016/Treur - 2016.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
pages = {131--168},
publisher = {Elsevier B.V.},
title = {{Dynamic modeling based on a temporal–causal network modeling approach}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X16300147},
volume = {16},
year = {2016}
}
@article{Anderson2005,
abstract = {This article describes the Adaptive Control of Thought-Rational (ACT-R) cognitive architecture (Anderson et al., 2004; Anderson {\&} Lebiere, 1998) and its detailed application to the learning of algebraic symbol manipulation. The theory is applied to modeling the data from a study by Qin, Anderson, Silk, Stenger, {\&} Carter (2004) in which children learn to solve linear equations and perfect their skills over a 6-day period. Functional MRI data show that: (a) a motor region tracks the output of equation solutions, (b) a prefrontal region tracks the retrieval of declarative information, (c) a parietal region tracks the transformation of mental representations of the equation, (d) an anterior cingulate region tracks the setting of goal information to control the information flow, and (e) a caudate region tracks the firing of productions in the ACT-R model. The article concludes with an architectural comparison of the competence children display in this task and the competence that monkeys have shown in tasks that require manipulations of sequences of elements.},
author = {Anderson, John R},
doi = {10.1207/s15516709cog0000_22},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive science/2005/Anderson - 2005.pdf:pdf},
issn = {0364-0213},
journal = {Cognitive science},
keywords = {brain imaging,cognitive architecture,comparative,education,learning,mathematics,problem solving,psychology},
number = {3},
pages = {313--41},
pmid = {21702777},
title = {{Human symbol manipulation within an integrated cognitive architecture}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21702777},
volume = {29},
year = {2005}
}
@article{Oizumi2014,
abstract = {This paper presents Integrated Information Theory (IIT) of consciousness 3.0, which incorporates several advances over previous formulations. IIT starts from phenomenological axioms: information says that each experience is specific – it is what it is by how it differs from alternative experiences; integration says that it is unified – irreducible to non- interdependent components; exclusion says that it has unique borders and a particular spatio-temporal grain. These axioms are formalized into postulates that prescribe how physical mechanisms, such as neurons or logic gates, must be configured to generate experience (phenomenology). The postulates are used to define intrinsic information as ‘‘differences that make a difference'' within a system, and integrated information as information specified by a whole that cannot be reduced to that specified by its parts. By applying the postulates both at the level of individual mechanisms and at the level of systems of mechanisms, IIT arrives at an identity: an experience is a maximally irreducible conceptual structure (MICS, a constellation of concepts in qualia space), and the set of elements that generates it constitutes a complex. According to IIT, a MICS specifies the quality of an experience and integrated information WMax its quantity. From the theory follow several results, including: a system of mechanisms may condense into a major complex and non-overlapping minor complexes; the concepts that specify the quality of an experience are always about the complex itself and relate only indirectly to the external environment; anatomical connectivity influences complexes and associated MICS; a complex can generate a MICS even if its elements are inactive; simple systems can be minimally conscious; complicated systems can be unconscious; there can be true ‘‘zombies'' – unconscious feed-forward systems that are functionally equivalent to conscious complexes. Citation:},
author = {Oizumi, Masafumi and Albantakis, Larissa and Tononi, Giulio},
doi = {10.1371/journal.pcbi.1003588},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS Computational Biology/2014/Oizumi, Albantakis, Tononi - 2014.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS Computational Biology/2014/Oizumi, Albantakis, Tononi - 2014.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS Computational Biology/2014/Oizumi, Albantakis, Tononi - 2014.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS Computational Biology/2014/Oizumi, Albantakis, Tononi - 2014.pdf:pdf},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {consciousness},
mendeley-tags = {consciousness},
number = {5},
pages = {e1003588},
title = {{From the Phenomenology to the Mechanisms of Consciousness: Integrated Information Theory 3.0}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1003588},
volume = {10},
year = {2014}
}
@article{Pulvermuller2013,
author = {Pulverm{\"{u}}ller, Friedemann},
doi = {10.1016/j.tics.2013.06.004},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in Cognitive Sciences/2013/Pulverm{\"{u}}ller - 2013.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {9},
pages = {458--470},
title = {{How neurons make meaning: brain mechanisms for embodied and abstract-symbolic semantics}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661313001228},
volume = {17},
year = {2013}
}
@article{Derbinsky2010,
author = {Derbinsky, Nate and Laird, John E},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the Remembering Who We Are – Human Memory for Artificial Agents Symposium, AISB 2010/2010/Derbinsky, Laird - 2010.pdf:pdf},
isbn = {1902956893},
journal = {Proceedings of the Remembering Who We Are – Human Memory for Artificial Agents Symposium, AISB 2010},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
pages = {31--37},
title = {{Extending Soar with Dissociated Symbolic Memories}},
year = {2010}
}
@book{Hegarty2014,
editor = {Freksa, Christian and Nebel, Bernhard and Hegarty, Mary and Barkowsky, Thomas},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2014/Unknown - 2014.pdf:pdf},
isbn = {9783319112145},
pages = {406},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Spatial Cognition IX}},
year = {2014}
}
@article{Keramati2011a,
abstract = {Reinforcement learning models address animal's behavioral adaptation to its changing “external” environment, and are based on the assumption that Pavlo- vian, habitual and goal-directed responses seek to maximize reward acquisition. Negative-feedback models of homeostatic regulation, on the other hand, are con- cerned with behavioral adaptation in response to the “internal” state of the animal, and assume that animals' behavioral objective is to minimize deviations of some key physiological variables from their hypothetical setpoints. Building upon the drive-reduction theory of reward, we propose a new analytical framework that in- tegrates learning and regulatory systems, such that the two seemingly unrelated objectives of reward maximization and physiological-stability prove to be identi- cal. The proposed theory shows behavioral adaptation to both internal and external states in a disciplined way. We further show that the proposed framework allows for a unified explanation of some behavioral pattern like motivational sensitivity of different associative learning mechanism, anticipatory responses, interaction among competing motivational systems, and risk aversion.},
author = {Keramati, Mehdi and Gutkin, Boris},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nips/2011/Keramati, Gutkin - 2011.pdf:pdf},
isbn = {9781618395993},
journal = {Nips},
pages = {82--90},
title = {{A Reinforcement Learning theory for homeostatic regulation}},
year = {2011}
}
@article{Gurney2001,
abstract = {We present a biologically plausible model of processing intrinsic to the basal ganglia based on the computational premise that action selection is a primary role of these central brain structures. By encoding the propensity for selecting a given action in a scalar value (the salience), it is shown that action selection may be recast in terms of signal selection. The generic properties of signal selection are defined and neural networks for this type of computation examined. A comparison between these networks and basal ganglia anatomy leads to a novel functional decomposition of the basal ganglia architecture into 'selection' and 'control' pathways. The former pathway performs the selection per se via a feedforward off-centre on-surround network. The control pathway regulates the action of the selection pathway to ensure its effective operation, and synergistically complements its dopaminergic modulation. The model contrasts with the prevailing functional segregation of basal ganglia into 'direct' and 'indirect' pathways.},
author = {Gurney, K and Prescott, T J and Redgrave, P},
doi = {10.1007/PL00007984},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biological cybernetics/2001/Gurney, Prescott, Redgrave - 2001.pdf:pdf},
isbn = {0340-1200 (Print)$\backslash$n0340-1200 (Linking)},
issn = {0340-1200},
journal = {Biological cybernetics},
number = {6},
pages = {401--410},
pmid = {11417052},
title = {{A computational model of action selection in the basal ganglia. I. A new functional anatomy}},
volume = {84},
year = {2001}
}
@article{Sandamirskaya2015a,
abstract = {Robots controlled by the state of the art cognitive architectures are still far behind animals in their capabilities to learn complex skills and autonomously adapt to unexpected circumstances. The neurocognitive architecture proposed in this paper addresses the problem of learning and execution of hierarchical behaviors and complex skills. Learning is addressed both on the level of individual elementary behaviors and goal-directed sequences of actions. The proposed architecture comprises a Dynamic Neural Fields (DNFs) implementation of the low-level elementary behaviors and a Functional System Network (FSN) tying these behaviors in goal-directed sequences. The DNF framework enables a continuous, dynamical representation of perceptual features and motor parameters, which may be directly coupled to the robot's sensors and motors. Attractor states and instabilities of the DNFs account for segregation of cognitive states and mark behaviorally relevant events in the continuous flow of sensorimotor dynamics. The FSN, in its turn, comprises dynamical elements that can be arranged in a multilayered network by a learning process, in which new layers and elementary behaviors are added on demand. In our architecture, the FSN controls adaptation processes in the already acquired neural-dynamic elementary behaviors, as well as formation of new elementary behaviors. Combination of the DNF and FSN frameworks in a neurocognitive architecture NARLE enables pervasive learning both on the level of individual behaviors and goal-directed sequence, contributing to the progress towards more adaptive intelligent robotic systems, capable to learn new tasks and extend their behavioral repertoire in stochastic real-world environments.},
author = {Sandamirskaya, Yulia and Burtsev, Mikhail},
doi = {10.1016/j.bica.2015.06.007},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2015/Sandamirskaya, Burtsev - 2015.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Dynamic Neural Fields,Functional System Network,Neurocognitive architecture,Pervasive learning,cog{\_}arch},
mendeley-tags = {cog{\_}arch},
pages = {91--104},
publisher = {Elsevier B.V.},
title = {{NARLE: Neurocognitive architecture for the autonomous task recognition, learning, and execution}},
url = {http://www.sciencedirect.com/science/article/pii/S2212683X15000341 http://linkinghub.elsevier.com/retrieve/pii/S2212683X15000341},
volume = {13},
year = {2015}
}
@article{Goertzel2014a,
abstract = {A high-level AGI architecture called GOLEM (Goal-Oriented LEarn- ing Meta-Architecture) is presented, along with an informal but care- ful argument that GOLEM may be capable of preserving its initial goals while radically improving its general intelligence. As a meta- architecture, GOLEM can be wrapped around a variety of different base-level AGI systems, and also has a role for a powerful narrow-AI subcomponent as a probability estimator. The motivation underlying these ideas is the desire to create AGI systems fulfilling the multiple criteria of being: massively and self-improvingly intelligent; probably beneficial; and almost surely not destructive.},
author = {Goertzel, Ben},
doi = {10.1080/0952813X.2014.895107},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Journal of Experimental {\&} Theoretical Artificial Intelligence/2014/Goertzel - 2014.pdf:pdf},
issn = {0952-813X},
journal = {Journal of Experimental {\&} Theoretical Artificial Intelligence},
number = {3},
pages = {391--403},
title = {{GOLEM: towards an AGI meta-architecture enabling both goal preservation and radical self-improvement}},
url = {http://www.tandfonline.com/doi/abs/10.1080/0952813X.2014.895107},
volume = {26},
year = {2014}
}
@article{Pezzulo2011,
author = {Pezzulo, Giovanni},
doi = {10.1111/j.1468-0017.2010.01411.x},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Mind {\&} Language/2011/Pezzulo - 2011.pdf:pdf},
issn = {02681064},
journal = {Mind {\&} Language},
number = {1},
pages = {78--114},
title = {{Grounding Procedural and Declarative Knowledge in Sensorimotor Anticipation}},
url = {http://doi.wiley.com/10.1111/j.1468-0017.2010.01411.x},
volume = {26},
year = {2011}
}
@techreport{Cortical2014,
author = {Hawkins, Jeff and Ahmad, Subutai and Byrne, Fergal and Surpur, Chetan},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2014/Hawkins et al. - 2014.pdf:pdf},
institution = {Numenta},
keywords = {htm},
mendeley-tags = {htm},
pages = {62},
title = {{Hierarchical Temporal Memory including HTM Cortical Learning Algorithms}},
url = {numenta.org},
year = {2014}
}
@article{Griffiths2010,
abstract = {Cognitive science aims to reverse-engineer the mind, and many of the engineering challenges the mind faces involve induction. The probabilistic approach to modeling cognition begins by identifying ideal solutions to these inductive problems. Mental processes are then modeled using algorithms for approximating these solutions, and neural processes are viewed as mechanisms for implementing these algorithms, with the result being a top-down analysis of cognition starting with the function of cognitive processes. Typical connectionist models, by contrast, follow a bottom-up approach, beginning with a characterization of neural mechanisms and exploring what macro-level functional phenomena might emerge. We argue that the top-down approach yields greater flexibility for exploring the representations and inductive biases that underlie human cognition.},
author = {Griffiths, Thomas L and Chater, Nick and Kemp, Charles and Perfors, Amy and Tenenbaum, Joshua B},
doi = {10.1016/j.tics.2010.05.004},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in cognitive sciences/2010/Griffiths et al. - 2010.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Bias (Epidemiology),Brain,Brain: physiology,Cognition,Cognition: physiology,Humans,Models,Predictive Value of Tests,Probability,Psychological},
number = {8},
pages = {357--64},
pmid = {20576465},
publisher = {Elsevier Ltd},
title = {{Probabilistic models of cognition: exploring representations and inductive biases}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20576465},
volume = {14},
year = {2010}
}
@article{Stankevich2006,
author = {Станкевич, Л. А. and Серебряков, С. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Труды СПИИРАН/2006/Станкевич, Серебряков - 2006.pdf:pdf},
journal = {Труды СПИИРАН},
language = {russian},
number = {3},
pages = {71--87},
title = {{Когнитивные системы и агенты}},
volume = {1},
year = {2006}
}
@article{Cadieu2014,
abstract = {The primate visual system achieves remarkable visual object recognition performance even in brief presentations and under changes to object exemplar, geometric transformations, and background variation (a.k.a. core visual object recognition). This remarkable performance is mediated by the representation formed in inferior temporal (IT) cortex. In parallel, recent advances in machine learning have led to ever higher performing models of object recognition using artificial deep neural networks (DNNs). It remains unclear, however, whether the representational performance of DNNs rivals that of the brain. To accurately produce such a comparison, a major difficulty has been a unifying metric that accounts for experimental limitations such as the amount of noise, the number of neural recording sites, and the number trials, and computational limitations such as the complexity of the decoding classifier and the number of classifier training examples. In this work we perform a direct comparison that corrects for these experimental limitations and computational considerations. As part of our methodology, we propose an extension of "kernel analysis" that measures the generalization accuracy as a function of representational complexity. Our evaluations show that, unlike previous bio-inspired models, the latest DNNs rival the representational performance of IT cortex on this visual object recognition task. Furthermore, we show that models that perform well on measures of representational performance also perform well on measures of representational similarity to IT and on measures of predicting individual IT multi-unit responses. Whether these DNNs rely on computational mechanisms similar to the primate visual system is yet to be determined, but, unlike all previous bio-inspired models, that possibility cannot be ruled out merely on representational performance grounds.},
archivePrefix = {arXiv},
arxivId = {1406.3284},
author = {Cadieu, Charles F. and Hong, Ha and Yamins, Daniel L. K. and Pinto, Nicolas and Ardila, Diego and Solomon, Ethan a. and Majaj, Najib J. and DiCarlo, James J.},
doi = {10.1371/journal.pcbi.1003963},
eprint = {1406.3284},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Arxiv/2014/Cadieu et al. - 2014.pdf:pdf},
issn = {15537358},
journal = {Arxiv},
number = {12},
pages = {35},
pmid = {25521294},
title = {{Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition}},
url = {http://arxiv.org/abs/1406.3284},
volume = {10},
year = {2014}
}
@article{Khrennikov2006,
abstract = {We try to perform geometrization of cognitive science and psychology by representing information states of cognitive systems by points of mental space given by a hierarchic m-adic tree. Associations are represented by balls and ideas by collections of balls. We consider dynamics of ideas based on lifting of dynamics of mental points. We apply our dynamical model for modeling of flows of unconscious and conscious information in the human brain. In a series of models, Models 1-3, we consider cognitive systems with increasing complexity of psychological behavior determined by structure of flows of associations and ideas.},
author = {Khrennikov, Andrei Yu.},
doi = {10.1016/j.biosystems.2007.02.004},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Bio Systems/2006/Khrennikov - 2006.pdf:pdf},
issn = {0303-2647},
journal = {Bio Systems},
keywords = {Artificial Intelligence,Brain,Brain: physiology,Cognition,Consciousness,Humans,Mathematics,Models,Neuropsychology,Psychological,Systems Biology,Unconscious (Psychology)},
number = {3},
pages = {656--75},
pmid = {17400367},
title = {{Toward an adequate mathematical model of mental space: conscious/unconscious dynamics on m-adic trees.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17400367},
volume = {90},
year = {2006}
}
@article{Pezzulo2014,
abstract = {A network of brain structures including hippocampus (HC), prefrontal cortex, and striatum controls goal-directed behavior and decision making. However, the neural mechanisms underlying these functions are unknown. Here, we review the role of 'internally generated sequences': structured, multi-neuron firing patterns in the network that are not confined to signaling the current state or location of an agent, but are generated on the basis of internal brain dynamics. Neurophysiological studies suggest that such sequences fulfill functions in memory consolidation, augmentation of representations, internal simulation, and recombination of acquired information. Using computational modeling, we propose that internally generated sequences may be productively considered a component of goal-directed decision systems, implementing a sampling-based inference engine that optimizes goal acquisition at multiple timescales of on-line choice, action control, and learning. {\textcopyright} 2014 Elsevier Ltd. All rights reserved.},
author = {Pezzulo, Giovanni and van der Meer, Matthijs a a and Lansink, Carien S. and Pennartz, Cyriel M a},
doi = {10.1016/j.tics.2014.06.011},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in Cognitive Sciences/2014/Pezzulo et al. - 2014.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {decision making,forward sweep,generative models,hippocampus,inference,prospection,reinforcement learning,replay,spatial navigation,theta rhythm,ventral striatum},
number = {12},
pages = {647--657},
pmid = {25156191},
publisher = {Elsevier Ltd},
title = {{Internally generated sequences in learning and executing goal-directed behavior}},
url = {http://dx.doi.org/10.1016/j.tics.2014.06.011},
volume = {18},
year = {2014}
}
@article{Simoes2015,
abstract = {Understanding consciousness is one of the most fasci- nating challenges of our time. Fromancient civilizations to modern philosophers, questions have been asked on howone is conscious of his/her own existence and about theworld that surrounds him/her. Although there is no precise definition for consciousness, there is an agreement that it is strongly related to human cognitive pro- cesses such as attention, a process capable of promoting a selection of a few stimuli from a huge amount of information that reaches us constantly. In order to bring the consciousness discussion to a com- putational scenario, this paper presents conscious attention-based integrated model (CONAIM), a formal model for machine con- sciousness based on an attentional schema for human-like agent cognition that integrates: short- and long-term memories, rea- soning, planning, emotion, decision-making, learning, motivation, and volition. Experimental results in a mobile robotics domain show that the agent can attentively use motivation, volition, and memories to set its goals and learn new concepts and procedures based on exogenous and endogenous stimuli. By performing com- putation over an attentional space, the model also allowed the agent to learn over a much reduced state space. Further imple- mentation under this model could potentially allow the agent to express sentience, self-awareness, self-consciousness, autonoetic consciousness, mineness, and perspectivalness.},
author = {Simoes, Alexandre and Colmbini, Esther and Ribeiro, Carlos},
doi = {10.1109/JSYST.2015.2498542},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/IEEE Systems Journal/2016/Simoes, Colmbini, Ribeiro - 2016.pdf:pdf},
issn = {19379234},
journal = {IEEE Systems Journal},
number = {99},
pages = {1--12},
title = {{CONAIM : A Conscious Attention-Based Integrated Model for Human-Like Robots}},
year = {2016}
}
@article{Frank2012,
abstract = {Growing evidence suggests that the prefrontal cortex (PFC) is organized hierarchically, with more anterior regions having increasingly abstract representations. How does this organization support hierarchical cognitive control and the rapid discovery of abstract action rules? We present computational models at different levels of description. A neural circuit model simulates interacting corticostriatal circuits organized hierarchically. In each circuit, the basal ganglia gate frontal actions, with some striatal units gating the inputs to PFC and others gating the outputs to influence response selection. Learning at all of these levels is accomplished via dopaminergic reward prediction error signals in each corticostriatal circuit. This functionality allows the system to exhibit conditional if-then hypothesis testing and to learn rapidly in environments with hierarchical structure. We also develop a hybrid Bayesian-reinforcement learning mixture of experts (MoE) model, which can estimate the most likely hypothesis state of individual participants based on their observed sequence of choices and rewards. This model yields accurate probabilistic estimates about which hypotheses are attended by manipulating attentional states in the generative neural model and recovering them with the MoE model. This 2-pronged modeling approach leads to multiple quantitative predictions that are tested with functional magnetic resonance imaging in the companion paper.},
author = {Frank, Michael J. and Badre, David},
doi = {10.1093/cercor/bhr114},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cerebral cortex (New York, N.Y. 1991)/2012/Frank, Badre - 2012.pdf:pdf},
issn = {1460-2199},
journal = {Cerebral cortex (New York, N.Y. : 1991)},
keywords = {Computer Simulation,Corpus Striatum,Corpus Striatum: cytology,Corpus Striatum: physiology,Humans,Learning,Learning: physiology,Models,Neural Pathways,Neural Pathways: cytology,Neural Pathways: physiology,Neurological,Neurons,Neurons: physiology,Prefrontal Cortex,Prefrontal Cortex: cytology,Prefrontal Cortex: physiology,Reinforcement (Psychology)},
number = {3},
pages = {509--26},
pmid = {21693490},
title = {{Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: Computational analysis}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3278315{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {22},
year = {2012}
}
@book{Artemyeva2007,
address = {М.},
author = {Артемьева, Е. Ю.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2007/Артемьева - 2007.pdf:pdf},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {136},
publisher = {Издательство ЛКИ},
title = {{Психология субъективной семантики}},
year = {2007}
}
@article{Heintz2010,
abstract = {Engineering autonomous agents that display rational and goal-directed behavior in dynamic physical environments requires a steady flow of information from sensors to high-level reasoning components. However, while sensors tend to generate noisy and incomplete quantitative data, reasoning often requires crisp symbolic knowledge. The gap between sensing and reasoning is quite wide, and cannot in general be bridged in a single step. Instead, this task requires a more general approach to integrating and organizing multiple forms of information and knowledge processing on different levels of abstraction in a structured and principled manner. We propose knowledge processing middleware as a systematic approach to organizing such processing. Desirable properties are presented and motivated. We argue that a declarative stream-based system is appropriate for the required functionality and present DyKnow, a concrete implemented instantiation of stream-based knowledge processing middleware with a formal semantics. Several types of knowledge processes are defined and motivated in the context of a UAV traffic monitoring application. In the implemented application, DyKnow is used to incrementally bridge the sense-reasoning gap and generate partial logical models of the environment over which metric temporal logical formulas are evaluated. Using such formulas, hypotheses are formed and validated about the type of vehicles being observed. DyKnow is also used to generate event streams representing for example changes in qualitative spatial relations, which are used to detect traffic violations expressed as declarative chronicles. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Heintz, Fredrik and Kvarnstrom, Jonas and Doherty, Patrick},
doi = {10.1016/j.aei.2009.08.007},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Advanced Engineering Informatics/2010/Heintz, Kvarnstrom, Doherty - 2010.pdf:pdf},
isbn = {1474-0346},
issn = {14740346},
journal = {Advanced Engineering Informatics},
number = {1},
pages = {14--26},
publisher = {Elsevier Ltd},
title = {{Bridging the sense-reasoning gap: DyKnow - Stream-based middleware for knowledge processing}},
url = {http://dx.doi.org/10.1016/j.aei.2009.08.007},
volume = {24},
year = {2010}
}
@article{Schneider1999,
abstract = {This paper addresses the issue of how visual-spatial working memory, attention, and scene representation are related. The first section introduces a modified two-stage conception of visual-spatial processing. "Stage one" refers to low-level visual-spatial processing and computes in parallel for the currently available retinal information "object candidates," here called "visual-spatial units." An attentional process called "unit selection" allows access to stage two for one of these units at a time. Stage two contains high-level visual-spatial information that can be used for goal-directions (e.g., verbal report, grasping). It consists of three parallel processing streams. First, the currently selected unit is recognized; second, a spatial-motor program for the selected unit is computed; and third, an "object file" is set up for the selected unit. An object file contains temporary episodic representations of detailed high-level visual-spatial attributes of an "object" plus an "index." An index acts as a pointer and is bound via temporary connections to the attributes of the file. Section two of this paper specifies one part of stage two in more detail, namely visual-spatial working memory (VSWM). It can contain up to four object files. A first central claim is that during sensory-based processing for working memory ("access"), one object file is always "on-line," and up to three other object files are "off-line". A second central claim is that the process of setting up an object file depends on the number and the activation level of already stored files. Based on the concept of activation-based competition between object files, it is postulated that the more files that are stored and the higher their activation is, the longer it takes for a newly set up object file to reach a sufficient level of activation. Activation-based competition is also used to explain "short-term forgetting" by "interference." A third central claim about VSWM is that a "refreshment" process exists that increases the activation level of an index of an object file in order to prevent forgetting or in order to bring the file back to the state of controlling the current action. Finally, section three gives a selective look at a number of experimental data such as the attentional blink, backward masking, dwell time effects, transsaccadic memory, and change blindness. New explanations are offered and new predictions made.},
author = {Schneider, W X},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Psychological research/1999/Schneider - 1999.pdf:pdf},
issn = {0340-0727},
journal = {Psychological research},
keywords = {Attention,Attention: physiology,Cognitive Science,Humans,Memory,Models,Perceptual Masking,Psychological,Psychophysics,Short-Term,Short-Term: physiology,Space Perception,Space Perception: physiology,Visual Perception,Visual Perception: physiology},
number = {2-3},
pages = {220--36},
pmid = {10472201},
title = {{Visual-spatial working memory, attention, and scene representation: a neuro-cognitive theory}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10472201},
volume = {62},
year = {1999}
}
@article{Chuvgunova2004,
abstract = {Целью данной статьи является обобщение и сопоставление результатов психологических исследований феномена планирования, а также анализ методов изучения планирования в психологии. В статье осуществлен аналитический обзор исследований феномена планирования в когнитивной психологии, нейропсихологии, теории деятельности.},
author = {Чувгунова, О. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Психологические исследования/2015/Чувгунова - 2015.pdf:pdf},
journal = {Психологические исследования},
keywords = {деятельность,исполнительные функции,когнитивная психология,нейропсихология,планирование},
number = {43},
pages = {11},
title = {{Планирование как предмет психологического исследования}},
url = {http://psystudy.ru/index.php/num/2015v8n43/1191-chuvgunova43.html ?},
volume = {8},
year = {2015}
}
@article{Borji2013,
abstract = {Modeling visual attention--particularly stimulus-driven, saliency-based attention--has been a very active research area over the past 25 years. Many different models of attention are now available which, aside from lending theoretical contributions to other fields, have demonstrated successful applications in computer vision, mobile robotics, and cognitive systems. Here we review, from a computational perspective, the basic concepts of attention implemented in these models. We present a taxonomy of nearly 65 models, which provides a critical comparison of approaches, their capabilities, and shortcomings. In particular, 13 criteria derived from behavioral and computational studies are formulated for qualitative comparison of attention models. Furthermore, we address several challenging issues with models, including biological plausibility of the computations, correlation with eye movement datasets, bottom-up and top-down dissociation, and constructing meaningful performance measures. Finally, we highlight current research trends in attention modeling and provide insights for future.},
author = {Borji, Ali and Itti, Laurent},
doi = {10.1109/TPAMI.2012.89},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/IEEE transactions on pattern analysis and machine intelligence/2013/Borji, Itti - 2013.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Animals,Attention,Attention: physiology,Computer Simulation,Fixation,Humans,Models,Neurological,Ocular,Ocular: physiology,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
number = {1},
pages = {185--207},
pmid = {22487985},
title = {{State-of-the-art in visual attention modeling}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22487985},
volume = {35},
year = {2013}
}
@article{Chernavskaya2015,
abstract = {Abstract This article represents an extension of authors' previous papers (Chernavskaya, Chernavskii, Karp, Nikitin, {\&} Shchepetov, 2012, 2013) in modeling cognitive systems on the base of the Dynamical Theory of Information. The paper focuses on the problem of account for emotions in artificial system. The main hypothesis consists in the assumption that emotions inherent in a living system could be simulated by variation of amplitude of the occasional component (noise) inherently embedded into the architecture of artificial system. Within this concept, increasing noise amplitude should correspond to negative emotions (anxiety), while its decreasing provides positive emotions (relaxation, pleasure). A rapid up-and-down spike in the noise amplitude could imitate a laugh. This hypothesis is secured by incorporation of an additional dynamical variable that represents an analogy to the compound of neural mediators in human beings. The system of linked equations in terms of “noise amplitude – neurotransmitter compound” is proposed to describe mutual influence of the cognitive process and emotional component. The model permits to reproduce qualitatively certain prominent effects typical for human emotional reactions (like stress and shock).},
author = {Chernavskaya, O D and Chernavskii, D S and Karp, V P and Nikitin, A P and Shchepetov, D S and Rozhylo, Ya.A.},
doi = {http://dx.doi.org/10.1016/j.bica.2015.04.009},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2015/Chernavskaya et al. - 2015.pdf:pdf},
issn = {2212-683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Emotions,Humor,Information,Learning,Noise amplitude,Unexpectedness},
pages = {144--154},
publisher = {Elsevier B.V.},
title = {{An architecture of the cognitive system with account for emotional component}},
url = {http://www.sciencedirect.com/science/article/pii/S2212683X15000183},
volume = {12},
year = {2015}
}
@inproceedings{Roy2014,
author = {Roy, Bc and Vosoughi, Soroush and Roy, Deb},
booktitle = {Proceedings of the 15th Annual Conference of the International Speech Communication Association},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the 15th Annual Conference of the International Speech Communication Association/2014/Roy, Vosoughi, Roy - 2014.pdf:pdf},
issn = {19909772},
keywords = {semiotics},
mendeley-tags = {semiotics},
pages = {14--18},
title = {{Grounding language models in spatiotemporal context}},
url = {http://www.media.mit.edu/cogmac/publications/RVR{\_}interspeech2014.pdf},
year = {2014}
}
@article{Gallese1996,
author = {Gallese, Vittorio and Fadiga, Luciano and Fogassi, Leonardo and Rizzolatti, Giacomo},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Brain/1996/Gallese et al. - 1996.pdf:pdf},
journal = {Brain},
keywords = {action encoding,macaque monkey,premotor cortex,visual responses},
number = {5},
pages = {593--609},
title = {{Action recognition in the premotor cortex}},
volume = {119},
year = {1996}
}
@article{Ivanitsky2010,
author = {Иваницкий, А. М.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Вестник РАН/2010/Иваницкий - 2010.pdf:pdf},
journal = {Вестник РАН},
keywords = {consciousness},
language = {russian},
mendeley-tags = {consciousness},
number = {5-6},
pages = {447--455},
title = {{Наука о мозге на пути к решению проблемы сознания}},
volume = {80},
year = {2010}
}
@inproceedings{2015a,
address = {Москва},
author = {Анохин, К. В.},
booktitle = {4th International Interdisciplinary Conference on “MODERN PROBLEMS IN SYSTEMIC REGULATION OF PHYSIOLOGICAL FUNCTIONS” Сonference proceedings},
doi = {10.12737/12261},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/4th International Interdisciplinary Conference on “MODERN PROBLEMS IN SYSTEMIC REGULATION OF PHYSIOLOGICAL FUNCTIONS” Сonference proceedings/2015/Анохин - 2015.pdf:pdf},
keywords = {гиперсети,когнитом,коннектом,мозг,функциональные системы},
pages = {3--5},
title = {{Когнитом: сетевое расширение теории функциональных систем}},
year = {2015}
}
@book{Leotiev2010,
abstract = {424},
address = {М.},
author = {Леонтьев, Алексей Николаевич},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2010/Леонтьев - 2010.pdf:pdf},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {450},
publisher = {Смысл, Academia},
title = {{Лекции по общей психологии}},
year = {2010}
}
@article{Ivanitsky1997,
author = {Ivanitsky, A. M.},
journal = {Neuroscience and Behavioral Physiology},
number = {4},
pages = {414--426},
title = {{Information synthesis in key parts of the cerebral cortex as the basis of subjective experience}},
volume = {27},
year = {1997}
}
@article{Churchill2014,
author = {Churchill, Alexander W. and Fernando, Chrisantha},
doi = {10.1007/s12065-014-0121-7},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Evolutionary Intelligence/2014/Churchill, Fernando - 2014.pdf:pdf},
issn = {1864-5909},
journal = {Evolutionary Intelligence},
keywords = {cognitive architecture {\'{a}} darwinian,neurodynamics {\'{a}} open-ended evolution,{\'{a}} robotics},
number = {3},
pages = {169--182},
title = {{An evolutionary cognitive architecture made of a bag of networks}},
url = {http://link.springer.com/10.1007/s12065-014-0121-7},
volume = {7},
year = {2014}
}
@inproceedings{Welke2013,
abstract = {Providing autonomous humanoid robots with the abilities to react in an adaptive and intelligent manner involves low level control and sensing as well as high level reasoning. However, the integration of both levels still remains challenging due to the representational gap between the continuous state space on the sensorimotor level and the discrete symbolic entities used in high level reasoning. In this work, we approach the problem of learning a representation of the space which is applicable on both levels. This representation is grounded on the sensorimotor level by means of exploration and on the language level by making use of common sense knowledge. We demonstrate how spatial knowledge can be extracted from these two sources of experience. Combining the resulting knowledge in a systematic way yields a solution to the grounding problem which has the potential to substantially decrease the learning effort.},
author = {Welke, Kai and Kaiser, Peter and Kozlov, Alexey and Adermann, Nils and Asfour, Tamim and Lewis, Mike and Steedman, Mark},
booktitle = {2013 13th IEEE-RAS International Conference on Humanoid Robots (Humanoids)},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/2013 13th IEEE-RAS International Conference on Humanoid Robots (Humanoids)/2013/Welke et al. - 2013.pdf:pdf},
isbn = {9781479926183},
pages = {484--491},
title = {{Grounded Spatial Symbols for Task Planning Based on Experience}},
year = {2013}
}
@incollection{Novianto2010a,
abstract = {The ASMO Cognitive Architecture has been developed to support key capabilities: attention, awareness and self-modification. In this paper we describe the underlying attention model in ASMO. The ASMO Cognitive Architecture is inspired by a biological attention theory, and offers a mechanism for directing and creating behaviours, beliefs, anticipation, discovery, expectations and changes in a complex system. Thus, our attention based architecture provides an elegant solution to the problem of behaviour development and behaviour selection particularly when the behaviours are mutually incompatible.},
author = {Novianto, R and Johnston, B and Williams, M A},
booktitle = {Biologically Inspired Cognitive Architectures 2010},
doi = {10.3233/978-1-60750-661-4-98},
editor = {Samsonovich, A. V and Johannsdottir, K. R. and Chella, A. and Goertzel, B.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures 2010/2010/Novianto, Johnston, Williams - 2010.pdf:pdf},
isbn = {9781607506607},
keywords = {ASMO,Attention,Cognitive Architecture,Dynamic Behaviour,Self-modification,cog{\_}arch},
mendeley-tags = {cog{\_}arch},
pages = {98--105},
publisher = {IOS Press},
series = {Frontiers in Artificial Intelligence and Applications},
title = {{Attention in ASMO cognitive architecture}},
year = {2010}
}
@book{Xu2016,
editor = {Xu, Kevin S. and Reitter, David and Lee, Dongwon and Osgood, Nathaniel},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2016/Unknown - 2016.pdf:pdf},
isbn = {9783319399300},
pages = {422},
publisher = {Springer International Publishing},
title = {{Social, Cultural, and Behavioral Modeling}},
year = {2016}
}
@article{Thilakarathne2015a,
abstract = {Human awareness under different circumstances is complex and non-trivial to understand. Nevertheless, due to the importance of awareness for safety and efficiency in many domains (e.g., the aviation domain), it is necessary to study the processes behind situation awareness, to eliminate possible errors in action selection that may lead to disasters. Interesting models for situation awareness have been presented, mainly from an ecological psychology perspective, but they are debatable with respect to the latest neurocognitive evidences. With the developments in brain imaging and recording techniques, more and more detailed information on complex cognitive processes becomes available. This provides room to further investigate the mechanisms behind many cognitive phenomena, including situation awareness. This paper presents a computational cognitive agent model for situation awareness from the perspective of action selection, which is inspired by neurocognitive evidences. The model integrates bottom-up and top-down cognitive processes, related to various cognitive states: perception, desires, attention, intention, (prior and retrospective) awareness, ownership, feeling, and communication. Based on the model, various cognitive effects can be explained, such as perceptual load, predictive processes, inferential processes, cognitive controlling, unconscious bias, and conscious bias. A model like this will be useful in domains that benefit from complex simulations of socio-technical systems (e.g. the aviation domain) based on computational models of human behaviour. In such domains, existing agent-based simulations are limited, since most of the agent models do not include realistic nature-inspired processes. The validity of the model is illustrated based on simulations for the aviation domain, focusing on a particular situation where an agent has biased perception, poor comprehension, habitual driven projection, and conflict between prior and retrospective effects on action execution.},
author = {Thilakarathne, Dilhan J.},
doi = {10.1016/j.bica.2015.04.010},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2015/Thilakarathne - 2015.pdf:pdf},
isbn = {2212-683X},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Bottom-up,Cognitive modelling,Prior and retrospective awareness,Situation awareness,Top-down},
pages = {77--104},
publisher = {Elsevier B.V.},
title = {{Modelling of situation awareness with perception, attention, and prior and retrospective awareness}},
url = {http://dx.doi.org/10.1016/j.bica.2015.04.010},
volume = {12},
year = {2015}
}
@inproceedings{Dura-Bernal2011,
author = {Dura-Bernal, Salvador and Wennekers, Thomas and Denham, Susan L.},
booktitle = {45th Annual Conference on Information Sciences and Systems},
doi = {10.1109/CISS.2011.5766096},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/45th Annual Conference on Information Sciences and Systems/2011/Dura-Bernal, Wennekers, Denham - 2011.pdf:pdf},
isbn = {978-1-4244-9846-8},
keywords = {bayesian belief propagation,hierarchical percep-},
pages = {1--6},
publisher = {IEEE},
title = {{Modelling object perception in cortex: Hierarchical Bayesian networks and belief propagation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5766096},
year = {2011}
}
@incollection{Osipov2015c,
abstract = {In this paper a sign-based or semiotic formalism is considered. The concept of sign arose in the framework of semiotics. Neurophysiological and psychological researches indicate sign-based structures, which are the basic elements of the world model of a human subject. These elements are formed during his/her activity and communication. In this formalism it was possible to formulate and solve the problem of goal-setting, i.e. generating the goal of behavior.},
author = {Osipov, Gennady S.},
booktitle = {Advances in Artificial Intelligence and Soft Computing},
doi = {10.1007/978-3-319-27060-9_1},
editor = {Sidorov, Grigori and Galicia-Haro, Sof{\'{i}}a N.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Advances in Artificial Intelligence and Soft Computing/2015/Osipov - 2015(2).pdf:pdf},
isbn = {978-3-319-27059-3},
keywords = {15-07-06214,image,meaning,osipov,relationship on the set of signs,sign,significance,the synthesis of behavior},
mendeley-tags = {15-07-06214,osipov},
pages = {3--11},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Signs-Based vs. Symbolic Models}},
url = {http://link.springer.com/10.1007/978-3-319-27060-9{\_}1},
year = {2015}
}
@article{Albus2010,
abstract = {The brain is first and foremost a control system that is capable of building an internal representation of the external world, and using this representation to make decisions, set goals and priorities, formulate plans, and control behavior with intent to achieve its goals. The internal representation is distributed throughout the brain in two forms: (1) firmware embedded in synaptic connections and axon-dendrite circuitry, and (2) dynamic state-variables encoded in the firing rates of neurons in computational loops in the spinal cord, midbrain, subcortical nuclei, and arrays of cortical columns. It assumes that clusters and arrays of neurons are capable of computing logical predicates, smooth arithmetic functions, and matrix transformations over a space defined by large input vectors and arrays. Feedback from output to input of these neural computational units enable them to function as finite-state-automata (fsa), Markov decision processes (MDP), or delay lines in processing signals and generating strings and grammars. Thus, clusters of neurons are capable of parsing and generating language, decomposing tasks, generating plans, and executing scripts. In the cortex, neurons are arranged in arrays of cortical columns that interact in tight loops with their underlying subcortical nuclei. It is hypothesized that these circuits compute sophisticated mathematical and logical functions that maintain and use complex abstract data structures. It is proposed that cortical hypercolumns together with their underlying thalamic nuclei can be modeled as a cortical computational unit (CCU) consisting of a frame-like data structure (containing attributes and pointers) plus the computational processes and mechanisms required to maintain it and use it for perception cognition, and sensory-motor behavior. In sensory processing areas of the brain, CCU processes enable focus of attention, segmentation, grouping, and classification. Pointers stored in CCU frames define relationships that link pixels and signals to objects and events in situations and episodes. CCU frame pointers also link objects and events to class prototypes and overlay them with meaning and emotional values. In behavior generating areas of the brain, CCU processes make decisions, set goals and priorities, generate plans, and control behavior. In general, CCU pointers are used to define rules, grammars, procedures, plans, and behaviors. CCU pointers also define abstract data structures analogous to lists, frames, objects, classes, rules, plans, and semantic nets. It is suggested that it may be possible to reverse engineer the human brain at the CCU level of fidelity using next-generation massively parallel computer hardware and software.},
author = {Albus, James S.},
doi = {10.1016/j.ins.2009.12.031},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Information Sciences/2010/Albus - 2010.pdf:pdf},
isbn = {0020-0255},
issn = {00200255},
journal = {Information Sciences},
keywords = {Brain modeling,Cognitive modeling,Human neocortex,Image processing,Knowledge representation,Perception,Reverse engineering the brain,Segmentation,Signals to symbols},
number = {9},
pages = {1519--1554},
publisher = {Elsevier Inc.},
title = {{A model of computation and representation in the brain}},
url = {http://dx.doi.org/10.1016/j.ins.2009.12.031},
volume = {180},
year = {2010}
}
@article{Chersi2013,
abstract = {Dual-system theories postulate that actions are supported either by a goal-directed or by a habit-driven response system. Neuroimaging and anatomo-functional studies have provided evidence that the prefrontal cortex plays a fundamental role in the first type of action control, while internal brain areas such as the basal ganglia are more active during habitual and overtrained responses. Additionally, it has been shown that areas of the cortex and the basal ganglia are connected through multiple parallel "channels", which are thought to function as an action selection mechanism resolving competitions between alternative options available in a given context. In this paper we propose a multi-layer network of spiking neurons that implements in detail the thalamo-cortical circuits that are believed to be involved in action learning and execution. A key feature of this model is that neurons are organized in small pools in the motor cortex and form independent loops with specific pools of the basal ganglia where inhibitory circuits implement a multistep selection mechanism. The described model has been validated utilizing it to control the actions of a virtual monkey that has to learn to turn on briefly flashing lights by pressing corresponding buttons on a board. When the animal is able to fluently execute the task the button-light associations are remapped so that it has to suppress its habitual behavior in order to execute goal-directed actions. The model nicely shows how sensory-motor associations for action sequences are formed at the cortico-basal ganglia level and how goal-directed decisions may override automatic motor responses.},
author = {Chersi, Fabian and Mirolli, Marco and Pezzulo, Giovanni and Baldassarre, Gianluca},
doi = {10.1016/j.neunet.2012.11.009},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural networks the official journal of the International Neural Network Society/2013/Chersi et al. - 2013.pdf:pdf},
issn = {1879-2782},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {AMPA,AMPA: physiology,Action Potentials,Action Potentials: physiology,Animals,Basal Ganglia,Basal Ganglia: cytology,Basal Ganglia: physiology,Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: physiology,Goals,Habits,Haplorhini,Models,Motor Cortex,Motor Cortex: cytology,Motor Cortex: physiology,N-Methyl-D-Aspartate,N-Methyl-D-Aspartate: physiology,Neural Inhibition,Neural Inhibition: physiology,Neural Pathways,Neurological,Neurons,Neurons: physiology,Neurotransmitter Agents,Neurotransmitter Agents: physiology,Problem Solving,Problem Solving: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Receptors,Somatosensory Cortex,Somatosensory Cortex: cytology,Somatosensory Cortex: physiology,Thalamus,Thalamus: cytology,Thalamus: physiology,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology},
pages = {212--24},
pmid = {23266482},
publisher = {Elsevier Ltd},
title = {{A spiking neuron model of the cortico-basal ganglia circuits for goal-directed and habitual action learning}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23266482},
volume = {41},
year = {2013}
}
@phdthesis{Hanford2011,
author = {Hanford, Scott D.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Hanford - 2011.pdf:pdf},
number = {December},
school = {The Pennsylvania State University},
title = {{A cognitive robotic system based on the SOAR cognitive architecture for mobile robot navigation, search and mapping mission}},
year = {2011}
}
@article{Battaglia2011,
abstract = {After acquisition, memories underlie a process of consolidation, making them more resistant to interference and brain injury. Memory consolidation involves systems-level interactions, most importantly between the hippocampus and associated structures, which takes part in the initial encoding of memory, and the neocortex, which supports long-term storage. This dichotomy parallels the contrast between episodic memory (tied to the hippocampal formation), collecting an autobiographical stream of experiences, and semantic memory, a repertoire of facts and statistical regularities about the world, involving the neocortex at large. Experimental evidence points to a gradual transformation of memories, following encoding, from an episodic to a semantic character. This may require an exchange of information between different memory modules during inactive periods. We propose a theory for such interactions and for the formation of semantic memory, in which episodic memory is encoded as relational data. Semantic memory is modeled as a modified stochastic grammar, which learns to parse episodic configurations expressed as an association matrix. The grammar produces tree-like representations of episodes, describing the relationships between its main constituents at multiple levels of categorization, based on its current knowledge of world regularities. These regularities are learned by the grammar from episodic memory information, through an expectation-maximization procedure, analogous to the inside-outside algorithm for stochastic context-free grammars. We propose that a Monte-Carlo sampling version of this algorithm can be mapped on the dynamics of "sleep replay" of previously acquired information in the hippocampus and neocortex. We propose that the model can reproduce several properties of semantic memory such as decontextualization, top-down processing, and creation of schemata.},
author = {Battaglia, Francesco P. and Pennartz, Cyriel M. A.},
doi = {10.3389/fncom.2011.00036},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in computational neuroscience/2011/Battaglia, Pennartz - 2011.pdf:pdf},
issn = {1662-5188},
journal = {Frontiers in computational neuroscience},
keywords = {episodic memory,memory consolidation,sleep r,sleep replay,stochastic grammars},
number = {August},
pages = {36},
pmid = {21887143},
title = {{The construction of semantic memory: grammar-based representations learned from relational episodic information}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3157741{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2011}
}
@article{Sharaev2014,
author = {Шараев, М. Г. and Мнацаканян, Е. В.},
doi = {10.7868/S0044467714060100},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Журнал Высшей Нервной Деятельности Им. И. В. Павлова/2014/Шараев, Мнацаканян - 2014.pdf:pdf},
issn = {0044-4677},
journal = {Журнал Высшей Нервной Деятельности Им. И. В. Павлова},
keywords = {10,7868,bayesian modeling,doi,dynamic causal modeling,eeg,ef,erp,fective connectivity,oddball paradigm,s0044467714060100,visual stimuli},
language = {russian},
number = {6},
pages = {627--638},
title = {{Динамическое моделирование вызванного ответа на простые стимулы в зрительной оддбол-парадигме}},
url = {http://elibrary.ru/item.asp?doi=10.7868/S0044467714060100},
volume = {64},
year = {2014}
}
@article{Kelley2006,
abstract = {Abstract: This paper describes the ongoing development of a robotic control architecture that was inspired by computational cognitive architectures from the discipline of cognitive psychology. The robotic control architecture combines symbolic and subsymbolic ...},
author = {Kelley, Troy Dale},
doi = {10.5772/5736},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/International Journal of Advanced Robotic Systems/2006/Kelley - 2006.pdf:pdf},
isbn = {9780819481740},
issn = {17298806},
journal = {International Journal of Advanced Robotic Systems},
keywords = {Cognitive architecture,Cognitive psychology,Robotic architecture,Robotic control},
number = {3},
pages = {219--222},
title = {{Developing a psychologically inspired cognitive architecture for robotic control: The Symbolic and Subsymbolic Robotic Intelligence Control System (SS-RICS)}},
volume = {3},
year = {2006}
}
@article{Plunkett1992,
abstract = {Describes a connectionist model of concept formation and vocabulary growth that auto-associates image representations and their associated labels. The model implements several well-known findings in the literature on early semantic development. It is shown how these apparently disparate findings can be attributed to the operation of a single underlying mechanism. The model represents a 1st step toward providing a formal explanation of the emergence of symbolic behavior in young children. (PsycLIT Database Copyright 1994 American Psychological Assn, all rights reserved)},
author = {Plunkett, Kim and Sinha, Chris and M{\o}ller, Martin F. and Strandsby, Ole},
doi = {10.1080/09540099208946620},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Connection Science/1992/Plunkett et al. - 1992.pdf:pdf},
isbn = {0954-0091},
issn = {0954-0091},
journal = {Connection Science},
keywords = {symb{\_}ground},
mendeley-tags = {symb{\_}ground},
number = {3-4},
pages = {293--312},
title = {{Symbol Grounding or the Emergence of Symbols? Vocabulary Growth in Children and a Connectionist Net}},
volume = {4},
year = {1992}
}
@book{Luria2000,
address = {М.},
author = {Лурия, A. Р.},
edition = {3-е изд.},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {512},
publisher = {Академический проект},
title = {{Высшие корковые функции человека и их нарушения при локальных поражениях мозга}},
year = {2000}
}
@article{Itti1998,
author = {Itti, Laurent and Koch, Christof and Niebur, Ernst},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/IEEE Transactions on pattern analysis and machine intelligence/1998/Itti, Koch, Niebur - 1998.pdf:pdf},
journal = {IEEE Transactions on pattern analysis and machine intelligence},
number = {11},
pages = {1254--1259},
title = {{A model of Siliency-Based Visual Attention for Rapid Scene Analysis}},
volume = {20},
year = {1998}
}
@article{Rockland2010,
abstract = {"Column," like "gene," has both conceptual and linguistic shortcomings. The simple question "what is a column" is not easy to answer and the word itself is not easy to replace. In the present article, I have selected five points, in no way comprehensive or canonical, but which may nevertheless serve as a prompt and aid for further discussions and re-evaluation. These are: that anatomical columns are not solid structures, that they are part of locally interdigitating systems, that any delimited column also participates in a widely distributed network, that columns are not an obligatory cortical feature, and that columns (as "modules") occur widely in the brain in non-cortical structures. I focus on the larger scale macrocolumns, mainly from an anatomical perspective. My position is that cortical organization is inherently dynamic and likely to incorporate multiple processing styles. One can speculate that the distributed mappings within areas like piriform cortex may resemble at least one mode of neocortical processing strategy.},
author = {Rockland, Kathleen S},
doi = {10.3389/fnana.2010.00022},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in neuroanatomy/2010/Rockland - 2010.pdf:pdf},
issn = {1662-5129},
journal = {Frontiers in neuroanatomy},
keywords = {VGLUT2,Zinc,distributed,divergence,honeycomb,ocular dominance},
language = {English},
pages = {22},
pmid = {20589097},
publisher = {Frontiers},
title = {{Five points on columns}},
url = {http://journal.frontiersin.org/Journal/10.3389/fnana.2010.00022/full},
volume = {4},
year = {2010}
}
@incollection{Stanovich2009,
abstract = {Building upon work which considers the implications dual-process theory for the great rationality debate in cognitive science, this chapter advances that discussion, first by discussing additions and complications to dual-process theory and then by working through the implications of these ideas for our view of human rationality. It argues that System 2 needs to be understood in terms of two levels of processing: the algorithmic and the reflective.},
author = {Stanovich, Keith E},
booktitle = {In two minds: Dual processes and beyond},
doi = {10.1093/acprof:oso/9780199230167.003.0003},
editor = {Evans, Jonathan and Frankish, Keith},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/In two minds Dual processes and beyond/2009/Stanovich - 2009.pdf:pdf},
isbn = {9780199230167},
keywords = {System 2,cognitive science,dual-process theory,human rationality},
pages = {55--88},
publisher = {Oxford University Press},
title = {{Distinguishing the reflective, algorithmic, and autonomous minds: Is it time for a tri-process theory?}},
url = {http://keithstanovich.com/Site/Research{\_}on{\_}Reasoning{\_}files/Stanovich{\_}Two{\_}MInds.pdf},
year = {2009}
}
@article{Maass,
abstract = {Highlights:  Computational role of transient network states  Simultaneous recordings from many neurons constrain computational models  Stochastic state transitions point to Markov chain computations  Ongoing network rewiring and compensation through synaptic sampling Abstract Experimental methods in neuroscience, such as Ca-imaging and recordings with multi-electrode arrays, are advancing at a rapid pace. They produce insight into the activity of large numbers of neurons and plastity processes in the brains of awake and behaving animals. These data provide new constraints for modelling neural computations and learning processes that underlie perception, cognition, and behaviour. I will discuss in this short review four such constraints: Inherent recurrent network activity and heterogeneous dynamic properties of neurons and synapses, stereotypical spatio-temporal activity patterns, high trial-to-trial variability of network responses, and functional stability in spite of permanently ongoing changes in the network. I will explain that these constraints provide hints to underlying principles of brain computation and learning. Constraint/Principle 1: Neural circuits are highly recurrent networks of neurons and synapses with diverse dynamic properties},
author = {Maass, Wolfgang},
doi = {10.1016/j.cobeha.2016.06.003},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Current Opinion in Behavioral Sciences/2016/Maass - 2016.pdf:pdf},
issn = {23521546},
journal = {Current Opinion in Behavioral Sciences},
pages = {81--92},
publisher = {The Author(s)},
title = {{Searching for Principles of Brain Computation}},
url = {http://dx.doi.org/10.1016/j.cobeha.2016.06.003},
volume = {11},
year = {2016}
}
@article{Barrera2014,
author = {Barrera, Alejandra and Tejera, Gonzalo and Llofriu, Martin and Weitzenfeld, Alfredo},
doi = {10.1080/13875868.2014.961602},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Spatial Cognition {\&} Computation/2014/Barrera et al. - 2014.pdf:pdf},
issn = {1387-5868},
journal = {Spatial Cognition {\&} Computation},
number = {1},
pages = {27--59},
title = {{Learning Spatial Localization: From Rat Studies to Computational Models of the Hippocampus}},
url = {http://www.tandfonline.com/doi/abs/10.1080/13875868.2014.961602},
volume = {15},
year = {2014}
}
@phdthesis{Price2011a,
author = {Price, Ryan William},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Price - 2011.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Price - 2011(2).pdf:pdf},
keywords = {htm},
mendeley-tags = {htm},
pages = {115},
school = {Portland State University},
title = {{Hierarchical Temporal Memory Cortical Learning Algorithm for Pattern Recognition on Multi-core Architectures}},
year = {2011}
}
@book{Petrenko2009,
address = {М.},
author = {Петренко, В. Ф.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2009/Петренко - 2009.pdf:pdf},
isbn = {9785948811000},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {440},
publisher = {Новый хронограф},
title = {{Многомерное сознание: психосемантическая парадигма}},
year = {2009}
}
@book{Lotman2000,
address = {С.-Петербург},
author = {Лотман, Ю. М.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2000/Лотман - 2000.pdf:pdf},
isbn = {5210014886},
keywords = {semiotics},
language = {russian},
mendeley-tags = {semiotics},
pages = {704},
publisher = {Искусство-СПБ},
title = {{Семиосфера}},
year = {2000}
}
@incollection{Hois2008,
abstract = {We address the problem of relating natural language descriptions of spatial situations with spatial logical calculi, focusing on projective terms (orientations). We provide a formalism based on the theory of -connections that connects natural language and spatial calculi. Semantics of linguistic expressions are specified in a linguistically motivated ontology, the Generalized Upper Model. Spatial information is specified as qualitative spatial relationships, namely orientations from the double-cross calculus. This linguistic-spatial connection cannot be adequately formulated without certain contextual, domain-specific aspects. We therefore extend the framework of -connections twofold: (1) external descriptions narrow down the class of intended models, and (2) context-dependencies inherent in natural language descriptions feed back into the representation finite descriptions of necessary context information.},
author = {Hois, Joana and Kutz, Oliver},
booktitle = {Spatial Cognition VI},
doi = {10.1007/978-3-540-87601-4_20},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Spatial Cognition VI/2008/Hois, Kutz - 2008.pdf:pdf},
isbn = {3540876006},
issn = {03029743},
keywords = {Ontologies,Spatial calculi,Spatial language,e-connections},
pages = {266--282},
publisher = {Springer},
series = {Lecture notes in Artificial Intelligence},
title = {{Natural language meets spatial calculi}},
year = {2008}
}
@article{Balaguer2016,
author = {Balaguer, Jan and Spiers, Hugo and Hassabis, Demis and Summerfield, Christopher},
doi = {10.1016/j.neuron.2016.03.037},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neuron/2016/Balaguer et al. - 2016.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {4},
pages = {893--903},
pmid = {27196978},
publisher = {The Authors},
title = {{Neural Mechanisms of Hierarchical Planning in a Virtual Subway Network}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627316300575},
volume = {90},
year = {2016}
}
@article{Lamme2003,
abstract = {Now that the study of consciousness is warmly embraced by cognitive scientists, much confusion seems to arise between the concepts of visual attention and visual awareness. Often, visual awareness is equated to what is in the focus of attention. There are, however, two sets of arguments to separate attention from awareness: a psychological/theoretical one and a neurobiological one. By combining these arguments I present definitions of visual attention and awareness that clearly distinguish between the two, yet explain why attention and awareness are so intricately related. In fact, there seems more overlap between mechanisms of memory and awareness than between those of attention and awareness.},
author = {Lamme, V. a F},
doi = {10.1016/S1364-6613(02)00013-X},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in Cognitive Sciences/2003/Lamme - 2003.pdf:pdf},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {1},
pages = {12--18},
pmid = {12517353},
title = {{Why visual attention and awareness are different}},
volume = {7},
year = {2003}
}
@article{Bowden2005,
abstract = {After a person has become stuck on a problem, they sometimes achieve a clear and sudden solution through insight - the so-called Aha! experience. Because of its distinctive experience, the origins and characteristics of insight have received considerable attention historically in psychological research. However, despite considerable progress in characterizing insight, the underlying mechanisms remain mysterious. We argue that research on insight could be greatly advanced by supplementing traditional insight research, which depends on a few complex problems, with paradigms common in other domains of cognitive science. We describe a large set of mini-insight problems to which multiple methods can be applied, together with subjective reports to identify insight problem-solving. Behavioral priming and neuroimaging methods are providing evidence about what, where, and how neural activity occurs during insight. Such evidence constrains theories of component processes, and will help to demystify insight. {\textcopyright} 2005 Elsevier Ltd. All rights reserved.},
author = {Bowden, Edward M. and Jung-Beeman, Mark and Fleck, Jessica and Kounios, John},
doi = {10.1016/j.tics.2005.05.012},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in Cognitive Sciences/2005/Bowden et al. - 2005.pdf:pdf},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {7},
pages = {322--328},
pmid = {15953756},
title = {{New approaches to demystifying insight}},
volume = {9},
year = {2005}
}
@article{Mensky2004,
author = {Менский, М. Б.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Вопросы философии/2004/Менский - 2004.pdf:pdf},
journal = {Вопросы философии},
language = {russian},
number = {6},
pages = {64--74},
title = {{Квантовая механика, сознание и мост между двумя культурами}},
year = {2004}
}
@article{Jaynes1986,
author = {Jaynes, Julian},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Canadian Psychology/1986/Jaynes - 1986.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Canadian Psychology/1986/Jaynes - 1986.rtf:rtf},
journal = {Canadian Psychology},
keywords = {bicameral mind,consciousness},
number = {2},
pages = {128--148},
title = {{Consciousness and the Voices of the Mind}},
volume = {27},
year = {1986}
}
@article{Nekorkon2008,
author = {Некоркин, В. И.},
doi = {10.3367/UFNr.0178.200803f.0313},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/2008/Некоркин - 2008.pdf:pdf},
issn = {0042-1294},
journal = {Успехи физических наук},
language = {russian},
number = {3},
pages = {313--323},
title = {{Нейронные колебания и волны в нейродинамике}},
url = {http://ufn.ru/ru/articles/2008/3/f/},
volume = {178},
year = {2008}
}
@article{Targon2016,
abstract = {Through semiotic modelling, a system can retrieve and manipulate its own representational formats to interpret a series of observations; this is in contrast to information processing approaches that require represen- tational formats to be specified beforehand and thus limit the semantic properties that the system can experience. Our semiotic cognitive automaton is driven only by the obser- vations it makes and therefore operates based on grounded symbols. A best-case scenario for our automaton involves observations that are univocally interpreted—i.e. distinct observation symbols—and that make reference to a reality characterised by ‘‘hard constraints''. Arithmetic offers such a scenario. The gap between syntax and semantics is also subtle in the case of calculations. Our automaton starts without any a priori knowledge of mathematical for- malisms and not only learns the syntactical rules by which arithmetic operations are solved but also reveals the true meaning of numbers by means of second-order reasoning.},
author = {Targon, Valerio},
doi = {10.1007/s12559-015-9378-0},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Computation/2016/Targon - 2016.pdf:pdf},
issn = {1866-9956},
journal = {Cognitive Computation},
keywords = {Abductive reasoning,Desmogram,Extended correlation,Second-order reasoning,Semiotic modelling,Symbol grounding problem,abductive reasoning,correlation {\'{a}} desmogram {\'{a}},modelling {\'{a}} second-order reasoning,semiotic,symbol grounding problem {\'{a}},{\'{a}} extended},
publisher = {Springer US},
title = {{Learning the Semantics of Notational Systems with a Semiotic Cognitive Automaton}},
url = {http://link.springer.com/10.1007/s12559-015-9378-0},
year = {2016}
}
@article{Samsonovich2010,
author = {Samsonovich, Alexei V.},
doi = {10.3233/978-1-60750-661-4-195},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in Artificial Intelligence and Applications/2010/Samsonovich - 2010.pdf:pdf},
isbn = {9781607506607},
issn = {09226389},
journal = {Frontiers in Artificial Intelligence and Applications},
keywords = {Cognitive architectures,model and data sharing,unifying framework},
pages = {195--244},
title = {{Toward a unified catalog of implemented cognitive architectures}},
volume = {221},
year = {2010}
}
@article{Ivanitsky1994,
author = {Иваницкий, Г. Р. and Медвинский, А. Б. and Цыганов, М. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/1994/Иваницкий, Медвинский, Цыганов - 1994.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {10},
pages = {1041--1072},
title = {{От динамики популяционных автоволн, формируемых живыми клетками, к нейроинформатике}},
volume = {164},
year = {1994}
}
@inproceedings{Howard2015,
abstract = {We have created a high-fidelity model of 9 regions of the brain involved in making sense of complex and uncertain situations. Sense making is a proactive form of situation awareness requiring sifting through information of various types to form hypotheses about evolving situations. The MINDS model (Mirroring Intelligence in a Neural Description of Sensemaking) reveals the neural principles and cognitive tradeoffs that explain weaknesses in human reasoning and decision-making.},
author = {Howard, Michael D. and Bhattacharyya, Rajan and Chelian, Suhas E. and Phillips, Matthew E. and Pilly, Praveen K. and Ziegler, Matthias D.},
booktitle = {2015 IEEE Aerospace Conference},
doi = {10.1109/AERO.2015.7118968},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/2015 IEEE Aerospace Conference/2015/Howard et al. - 2015.pdf:pdf},
isbn = {978-1-4799-5379-0},
keywords = {Brain modeling,Cognition,Computational modeling,Decision making,MINDS computational model,Semantics,Tuning,Uncertainty,brain,cognition,decision making,decision-making,human computer interaction,human-system interaction,mirroring intelligence-in-a-neural description-of-,neural nets,neural principle,situation awareness},
pages = {1--16},
publisher = {IEEE},
shorttitle = {Aerospace Conference, 2015 IEEE},
title = {{The neural basis of decision-making during sensemaking: Implications for human-system interaction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7118968},
year = {2015}
}
@article{Rolls2010,
abstract = {A quantitative computational theory of the operation of the hippocampus as an episodic memory system is described. The CA3 system operates as a single attractor or autoassociation network to enable rapid, one-trial associations between any spatial location (place in rodents or spatial view in primates) and an object or reward and to provide for completion of the whole memory during recall from any part. The theory is extended to associations between time and object or reward to implement temporal order memory, also important in episodic memory. The dentate gyrus performs pattern separation by competitive learning to produce sparse representations, producing for example neurons with place-like fields from entorhinal cortex grid cells. The dentate granule cells produce by the very small number of mossy fibre connections to CA3 a randomizing pattern separation effect important during learning but not recall that separates out the patterns represented by CA3 firing to be very different from each other, which is optimal for an unstructured episodic memory system in which each memory must be kept distinct from other memories. The direct perforant path input to CA3 is quantitatively appropriate to provide the cue for recall in CA3, but not for learning. The CA1 recodes information from CA3 to set up associatively learned backprojections to neocortex to allow subsequent retrieval of information to neocortex, providing a quantitative account of the large number of hippocampo-neocortical and neocortical-neocortical backprojections. Tests of the theory including hippocampal subregion analyses and hippocampal NMDA receptor knockouts are described and support the theory. ?? 2010 Elsevier B.V.},
author = {Rolls, Edmund T.},
doi = {10.1016/j.bbr.2010.03.027},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Behavioural Brain Research/2010/Rolls - 2010.pdf:pdf},
isbn = {0166-4328},
issn = {01664328},
journal = {Behavioural Brain Research},
keywords = {Attractor network,Competitive network,Completion,Episodic memory,Hippocampus,Object-place memory,Pattern separation,Recall,Spatial view neurons},
number = {2},
pages = {180--196},
pmid = {20307583},
publisher = {Elsevier B.V.},
title = {{A computational theory of episodic memory formation in the hippocampus}},
url = {http://dx.doi.org/10.1016/j.bbr.2010.03.027},
volume = {215},
year = {2010}
}
@article{Dehaene2011,
abstract = {Recent experimental studies and theoretical models have begun to address the challenge of establishing a causal link between subjective conscious experience and measurable neuronal activity. The present review focuses on the well-delimited issue of how an external or internal piece of information goes beyond nonconscious processing and gains access to conscious processing, a transition characterized by the existence of a reportable subjective experience. Converging neuroimaging and neurophysiological data, acquired during minimal experimental contrasts between conscious and nonconscious processing, point to objective neural measures of conscious access: late amplification of relevant sensory activity, long-distance cortico-cortical synchronization at beta and gamma frequencies, and "ignition" of a large-scale prefronto-parietal network. We compare these findings to current theoretical models of conscious processing, including the Global Neuronal Workspace (GNW) model according to which conscious access occurs when incoming information is made globally available to multiple brain systems through a network of neurons with long-range axons densely distributed in prefrontal, parieto-temporal, and cingulate cortices. The clinical implications of these results for general anesthesia, coma, vegetative state, and schizophrenia are discussed.},
author = {Dehaene, Stanislas and Changeux, Jean-Pierre},
doi = {10.1016/j.neuron.2011.03.018},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neuron/2011/Dehaene, Changeux - 2011.pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Animals,Attention,Attention: physiology,Biological,Brain,Brain Mapping,Brain: blood supply,Brain: cytology,Brain: physiology,Consciousness,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Models,Nerve Net,Nerve Net: physiology,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,consciousness},
mendeley-tags = {consciousness},
number = {2},
pages = {200--27},
pmid = {21521609},
publisher = {Elsevier Inc.},
title = {{Experimental and theoretical approaches to conscious processing}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21521609},
volume = {70},
year = {2011}
}
@article{Snaider2014,
abstract = {The representation paradigm used by a cognitive architecture helps to determine the kind of processes that it can perform more efficiently. Vector LIDA is a variation of the LIDA cognitive architecture that employs high-dimensional Modular Composite Representation (MCR) vectors as its main representation model and Integer Sparse Distributed Memory as its main memory implementation technology. The advantages of this new model include a more realistic and biologically plausible model, better integration with its episodic memory, better integration with other low level perceptual processing (such as deep learning systems), better scalability, and easier learning mechanisms. Here, after briefly recapping the LIDA model and MCR, we describe Vector LIDA and argue for its several advantages.},
author = {Snaider, Javier and Franklin, Stan},
doi = {10.1016/j.procs.2014.11.103},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Procedia Computer Science/2014/Snaider, Franklin - 2014.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {cog{\_}arch,cognitive architectures,high dimensional representations,modular composite,semantic vectors},
mendeley-tags = {cog{\_}arch},
pages = {188--203},
publisher = {Elsevier Masson SAS},
title = {{Vector LIDA}},
url = {http://ccrg.cs.memphis.edu/assets/papers/2014/Vector LIDA bica2014 submit.pdf http://linkinghub.elsevier.com/retrieve/pii/S1877050914015488},
volume = {41},
year = {2014}
}
@article{Grossberg2014,
author = {Grossberg, Stephen},
doi = {10.1016/j.brainres.2014.11.018},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Brain Research/2014/Grossberg - 2014.pdf:pdf},
issn = {0006-8993},
journal = {Brain Research},
keywords = {3D vision,Adaptive resonance theory,Adaptively controlled conditioning,Attention,Autism,Category learning,Cognitive working memory,Eye movement,Grid cell,Laminar cortical circuits,Learning,Medial temporal amnesia,Memory,NeuroModels,Place cell,Predictive remapping,Spatial navigation,Speech perception,Time cell,mGluR},
mendeley-tags = {NeuroModels},
pages = {1--24},
publisher = {Elsevier},
title = {{From brain synapses to systems for learning and memory: Object recognition, spatial navigation, timed conditioning, and movement control}},
url = {http://dx.doi.org/10.1016/j.brainres.2014.11.018},
year = {2014}
}
@article{Kuznetcova2015,
abstract = {Статья представляет собой обзор некоторых из имеющихся в специальной литературе представлений о структуре, функциях и разновидностях дефиниции как характерной для научной коммуникации формы выражения знания. Основное внимание уделяется лингвистическим моделям дефиниции, в которых представлено описание конкретных языковых средств выражения дефиниций, а также их типологий, основанных на структурных и содержательных особенностях. На примерах показано, что особую техническую сложность может вызывать идентификация дефиниций с модифицированной структурой, отклоняющейся от классической трехчастной, а также дефиниций, выраженных более чем одним предложением.},
author = {Кузнецова, Ю. М.},
journal = {Искусственный интеллект и принятие решений},
keywords = {15-07-06214,lingvo,автоматическая обработка текста,научная дефиниция,научный текст},
language = {russian},
mendeley-tags = {15-07-06214,lingvo},
number = {3},
pages = {70--82},
title = {{Дефиниции в научном тексте: функции, виды, способы выражения и возможности идентификации}},
year = {2015}
}
@article{Jones2000a,
author = {Jones, E. G.},
doi = {10.1073/pnas.97.10.5019},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences/2000/Jones - 2000.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {10},
pages = {5019--5021},
title = {{Microcolumns in the cerebral cortex}},
url = {http://www.pnas.org/content/97/10/5019.full},
volume = {97},
year = {2000}
}
@article{Hampshire2016,
abstract = {The ability to learn new tasks rapidly is a prominent characteristic of human behaviour. This ability relies on flexible cognitive systems that adapt in order to encode temporary programs for processing non-automated tasks. Previous functional imaging studies have revealed distinct roles for the lateral frontal cortices (LFCs) and the ventral striatum in intentional learning processes. However, the human LFCs are complex; they house multiple distinct sub-regions, each of which co-activates with a different functional network. It remains unclear how these LFC networks differ in their functions and how they coordinate with each other, and the ventral striatum, to support intentional learning. Here, we apply a suite of fMRI connectivity methods to determine how LFC networks activate and interact at different stages of two novel tasks, in which arbitrary stimulus-response rules are learnt either from explicit instruction or by trial-and-error. We report that the networks activate en masse and in synchrony when novel rules are being learnt from instruction. However, these networks are not homogeneous in their functions; instead, the directed connectivities between them vary asymmetrically across the learning timecourse and they disengage from the task sequentially along a rostro-caudal axis. Furthermore, when negative feedback indicates the need to switch to alternative stimulus-response rules, there is additional input to the LFC networks from the ventral striatum. These results support the hypotheses that LFC networks interact as a hierarchical system during intentional learning and that signals from the ventral striatum have a driving influence on this system when the internal program for processing the task is updated.},
author = {Hampshire, Adam and Hellyer, Peter J. and Parkin, Beth and Hiebert, Nole and MacDonald, Penny and Owen, Adrian M. and Leech, Robert and Rowe, James},
doi = {10.1016/j.neuroimage.2015.11.060},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/NeuroImage/2016/Hampshire et al. - 2016.pdf:pdf},
issn = {10959572},
journal = {NeuroImage},
keywords = {Caudate,Dynamic causal modelling,Frontal cortex,Functional connectivity,Learning},
pages = {123--134},
publisher = {The Authors},
title = {{Network mechanisms of intentional learning}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2015.11.060},
volume = {127},
year = {2016}
}
@incollection{Maslov1979,
author = {Маслов, С. Ю.},
booktitle = {Семиотика и информатика},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Семиотика и информатика/1979/Маслов - 1979.pdf:pdf},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {17--46},
title = {{Теория поиска вывода и вопросы психологии творчества}},
volume = {13},
year = {1979}
}
@inproceedings{Yang2013,
author = {Yang, Yezhou and Teo, Ching L and Ferm, Cornelia},
booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/IEEE International Conference on Robotics and Automation (ICRA)/2013/Yang, Teo, Ferm - 2013.pdf:pdf},
pages = {4256--4262},
title = {{Robots with Language: Multi-Label Visual Recognition Using NLP}},
year = {2013}
}
@article{Walther2006,
abstract = {Selective visual attention is believed to be responsible for serializing visual information for recognizing one object at a time in a complex scene. But how can we attend to objects before they are recognized? In coherence theory of visual cognition, so-called proto-objects form volatile units of visual information that can be accessed by selective attention and subsequently validated as actual objects. We propose a biologically plausible model of forming and attending to proto-objects in natural scenes. We demonstrate that the suggested model can enable a model of object recognition in cortex to expand from recognizing individual objects in isolation to sequentially recognizing all objects in a more complex scene.},
author = {Walther, Dirk and Koch, Christof},
doi = {10.1016/j.neunet.2006.10.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural networks/2006/Walther, Koch - 2006.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks},
keywords = {Attention,Biological,Computer Simulation,Discrimination Learning,Discrimination Learning: physiology,Feedback,Humans,Models,Neural Networks (Computer),Pattern Recognition,Photic Stimulation,Photic Stimulation: methods,ROC Curve,Visual,Visual: physiology},
number = {9},
pages = {1395--407},
pmid = {17098563},
title = {{Modeling attention to salient proto-objects}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17098563},
volume = {19},
year = {2006}
}
@article{Minami2001,
author = {Minami, T. and Inui, T.},
doi = {10.1007/s12559-015-9330-3},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Connectionist Models of Neurons, Learning Processes, and Artificial Intelligence/2001/Minami, Inui - 2001.pdf:pdf},
issn = {18669964},
journal = {Connectionist Models of Neurons, Learning Processes, and Artificial Intelligence},
keywords = {Action preparation,Language processing,Neural network modelling,Sequence learning,Working memory,modelling {\'{a}} sequence learning,network,working memory {\'{a}} neural,{\'{a}} action preparation {\'{a}}},
pages = {126--133},
publisher = {Springer US},
title = {{A Neural Network Model of Working Memory}},
url = {http://www.springerlink.com/index/NW4NLH1ME9PJ8JQY.pdf},
year = {2001}
}
@article{Taniguchi2015,
abstract = {Humans can learn the use of language through physical interaction with their environment and semi-otic communication with other people. It is very important to obtain a computational understanding of how humans can form a symbol system and obtain semiotic skills through their autonomous mental development. Recently, many studies have been conducted on the construction of robotic systems and machine-learning methods that can learn the use of language through embodied multimodal in-teraction with their environment and other systems. Understanding human social interactions and developing a robot that can smoothly communicate with human users in the long term, requires an understanding of the dynamics of symbol systems and is crucially important. The embodied cognition and social interaction of participants gradually change a symbol system in a constructive manner. In this paper, we introduce a field of research called symbol emergence in robotics (SER). SER is a con-structive approach towards an emergent symbol system. The emergent symbol system is socially self-organized through both semiotic communications and physical interactions with autonomous cognitive developmental agents, i.e., humans and developmental robots. Specifically, we describe some state-of-art research topics concerning SER, e.g., multimodal categorization, word discovery, and a double articulation analysis, that enable a robot to obtain words and their embodied meanings from raw sensory–motor information, including visual information, haptic information, auditory information, and acoustic speech signals, in a totally unsupervised manner. Finally, we suggest future directions of research in SER.},
archivePrefix = {arXiv},
arxivId = {arXiv:1509.08973v1},
author = {Taniguchi, Tadahiro and Nagai, Takayuki and Nakamura, Tomoaki and Iwahashi, Naoto and Ogata, Tetsuya and Asoh, Hideki},
doi = {10.1080/01691864.2016.1164622},
eprint = {arXiv:1509.08973v1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Advanced Robotics/2015/Taniguchi et al. - 2015.pdf:pdf},
issn = {15685535},
journal = {Advanced Robotics},
keywords = {()},
number = {00},
pages = {1--27},
title = {{Symbol Emergence in Robotics: A Survey}},
volume = {00},
year = {2015}
}
@techreport{Bothell2015,
author = {Bothell, Dan},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Bothell - 2015.pdf:pdf},
institution = {Carnegie Mellon University},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
pages = {516},
title = {{ACT-R 7 Reference Manual}},
url = {http://act-r.psy.cmu.edu/wordpress/wp-content/themes/ACT-R/actr7/reference-manual.pdf},
year = {2015}
}
@article{Liu2014,
author = {Liu, Zhi and Zou, Wenbin and Li, Lina and Shen, Liquan and {Le Meur}, Olivier},
doi = {10.1109/LSP.2013.2292873},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/IEEE Signal Processing Letters/2014/Liu et al. - 2014.pdf:pdf},
issn = {1070-9908},
journal = {IEEE Signal Processing Letters},
number = {1},
pages = {88--92},
title = {{Co-Saliency Detection Based on Hierarchical Segmentation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6675796},
volume = {21},
year = {2014}
}
@article{Zendehrouh2015,
author = {Zendehrouh, Sareh},
doi = {10.1016/j.neunet.2015.08.006},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural Networks/2015/Zendehrouh - 2015.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
pages = {112--123},
publisher = {Elsevier Ltd},
title = {{A new computational account of cognitive control over reinforcement-based decision-making: Modeling of a probabilistic learning task}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608015001604},
volume = {71},
year = {2015}
}
@article{Eliasmith2014,
abstract = {We provide an overview and comparison of several recent large-scale brain models. In addition to discussing challenges involved with building large neural models, we identify several expected benefits of pursuing such a research program. We argue that these benefits are only likely to be realized if two basic guidelines are made central to the pursuit. The first is that such models need to be intimately tied to behavior. The second is that models, and more importantly their underlying methods, should provide mechanisms for varying the level of simulated detail. Consequently, we express concerns with models that insist on a 'correct' amount of detail while expecting interesting behavior to simply emerge. ?? 2013 Elsevier Ltd.},
author = {Eliasmith, Chris and Trujillo, Oliver},
doi = {10.1016/j.conb.2013.09.009},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Current Opinion in Neurobiology/2014/Eliasmith, Trujillo - 2014.pdf:pdf},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
pages = {1--6},
pmid = {24709593},
publisher = {Elsevier Ltd},
title = {{The use and abuse of large-scale brain models}},
url = {http://dx.doi.org/10.1016/j.conb.2013.09.009},
volume = {25},
year = {2014}
}
@article{Chersi2014,
abstract = {A growing body of evidence in cognitive psychology and neuroscience suggests a deep interconnection between sensory-motor and language systems in the brain. Based on recent neurophysiological findings on the anatomo-functional organization of the fronto-parietal network, we present a computational model showing that language processing may have reused or co-developed organizing principles, functionality, and learning mechanisms typical of premotor circuit. The proposed model combines principles of Hebbian topological self-organization and prediction learning. Trained on sequences of either motor or linguistic units, the network develops independent neuronal chains, formed by dedicated nodes encoding only context-specific stimuli. Moreover, neurons responding to the same stimulus or class of stimuli tend to cluster together to form topologically connected areas similar to those observed in the brain cortex. Simulations support a unitary explanatory framework reconciling neurophysiological motor data with established behavioral evidence on lexical acquisition, access, and recall.},
author = {Chersi, Fabian and Ferro, Marcello and Pezzulo, Giovanni and Pirrelli, Vito},
doi = {10.1111/tops.12094},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Topics in cognitive science/2014/Chersi et al. - 2014.pdf:pdf},
issn = {1756-8765},
journal = {Topics in cognitive science},
keywords = {computational modeling,lexical chains,motor chains,prediction,self-organizing maps,serial working memory,somatotopic organization},
number = {3},
pages = {476--91},
pmid = {24935737},
title = {{Topological self-organization and prediction learning support both action and lexical chains in the brain}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24935737},
volume = {6},
year = {2014}
}
@article{Tononi2004,
abstract = {BACKGROUND: Consciousness poses two main problems. The first is understanding the conditions that determine to what extent a system has conscious experience. For instance, why is our consciousness generated by certain parts of our brain, such as the thalamocortical system, and not by other parts, such as the cerebellum? And why are we conscious during wakefulness and much less so during dreamless sleep? The second problem is understanding the conditions that determine what kind of consciousness a system has. For example, why do specific parts of the brain contribute specific qualities to our conscious experience, such as vision and audition? PRESENTATION OF THE HYPOTHESIS: This paper presents a theory about what consciousness is and how it can be measured. According to the theory, consciousness corresponds to the capacity of a system to integrate information. This claim is motivated by two key phenomenological properties of consciousness: differentiation - the availability of a very large number of conscious experiences; and integration - the unity of each such experience. The theory states that the quantity of consciousness available to a system can be measured as the Phi value of a complex of elements. Phi is the amount of causally effective information that can be integrated across the informational weakest link of a subset of elements. A complex is a subset of elements with Phi{\textgreater}0 that is not part of a subset of higher Phi. The theory also claims that the quality of consciousness is determined by the informational relationships among the elements of a complex, which are specified by the values of effective information among them. Finally, each particular conscious experience is specified by the value, at any given time, of the variables mediating informational interactions among the elements of a complex. TESTING THE HYPOTHESIS: The information integration theory accounts, in a principled manner, for several neurobiological observations concerning consciousness. As shown here, these include the association of consciousness with certain neural systems rather than with others; the fact that neural processes underlying consciousness can influence or be influenced by neural processes that remain unconscious; the reduction of consciousness during dreamless sleep and generalized seizures; and the time requirements on neural interactions that support consciousness. IMPLICATIONS OF THE HYPOTHESIS: The theory entails that consciousness is a fundamental quantity, that it is graded, that it is present in infants and animals, and that it should be possible to build conscious artifacts.},
author = {Tononi, Giulio},
doi = {10.1186/1471-2202-5-42},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/BMC neuroscience/2004/Tononi - 2004.pdf:pdf},
issn = {1471-2202},
journal = {BMC neuroscience},
keywords = {Afferent Pathways,Brain,Brain: physiology,Consciousness,Humans,Information Theory,Motor Activity,Neurons,Neurons: physiology,Systems Integration,Thalamus,Thalamus: physiology},
pages = {42},
pmid = {15522121},
title = {{An information integration theory of consciousness}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=543470{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2004}
}
@article{Anderson2008,
abstract = {The methodologies of cognitive architectures and functional magnetic resonance imaging can mutually inform each other. For example, four modules of the ACT-R (adaptive control of thought - rational) cognitive architecture have been associated with four brain regions that are active in complex tasks. Activity in a lateral inferior prefrontal region reflects retrieval of information in a declarative module; activity in a posterior parietal region reflects changes to problem representations in an imaginal module; activity in the anterior cingulate cortex reflects the updates of control information in a goal module; and activity in the caudate nucleus reflects execution of productions in a procedural module. Differential patterns of activation in such central regions can reveal the time course of different components of complex cognition. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Anderson, John R. and Fincham, Jon M. and Qin, Yulin and Stocco, Andrea},
doi = {10.1016/j.tics.2008.01.006},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in Cognitive Sciences/2008/Anderson et al. - 2008.pdf:pdf},
isbn = {1364-6613 (Print)$\backslash$n1364-6613 (Linking)},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {4},
pages = {136--143},
pmid = {18329948},
title = {{A central circuit of the mind}},
volume = {12},
year = {2008}
}
@book{ZhuravlevL2009,
address = {М.},
editor = {Журавлев, А. Л. and Сергиенко, Е. А. and Знаков, В. В. and Александров, И. О.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2009/Unknown - 2009.pdf:pdf},
isbn = {9785927001705},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {400},
publisher = {Институт психологии РАН},
title = {{Психология человека в современном мире}},
volume = {3},
year = {2009}
}
@article{Chudova2012a,
author = {Чудова, Н. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Искусственный интеллект и принятие решений/2012/Чудова - 2012(2).pdf:pdf},
journal = {Искусственный интеллект и принятие решений},
keywords = {12-07-00611,lingvo},
language = {russian},
mendeley-tags = {12-07-00611,lingvo},
number = {4},
pages = {3--31},
title = {{Понимание: предмет исследования и объект моделирования}},
year = {2012}
}
@article{Friston2010,
abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories — optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
author = {Friston, Karl},
doi = {10.1038/nrn2787},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature Reviews Neuroscience/2010/Friston - 2010.pdf:pdf},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
number = {2},
pages = {127--138},
publisher = {Nature Publishing Group},
title = {{The free-energy principle: a unified brain theory?}},
url = {http://www.nature.com/doifinder/10.1038/nrn2787},
volume = {11},
year = {2010}
}
@article{Hasselmo2006,
author = {Howard, Marc W. and Fotedar, Mrigankka S. and Datey, Aditya V. and Hasselmo, Michael E.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Psychology Review/2005/Howard et al. - 2005.pdf:pdf},
journal = {Psychology Review},
number = {1},
pages = {75--116},
title = {{The Temporal Context Model in spatial navigation and relational learning: Toward a common explanation of medial temporal lobe function across domains}},
volume = {112},
year = {2005}
}
@article{Borisuk2002,
author = {Борисюк, Г. Н. and Борисюк, Р. М. and Казанович, Я. Б. and Иваницкий, Г. Р.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/2002/Борисюк et al. - 2002.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {10},
pages = {1189--1214},
title = {{Модели динамики нейронной активности при обработке информации мозгом - итоги ``десятилетия''}},
volume = {170},
year = {2002}
}
@article{Goertzel2010,
abstract = {A number of leading cognitive architectures that are inspired by the human brain, at various levels of granularity, are reviewed and compared, with special attention paid to the way their internal structures and dynamics map onto neural processes. Four categories of Biologically Inspired Cognitive Architectures (BICAs) are considered, with multiple examples of each category briefly reviewed, and selected examples discussed in more depth: primarily symbolic architectures (e.g. ACT-R), emergentist architectures (e.g. DeSTIN), developmental robotics architectures (e.g. IM-CLEVER), and our central focus, hybrid architectures (e.g. LIDA, CLARION, 4D/RCS, DUAL, MicroPsi, and OpenCog). Given the state of the art in BICA, it is not yet possible to tell whether emulating the brain on the architectural level is going to be enough to allow rough emulation of brain function; and given the state of the art in neuroscience, it is not yet possible to connect BICAs with large-scale brain simulations in a thoroughgoing way. However, it is nonetheless possible to draw reasonably close function connections between various components of various BICAs and various brain regions and dynamics, and as both BICAs and brain simulations mature, these connections should become richer and may extend further into the domain of internal dynamics as well as overall behavior. ?? 2010 Elsevier B.V.},
author = {Goertzel, Ben and Lian, Ruiting and Arel, Itamar and de Garis, Hugo and Chen, Shuo},
doi = {10.1016/j.neucom.2010.08.012},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neurocomputing/2010/Goertzel et al. - 2010.pdf:pdf},
isbn = {0925-2312},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Artificial brains,Cognitive architectures},
number = {1-3},
pages = {30--49},
publisher = {Elsevier},
title = {{A world survey of artificial brain projects, Part II: Biologically inspired cognitive architectures}},
url = {http://dx.doi.org/10.1016/j.neucom.2010.08.012},
volume = {74},
year = {2010}
}
@book{Luria1979,
address = {М.},
author = {Лурия, A. Р.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/1979/Лурия - 1979.pdf:pdf},
isbn = {0304000000},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {320},
publisher = {Издательство Московского университета},
title = {{Язык и сознание}},
year = {1979}
}
@book{Danilova2012,
address = {М.},
author = {Данилова, Н. Н.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2012/Данилова - 2012.pdf:pdf},
language = {russian},
pages = {368},
publisher = {Аспект Пресс},
title = {{Психофизиология: Учебник для вузов}},
year = {2012}
}
@book{Leontiev1977,
address = {М.},
author = {Леонтьев, Алексей Николаевич},
edition = {Изд. 2-е},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/1977/Леонтьев - 1977.pdf:pdf},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {304},
publisher = {Политиздат},
title = {{Деятельность. Сознание. Личность}},
year = {1977}
}
@unpublished{Wallace2005,
author = {Wallace, Rodrick},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2005/Wallace - 2005.pdf:pdf},
keywords = {consciousness,general cognitive model,global,information theory,phase transition,random net-,workspace},
pages = {9},
title = {{A modular network treatment of Baars' Global Workspace consciousness model}},
year = {2005}
}
@article{Rasmussen2011,
abstract = {Abstract Inductive reasoning is a fundamental and complex aspect of human intelligence. In particular, how do subjects, given a set of particular examples, generate general descriptions of the rules governing that set? We present a biologically plausible method ... $\backslash$n},
author = {Rasmussen, Daniel and Eliasmith, Chris},
doi = {10.1111/j.1756-8765.2010.01127.x},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Topics in Cognitive Science/2011/Rasmussen, Eliasmith - 2011.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {Cognitive modeling,Fluid intelligence,Inductive reasoning,Neural engineering framework,Raven's progressive matrices,Realistic neural modeling,Rule generation,Vector symbolic architectures},
number = {1},
pages = {140--153},
title = {{A neural model of rule generation in inductive reasoning}},
volume = {3},
year = {2011}
}
@article{Dong2011a,
abstract = {We present a new model of sensorimotor learning in a systems-level cognitive model, LIDA. Sensorimotor learning helps an agent properly interact with its environment using past experi- ences. This new model stores and updates the rewards of pairs of data, motor commands and their contexts, using the concept of reinforcement learning; thus the agent is able to generate (output) effective commands in certain contexts based on its reward history. Following Global Workspace Theory, the primary basis of LIDA, the process of updating rewards in sensorimotor learning is cued by the agent's conscious content, the most salient portion of the agent's under- standing of the current situation, issued by the Global Workspace module of LIDA. Furthermore, we add a dynamic learning rate to control the extent to which a newly arriving reward may affect the reward update. This learning rate control mechanism is inspired by a hypothesis from neuroscience regarding memory of errors. Our experimental results show that sensorimotor learning using a dynamic learning rate improves performance in a simulated movement of push- ing a box.},
author = {Dong, Daqi and Franklin, Stan},
doi = {10.1016/j.bica.2015.09.005},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2015/Dong, Franklin - 2015.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {a learning rate control,action,cognitive modeling,execution,in lida and add,in this paper,learning rate,lida 1,lida model,mechanism,sensorimotor learning,this is,we implement sensorimotor learning},
pages = {1--9},
publisher = {Elsevier B.V.},
title = {{Modeling Sensorimotor Learning in LIDA using a Dynamic Learning Rate}},
volume = {14},
year = {2015}
}
@article{Culhane1995,
author = {Tsotsos, John K. and Culhane, Sean M and Wai, Winky Yan Kei and Lai, Yuzhong and Davis, Neal and Nuflo, Fernando},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Artificial Intelligence/1995/Tsotsos et al. - 1995.pdf:pdf},
journal = {Artificial Intelligence},
number = {78},
pages = {507--545},
title = {{Modeling visual attention via selective tuning}},
year = {1995}
}
@inproceedings{Osipov2012,
address = {Калининград},
author = {Осипов, Г. С.},
booktitle = {Пятая международная конференция по когнитивной науке: Тезисы докладов: Калининград, 18-24 июня 2012 г.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Пятая международная конференция по когнитивной науке Тезисы докладов Калининград, 18-24 июня 2012 г/2012/Осипов - 2012.pdf:pdf},
keywords = {osipov},
language = {russian},
mendeley-tags = {osipov},
pages = {812--813},
publisher = {Межрегиональная ассоциация когнитивных исследований (МАКИ)},
title = {{Поведение, управляемое картиной мира}},
year = {2012}
}
@incollection{Cotterill1987,
author = {Cotterill, Rodney M. J.},
booktitle = {Physics in Living Matter},
editor = {Baeriswyl, Dionys and Droz, Michel and Malaspinas, Andreas and Martinoli, Piero},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Physics in Living Matter/1987/Cotterill - 1987.pdf:pdf},
pages = {138--151},
publisher = {Springer-Verlag},
title = {{Physics of the Brain}},
year = {1987}
}
@book{Friedenberg2006,
author = {Friedenberg, Jay and Silverman, Gordon},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2006/Friedenberg, Silverman - 2006.pdf:pdf},
pages = {560},
publisher = {Sage Publications},
title = {{Cognitive sciencee: an introduction to the study of mind}},
year = {2006}
}
@article{Osipov1999,
author = {Осипов, Г. С. and Поспелов, Д. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Новости искусственного интеллекта/1999/Осипов, Поспелов - 1999.pdf:pdf},
journal = {Новости искусственного интеллекта},
keywords = {osipov},
language = {russian},
mendeley-tags = {osipov},
number = {1},
pages = {9--35},
title = {{Прикладная семиотика}},
year = {1999}
}
@article{Sokolov2005,
author = {Соколов, Е. Н. and Незлина, Н. И.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Журнал высшей нервной деятельности/2005/Соколов, Незлина - 2005.pdf:pdf},
issn = {00444677},
journal = {Журнал высшей нервной деятельности},
language = {russian},
number = {4},
pages = {459--471},
pmid = {16217959},
title = {{Нейродарвинизм: моделирование отбора нейронных групп}},
volume = {55},
year = {2005}
}
@article{Miyazaki2014,
abstract = {Our research purpose is to realize a consciousness system on computers. In this paper, we focus on the relation between a primary system that directly interacts and learns the input-output relation within an environment, and a secondary system that continuously monitors and is able to direct the primary system. We hold that consciousness is not composed of a primary system alone, but that the employment of a secondary system is essential. The purpose of this paper is therefore to clarify the importance of a secondary system. We show by numerical experiments that the addition of a secondary system provides adaptability to a wider range of environmental changes than a primary system alone. Alternatively, we present an extraordinary case where a customized primary system fully adapts to an environment undergoing a particular type of change. Far from refuting the value of a secondary system, this special case serves to point out the importance of the effective design of a secondary system. Therefore, we confirm the value and usefulness of a secondary system in a machine consciousness system through these numericalexperiments.},
author = {Miyazaki, Kazuteru and Takeno, Junichi},
doi = {10.1016/j.procs.2014.11.079},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Procedia Computer Science/2014/Miyazaki, Takeno - 2014.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Consciousness system,Exploitation-oriented learning (XoL),NeuroModels,Primary system,Reinforcement learning,Secondary system},
mendeley-tags = {NeuroModels},
pages = {15--22},
title = {{The Necessity of a Secondary System in Machine Consciousness}},
url = {http://www.sciencedirect.com/science/article/pii/S1877050914015245},
volume = {41},
year = {2014}
}
@article{Coward2004,
abstract = {In the physical sciences a rigorous theory is a hierarchy of descriptions in which causal relationships between many general types of entity at a phenomenological level can be derived from causal relationships between smaller numbers of simpler entities at more detailed levels. The hierarchy of descriptions resembles the modular hierarchy created in electronic systems in order to be able to modify a complex functionality without excessive side effects. Such a hierarchy would make it possible to establish a rigorous scientific theory of consciousness. The causal relationships implicit in definitions of access consciousness and phenomenal consciousness are made explicit, and the corresponding causal relationships at the more detailed levels of perception, memory, and skill learning described. Extension of these causal relationships to physiological and neural levels is discussed. The general capability of a range of current consciousness models to support a modular hierarchy which could generate these causal relationships is reviewed, and the specific capabilities of two models with good general capabilities are compared in some detail.},
author = {Coward, L Andrew and Sun, Ron},
doi = {10.1016/j.concog.2003.09.002},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Consciousness and cognition/2004/Coward, Sun - 2004.pdf:pdf},
issn = {1053-8100},
journal = {Consciousness and cognition},
keywords = {Consciousness,Consciousness: physiology,Humans,Learning,Learning: physiology,Memory,Memory: physiology,Models,Neural Networks (Computer),Neurophysiology,Perception,Perception: physiology,Psychological},
number = {2},
pages = {268--301},
pmid = {15134761},
title = {{Criteria for an effective theory of consciousness and some preliminary attempts.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15134761},
volume = {13},
year = {2004}
}
@article{Sun2004,
abstract = {This paper explores the interaction between implicit and explicit processes during skill learning, in terms of top-down learning (that is, learning that goes from explicit to implicit knowledge) versus bottom-up learning (that is, learning that goes from implicit to explicit knowledge). Instead of studying each type of knowledge (implicit or explicit) in isolation, we stress the interaction between the two types, especially in terms of one type giving rise to the other, and its effects on learning. The work presents an integrated model of skill learning that takes into account both implicit and explicit processes and both top-down and bottom-up learning. We examine and simulate human data in the Tower of Hanoi task. The paper shows how the quantitative data in this task may be captured using either top-down or bottom-up approaches, although top-down learning is a more apt explanation of the human data currently available. These results illustrate the two different directions of learning (top-down versus bottom-up), and thereby provide a new perspective on skill learning. ?? 2003 Elsevier B.V. All rights reserved.},
author = {Sun, Ron and Zhang, Xi},
doi = {10.1016/j.cogsys.2003.07.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Systems Research/2004/Sun, Zhang - 2004.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
pages = {63--89},
title = {{Top-down versus bottom-up learning in cognitive skill acquisition}},
volume = {5},
year = {2004}
}
@unpublished{Jaeger2014,
abstract = {Conceptors provide an elementary neuro-computational mechanism which sheds a fresh and unifying light on a diversity of cognitive phenomena. A number of demanding learning and processing tasks can be solved with unprecedented ease, robustness and accuracy. Some of these tasks were impossible to solve before. This entirely informal paper introduces the basic principles of conceptors and highlights some of their usages.},
archivePrefix = {arXiv},
arxivId = {1406.2671},
author = {Jaeger, Herbert},
eprint = {1406.2671},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2014/Jaeger - 2014.pdf:pdf},
pages = {11},
title = {{Conceptors: an easy introduction}},
url = {http://arxiv.org/abs/1406.2671},
year = {2014}
}
@article{Vannini2007,
author = {Vannini, Antonella},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Syntropy/2007/Vannini - 2007.pdf:pdf},
journal = {Syntropy},
number = {1},
pages = {130--146},
title = {{Quantum Models of Consciousness}},
year = {2007}
}
@article{Brown2015,
author = {Brown, T I and Carr, V A and LaRocque, K F and Favila, S E and Gordon, A M and Bowles, B and Wagner, A D},
doi = {10.1126/science.aaf0784},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Science/2015/Brown et al. - 2015.pdf:pdf},
issn = {0036-8075},
journal = {Science},
number = {6291},
pages = {1323--1326},
pmid = {27284194},
title = {{Prospective representation of navigational goals in the human hippocampus}},
volume = {352},
year = {2015}
}
@article{Harnad1990,
archivePrefix = {arXiv},
arxivId = {arXiv:cs.AI/9906002},
author = {Harnad, Stevan},
doi = {10.4249/scholarpedia.2373},
eprint = {9906002},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Physica/1990/Harnad - 1990.pdf:pdf},
isbn = {0167-2789},
issn = {01672789},
journal = {Physica},
keywords = {symb{\_}ground},
mendeley-tags = {symb{\_}ground},
pages = {335--346},
primaryClass = {arXiv:cs.AI},
title = {{Symbol Grounding Problem}},
url = {http://eprints.soton.ac.uk/271345/5/Harnad-CangelelosiComm.rtf},
volume = {42},
year = {1990}
}
@article{Rinkus2010,
abstract = {No generic function for the minicolumn - i.e., one that would apply equally well to all cortical areas and species - has yet been proposed. I propose that the minicolumn does have a generic functionality, which only becomes clear when seen in the context of the function of the higher-level, subsuming unit, the macrocolumn. I propose that: (a) a macrocolumn's function is to store sparse distributed representations of its inputs and to be a recognizer of those inputs; and (b) the generic function of the minicolumn is to enforce macrocolumnar code sparseness. The minicolumn, defined here as a physically localized pool of approximately 20 L2/3 pyramidals, does this by acting as a winner-take-all (WTA) competitive module, implying that macrocolumnar codes consist of approximately 70 active L2/3 cells, assuming approximately 70 minicolumns per macrocolumn. I describe an algorithm for activating these codes during both learning and retrievals, which causes more similar inputs to map to more highly intersecting codes, a property which yields ultra-fast (immediate, first-shot) storage and retrieval. The algorithm achieves this by adding an amount of randomness (noise) into the code selection process, which is inversely proportional to an input's familiarity. I propose a possible mapping of the algorithm onto cortical circuitry, and adduce evidence for a neuromodulatory implementation of this familiarity-contingent noise mechanism. The model is distinguished from other recent columnar cortical circuit models in proposing a generic minicolumnar function in which a group of cells within the minicolumn, the L2/3 pyramidals, compete (WTA) to be part of the sparse distributed macrocolumnar code.},
author = {Rinkus, Gerard J},
doi = {10.3389/fnana.2010.00017},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in neuroanatomy/2010/Rinkus - 2010.pdf:pdf},
issn = {1662-5129},
journal = {Frontiers in neuroanatomy},
keywords = {NeuroModels,learning,macrocolumn,memory,minicolumn,novelty detection,population coding,sparse distributed representations,winner-take-all},
mendeley-tags = {NeuroModels},
number = {June},
pages = {17},
pmid = {20577587},
title = {{A cortical sparse distributed coding model linking mini- and macrocolumn-scale functionality}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2889687{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2010}
}
@article{Stewart2012,
abstract = {We expand our existing spiking neuron model of decision making in the cortex and basal ganglia to include local learning on the synaptic connections between the cortex and striatum, modulated by a dopaminergic reward signal. We then compare this model to animal data in the bandit task, which is used to test rodent learning in conditions involving forced choice under rewards. Our results indicate a good match in terms of both behavioral learning results and spike patterns in the ventral striatum. The model successfully generalizes to learning the utilities of multiple actions, and can learn to choose different actions in different states. The purpose of our model is to provide both high-level behavioral predictions and low-level spike timing predictions while respecting known neurophysiology and neuroanatomy.},
author = {Stewart, Terrence C and Bekolay, Trevor and Eliasmith, Chris},
doi = {10.3389/fnins.2012.00002},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in neuroscience/2012/Stewart, Bekolay, Eliasmith - 2012.pdf:pdf},
issn = {1662-453X},
journal = {Frontiers in neuroscience},
keywords = {Basal ganglia,Neural engineering framework,Reinforcement learning,Two-armed bandit,Ventral striatum},
number = {JAN},
pages = {2},
pmid = {22319465},
title = {{Learning to select actions with spiking neurons in the Basal Ganglia}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861903649{\&}partnerID=tZOtx3y1},
volume = {6},
year = {2012}
}
@article{Chernavsky2000,
author = {Чернавский, Д. С.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/2000/Чернавский - 2000.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {2},
pages = {158--183},
title = {{Проблема происхождения жизни и мышления с точки зрения современной физики}},
volume = {170},
year = {2000}
}
@article{Coward2014,
abstract = {The brain uses computational primitives that are analogous with but qualitatively different from the computational primitives used in electronic computer systems. The primary computational primitives of the brain are described, and their implementation in anatomy and physiology discussed. Combinations and sequences of these primitives implement cognitive tasks. Many of the primitives have also been implemented electronically. The brain is a very effective general learning system, and although an artificial general intelligence system will be required to learn a different range of behaviours from the brain, the computational primitives used by the brain are the best available guide to appropriate primitives for such an AGI system.},
author = {Coward, L. Andrew},
doi = {10.1016/j.procs.2014.11.100},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Procedia Computer Science/2014/Coward - 2014.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {NeuroModels},
mendeley-tags = {NeuroModels},
pages = {164--175},
title = {{Brain Computational Primitives}},
url = {http://www.sciencedirect.com/science/article/pii/S1877050914015452},
volume = {41},
year = {2014}
}
@incollection{Vityaev1998a,
address = {Новосибирск},
author = {Витяев, Е. Е.},
booktitle = {Модели когнитивных процессов},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Модели когнитивных процессов/1998/Витяев - 1998(2).pdf:pdf},
language = {russian},
pages = {3--61},
publisher = {Институт математики им. С.Л. Соболев},
title = {{Формальная модель работы мозга, основанная на принципе предсказания}},
year = {1998}
}
@inproceedings{Osipov2014a,
address = {Челябинск},
author = {Осипов, Г. С.},
booktitle = {Информационные технологии и системы: Труды Третьей международной научной конференции},
editor = {Попков, Ю. С. and Мельников, А. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Информационные технологии и системы Труды Третьей международной научной конференции/2014/Осипов - 2014.pdf:pdf},
keywords = {osipov},
language = {russian},
mendeley-tags = {osipov},
pages = {21--27},
publisher = {Изд-во Челяб. гос. ун–та},
title = {{Когнитивное метамоделирование. Элементы сознания и картины мира}},
year = {2014}
}
@incollection{Maslov1982,
author = {Маслов, С. Ю.},
booktitle = {Семиотика и информатика},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Семиотика и информатика/1982/Маслов - 1982.pdf:pdf},
language = {russian},
pages = {3--34},
title = {{Асимметрия познавательных механизмов и ее следствия}},
volume = {20},
year = {1982}
}
@article{Chernavskaya2013,
abstract = {The problem of the thinking process modeling is considered within the context of Dynamical Theory of Information. The proposed definition for thinking process is based on listing its main goals and functions. A set of various type neural processors is considered to reveal necessary and sufficient combination to implement these basic functions. It is shown that, according to DTI, the artificial thinking system is to be divided into two subsystems, where the first subsystem provides generation of information and learning, the second one - storage and application of the information. This correlates with presence of two hemispheres of the human brain, one of them is believed to produce the intuition, while the other one being responsible for the logical thinking. A particular version of the thinking-system architecture is proposed. It is shown that in the course of evolution, the system is progressively growing from low imaginary information levels, through semantic levels (where the information has sense for this individual system only), up to high abstract levels that could be verbalized to be generally realized. An interpretation of intuitive and logical thinking is given. Our approach, being close to that common for BICA, does differ in certain points. We are not dealing with the active agents that are a priori endowed with emotions, motivations, and comprehension. Instead, starting with just formal (but dynamical) neurons, the system itself, due to the self-organizing nonlinear interactions of the neuron ensembles, could produce semantic and abstract information, and perceive the verbalized one. ?? 2013 Elsevier B.V. All rights reserved.},
author = {Chernavskaya, O. D. and Chernavskii, D. S. and Karp, V. P. and Nikitin, a. P. and Shchepetov, D. S.},
doi = {10.1016/j.bica.2013.05.013},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2013/Chernavskaya et al. - 2013.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Choice,Image,Information,Selection,Symbol,Thinking process},
pages = {147--158},
publisher = {Elsevier B.V.},
title = {{An architecture of thinking system within the Dynamical Theory of Information}},
url = {http://dx.doi.org/10.1016/j.bica.2013.05.013},
volume = {6},
year = {2013}
}
@article{Takac2015,
author = {Takac, Martin and Knott, Alistair and Knott, Alistair},
doi = {10.1007/s12559-015-9330-3},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Computation/2015/Takac, Knott, Knott - 2015.pdf:pdf},
issn = {1866-9964},
journal = {Cognitive Computation},
keywords = {Action preparation,Language processing,Neural network modelling,Sequence learning,Working memory,modelling {\'{a}} sequence learning,network,working memory {\'{a}} neural,{\'{a}} action preparation {\'{a}}},
pages = {1--17},
publisher = {Springer US},
title = {{A Neural Network Model of Episode Representations in Working Memory}},
url = {"http://dx.doi.org/10.1007/s12559-015-9330-3},
year = {2015}
}
@inproceedings{Rasmussen1998,
author = {Rasmussen, Daniel and Eliasmith, Chris},
booktitle = {Proceedings of the 36th Annual Conference of the Cognitive Science Society},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the 36th Annual Conference of the Cognitive Science Society/2014/Rasmussen, Eliasmith - 2014.pdf:pdf},
keywords = {brain could achieve its,hierarchical,hrl into a theory,neural engineering framework,neural model,of neural function,providing a hypothe-,reinforcement learning,sis for how the,strengths in scaling},
number = {1},
pages = {1252--1257},
title = {{A neural model of hierarchical reinforcement learning}},
year = {2014}
}
@article{Chudova2012b,
author = {Чудова, Н. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Искусственный интеллект и принятие решений/2012/Чудова - 2012.pdf:pdf},
journal = {Искусственный интеллект и принятие решений},
keywords = {12-07-00611,psycho},
language = {russian},
mendeley-tags = {12-07-00611,psycho},
number = {2},
pages = {51--62},
title = {{Концептуальная модель картины мира для задачи моделирования поведения, основанного на сознании}},
year = {2012}
}
@inproceedings{Process,
abstract = {This paper shows a formal model of cognitive function of decision-making. The decision-making is only one of several cognitive functions of high level of natural intelligence. Our model has been inspired by human decision-making process. In order to show a comprehensive and coherent model of human decision-making process based on a rigorous formalism, we have adopted a multidisciplinary approach encompassing knowledge in cognitive informatics, neuroscience, and psychology. The model has been divided into conceptual, formal, and computational model. However, in this paper we show the conceptual and part of the formal model. In order to develop a comprehensive and coherent conceptual model of the decision- making process and its relationship with others cognitive processes, we have adopted the layered reference model postulated by Wang. Our conceptual model shows the main brain areas involved in the decision-making process and describes their functions. While our formal model tries to show a rigorous explanation for the cognitive decision-making process.},
author = {Process, Decision-making and Wang, Yingxu},
booktitle = {Proceedings IEEE International Conference on Cognitive Inlormatics {\&} Cognitive Computing},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings IEEE International Conference on Cognitive Inlormatics {\&} Cognitive Computing/2015/Process, Wang - 2015.pdf:pdf},
isbn = {9181461312909},
keywords = {cognitive informatics,decision-making,fuzzy logic,natural intelligence},
pages = {375--383},
title = {{A Formal Model Inspired on Human Decision-Making Process}},
year = {2015}
}
@book{Tikhomirov1988,
address = {M.},
author = {Tikhomirov, O. K.},
keywords = {psycho},
mendeley-tags = {psycho},
pages = {272},
publisher = {Progress},
title = {{Psychology of thinking}},
year = {1988}
}
@inproceedings{Osipov2015b,
abstract = {Уточняется понятие знака, достаточно широко используемое в психологии, в частности, в культурно-исторической теории Л. С. Выготского, где знак понимается неформальным образом. Рассмотрены процедуры формирования знаков и самоорганизация на множестве знаков. Результатом самоорганизации является новый способ описания картины мира субъекта деятельности. На основе предложенной картины мира строятся модели некоторых функций сознания.},
address = {Челябинск},
author = {Осипов, Г. С.},
booktitle = {Информационные технологии и системы: Труды Четвертой международной научной конференции},
editor = {Попков, Ю. С. and Мельников, А. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Информационные технологии и системы Труды Четвертой международной научной конференции/2015/Осипов - 2015.pdf:pdf},
keywords = {15-07-06214,osipov},
language = {russian},
mendeley-tags = {15-07-06214,osipov},
pages = {94--100},
publisher = {Изд-во Челяб. гос. ун–та},
title = {{Когнитивное метамоделирование}},
year = {2015}
}
@article{Horton2005,
abstract = {This year, the field of neuroscience celebrates the 50th anniversary of Mountcastle's discovery of the cortical column. In this review, we summarize half a century of research and come to the disappointing realization that the column may have no function. Originally, it was described as a discrete structure, spanning the layers of the somatosensory cortex, which contains cells responsive to only a single modality, such as deep joint receptors or cutaneous receptors. Subsequently, examples of columns have been uncovered in numerous cortical areas, expanding the original concept to embrace a variety of different structures and principles. A "column" now refers to cells in any vertical cluster that share the same tuning for any given receptive field attribute. In striate cortex, for example, cells with the same eye preference are grouped into ocular dominance columns. Unaccountably, ocular dominance columns are present in some species, but not others. In principle, it should be possible to determine their function by searching for species differences in visual performance that correlate with their presence or absence. Unfortunately, this approach has been to no avail; no visual faculty has emerged that appears to require ocular dominance columns. Moreover, recent evidence has shown that the expression of ocular dominance columns can be highly variable among members of the same species, or even in different portions of the visual cortex in the same individual. These observations deal a fatal blow to the idea that ocular dominance columns serve a purpose. More broadly, the term "column" also denotes the periodic termination of anatomical projections within or between cortical areas. In many instances, periodic projections have a consistent relationship with some architectural feature, such as the cytochrome oxidase patches in V1 or the stripes in V2. These tissue compartments appear to divide cells with different receptive field properties into distinct processing streams. However, it is unclear what advantage, if any, is conveyed by this form of columnar segregation. Although the column is an attractive concept, it has failed as a unifying principle for understanding cortical function. Unravelling the organization of the cerebral cortex will require a painstaking description of the circuits, projections and response properties peculiar to cells in each of its various areas.},
author = {Horton, Jonathan C and Adams, Daniel L},
doi = {10.1098/rstb.2005.1623},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Philosophical transactions of the Royal Society of London. Series B, Biological sciences/2005/Horton, Adams - 2005.pdf:pdf},
issn = {0962-8436},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Brain Mapping,Cerebral Cortex,Cerebral Cortex: anatomy {\&} histology,Cerebral Cortex: physiology,Electron Transport Complex IV,Electron Transport Complex IV: metabolism,Humans,Models, Neurological,Neurological,Visual Pathways,Visual Pathways: cytology,Visual Pathways: physiology,Visual Perception,Visual Perception: physiology},
number = {1456},
pages = {837--62},
pmid = {15937015},
title = {{The cortical column: a structure without a function}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1569491{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {360},
year = {2005}
}
@article{Favareau2015,
author = {Favareau, Donald},
doi = {10.1007/s12304-015-9234-3},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biosemiotics/2015/Favareau - 2015.pdf:pdf},
issn = {1875-1342},
journal = {Biosemiotics},
keywords = {pragmatic maxim,referential generality,semiotic constraints,semiotic pathway bias,semiotic scaffolding,symbol grounding},
pages = {235--255},
title = {{Symbols are Grounded not in Things, but in Scaffolded Relations and their Semiotic Constraints (Or How the Referential Generality of Symbol Scaffolding Grows Minds)}},
url = {http://link.springer.com/10.1007/s12304-015-9234-3},
year = {2015}
}
@article{Bonarini2003,
abstract = {We propose an architecture to implement coordination among fuzzy behavior modules for autonomous agents, in real-time tasks. Behavior coordination is obtained by fuzzy conditions and motivations evaluated on information provided by intelligent sensors and a world modeler. We also discuss the compatibility of our architecture with cognitive models. We present the application of this architecture in one of the domains we have faced with it: service and edutainment robotics. ?? 2002 Elsevier Science B.V. All rights reserved.},
author = {Bonarini, Andrea and Invernizzi, Giovanni and {Halva Labella}, Thomas and Matteucci, Matteo},
doi = {10.1016/S0165-0114(02)00232-4},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Fuzzy Sets and Systems/2003/Bonarini et al. - 2003.pdf:pdf},
issn = {01650114},
journal = {Fuzzy Sets and Systems},
keywords = {Agent architecture,Behavior-based robotics,Cognitive robotics,Fuzzy systems,Robotic architecture},
number = {1},
pages = {101--115},
title = {{An architecture to coordinate fuzzy behaviors to control an autonomous robot}},
volume = {134},
year = {2003}
}
@article{George2005,
abstract = {We describe a hierarchical model of invariant visual pattern recognition in the visual cortex. In this model, the knowledge of how patterns change when objects move is learned and encapsulated in terms of high probability sequences at each level of the hierarchy. Configuration of object parts is captured by the patterns of coincident high probability sequences. This knowledge is then encoded in a highly efficient Bayesian Network structure.The learning algorithm uses a temporal stability criterion to discover object concepts and movement patterns. We show that the architecture and algorithms are biologically plausible. The large scale architecture of the system matches the large scale organization of the cortex and the micro-circuits derived from the local computations match the anatomical data on cortical circuits. The system exhibits invariance across a wide variety of transformations and is robust in the presence of noise. Moreover, the model also offers alternative explanations for various known cortical phenomena.},
author = {George, Dileep and Hawkins, Jeff},
doi = {10.1109/IJCNN.2005.1556155},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN)/2005/George, Hawkins - 2005.pdf:pdf},
isbn = {0780390482},
journal = {Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN)},
keywords = {Bayes methods,Bayesian model,Bayesian network structure,anatomical data,belief networks,cortical circuit,cortical phenomena,htm,invariant visual pattern recognition,large scale architecture,learning (artificial intelligence),learning algorithm,micro-circuits,movement pattern,neural nets,object concept,pattern recognition,probability,probability sequence,temporal stability,visual cortex},
mendeley-tags = {htm},
pages = {1812--1817},
pmid = {1556155},
title = {{A hierarchical Bayesian model of invariant pattern recognition in the visual cortex}},
volume = {3},
year = {2005}
}
@article{Beckes2015,
author = {Beckes, Lane and IJzerman, Hans and Tops, Mattie},
doi = {10.3389/fnhum.2015.00266},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in Human Neuroscience/2015/Beckes, IJzerman, Tops - 2015.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {and close relationships,attachment,attachment, embodied cognition, interpersonal rela,ecological psychology,embodied cognition,interpersonal rela,interpersonal relationships,neurobiology,neuroscience of attachment,oxytocin,thermoregulation,toward a radically embodied},
pages = {1--18},
title = {{Toward a radically embodied neuroscience of attachment and relationships}},
url = {http://journal.frontiersin.org/article/10.3389/fnhum.2015.00266},
volume = {9},
year = {2015}
}
@article{Anderson2004,
abstract = {Adaptive control of thought-rational (ACT-R; J. R. Anderson {\&} C. Lebiere, 1998) has evolved into a theory that consists of multiple modules but also explains how these modules are integrated to produce coherent cognition. The perceptual-motor modules, the goal module, and the declarative memory module are presented as examples of specialized systems in ACT-R. These modules are associated with distinct cortical regions. These modules place chunks in buffers where they can be detected by a production system that responds to patterns of information in the buffers. At any point in time, a single production rule is selected to respond to the current pattern. Subsymbolic processes serve to guide the selection of rules to fire as well as the internal operations of some modules. Much of learning involves tuning of these subsymbolic processes. A number of simple and complex empirical examples are described to illustrate how these modules function singly and in concert.},
author = {Anderson, John R and Bothell, Daniel and Byrne, Michael D and Douglass, Scott and Lebiere, Christian and Qin, Yulin},
doi = {10.1037/0033-295X.111.4.1036},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Psychological review/2004/Anderson et al. - 2004.pdf:pdf},
isbn = {ISSN{\~{}}{\~{}}2004-1901},
issn = {0033-295X},
journal = {Psychological review},
keywords = {cog{\_}arch},
mendeley-tags = {cog{\_}arch},
number = {4},
pages = {1036--1060},
pmid = {15482072},
title = {{An integrated theory of the mind}},
volume = {111},
year = {2004}
}
@article{Douglas1989c,
author = {Douglas, Rodney J and Martin, Kevan A C and Whitteridge, David},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural Computation/1989/Douglas, Martin, Whitteridge - 1989.pdf:pdf},
journal = {Neural Computation},
title = {{A Canonical Microcircuit for Neocortex}},
year = {1989}
}
@article{Rabinovich2015,
author = {Rabinovich, Mikhail I. and Simmons, Alan N. and Varona, Pablo},
doi = {10.1016/j.tics.2015.06.005},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in Cognitive Sciences/2015/Rabinovich, Simmons, Varona - 2015.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
keywords = {cognitive dynamical principles,competition,functional cognitive networks,robust cognitive processing,sequential stability and winnerless,stable heteroclinic channel,transient brain dynamics},
number = {8},
pages = {453--461},
publisher = {Elsevier Ltd},
title = {{Dynamical bridge between brain and mind}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1364661315001424},
volume = {19},
year = {2015}
}
@inproceedings{Chudova2012c,
author = {Чудова, Н. В.},
booktitle = {Пятая международная конференция по когнитивной науке: Тезисы докладов: Калининград, 18-24 июня 2012 г.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Пятая международная конференция по когнитивной науке Тезисы докладов Калининград, 18-24 июня 2012 г/2012/Чудова - 2012.pdf:pdf},
language = {russian},
pages = {815--816},
title = {{К вопросу об операционализации понятия ``картина мира''}},
year = {2012}
}
@article{Samborska2016,
author = {Samborska, Veronika and Gordleeva, Susanna and Ullner, Ekkehard and Lebedeva, Albina and Kazantsev, Viktor and Zaikin, Alexey},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Opera Medica {\&} Physiologica/2016/Samborska et al. - 2016.pdf:pdf},
journal = {Opera Medica {\&} Physiologica},
keywords = {complexity,glial-neural,intelligence,network analysis,neural networks,nonlinearity,perceptron},
number = {1},
pages = {23--38},
title = {{Mammalian Brain As a Network of Networks}},
year = {2016}
}
@article{Kruglanski2011,
abstract = {Apopular distinction in cognitive and social psychology has been between intuitive and deliberate judgments. This juxtaposition has aligned in dual-process theories of reasoning associative, unconscious, effortless, heuristic, and suboptimal processes (assumed to foster intuitive judgments) versus rule-based, conscious, effortful, analytic, and rational processes (assumed to characterize deliberate judgments). In contrast, we provide convergent arguments and evidence for a unified theoretical approach to both intuitive and deliberative judgments. Both are rule-based, and in fact, the very same rules can underlie both intuitive and deliberate judgments. The important open question is that of rule selection, and we propose a 2-step process in which the task itself and the individual's memory constrain the set of applicable rules, whereas the individual's processing potential and the (perceived) ecological rationality of the rule for the task guide the final selection from that set. Deliberate judgments are not generally more accurate than intuitive judgments; in both cases, accuracy depends on the match between rule and environment: the rules' ecological rationality. Heuristics that are less effortful and in which parts of the information are ignored can be more accurate than cognitive strategies that have more information and computation. The proposed framework adumbrates a unified approach that specifies the critical dimensions on which judgmental situations may vary and the environmental conditions under which rules can be expected to be successful.},
author = {Kruglanski, Arie W. and Gigerenzer, Gerd},
doi = {10.1037/a0020762},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Psychological Review/2011/Kruglanski, Gigerenzer - 2011.pdf:pdf},
isbn = {0033-295X$\backslash$r1939-1471},
issn = {1939-1471},
journal = {Psychological Review},
keywords = {at times,deliberate judgments,dual-systems models,heuristics,intuitive judgments,nowhere,of the manner of,of their origins or,out much conscious awareness,people,quickly and effortlessly,s judgments seem intuitive,seemingly popping out of,they come to mind,unimodel,with-},
number = {1},
pages = {97--109},
pmid = {21480737},
title = {{Intuitive and deliberate judgments are based on common principles}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0020762},
volume = {118},
year = {2011}
}
@article{Reggia2013,
abstract = {Efforts to create computational models of consciousness have accelerated over the last two decades, creating a field that has become known as artificial consciousness. There have been two main motivations for this controversial work: to develop a better scientific understanding of the nature of human/animal consciousness and to produce machines that genuinely exhibit conscious awareness. This review begins by briefly explaining some of the concepts and terminology used by investigators working on machine consciousness, and summarizes key neurobiological correlates of human consciousness that are particularly relevant to past computational studies. Models of consciousness developed over the last twenty years are then surveyed. These models are largely found to fall into five categories based on the fundamental issue that their developers have selected as being most central to consciousness: a global workspace, information integration, an internal self-model, higher-level representations, or attention mechanisms. For each of these five categories, an overview of past work is given, a representative example is presented in some detail to illustrate the approach, and comments are provided on the contributions and limitations of the methodology. Three conclusions are offered about the state of the field based on this review: (1) computational modeling has become an effective and accepted methodology for the scientific study of consciousness, (2) existing computational models have successfully captured a number of neurobiological, cognitive, and behavioral correlates of conscious information processing as machine simulations, and (3) no existing approach to artificial consciousness has presented a compelling demonstration of phenomenal machine consciousness, or even clear evidence that artificial phenomenal consciousness will eventually be possible. The paper concludes by discussing the importance of continuing work in this area, considering the ethical issues it raises, and making predictions concerning future developments.},
author = {Reggia, James A},
doi = {10.1016/j.neunet.2013.03.011},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural networks the official journal of the International Neural Network Society/2013/Reggia - 2013.pdf:pdf},
issn = {1879-2782},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Artificial Intelligence,Computer Simulation,Consciousness,consciousness},
mendeley-tags = {consciousness},
pages = {112--31},
pmid = {23597599},
title = {{The rise of machine consciousness: studying consciousness with computational models.}},
url = {http://www.sciencedirect.com/science/article/pii/S0893608013000968},
volume = {44},
year = {2013}
}
@inproceedings{Osipov1997b,
address = {Bratislava},
author = {Pospelov, D. A. and Osipov, G. S.},
booktitle = {Proceedings of the Second Workshop on Applied Semiotics, Seventh International Conference on Artificial Intelligence and Information-Control Systems of Robots (AIICSR'97)},
keywords = {osipov},
mendeley-tags = {osipov},
pages = {1--12},
title = {{Knowledge in semiotic models}},
year = {1997}
}
@incollection{Zhdanov1997,
address = {М.},
author = {Жданов, А. А.},
booktitle = {Сборник «Вопросы кибернетики". Научный совет по комплексной проблеме «Кибернетика» РАН. Вып. 3},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Сборник «Вопросы кибернетики. Научный совет по комплексной проблеме «Кибернетика» РАН. Вып. 3/1997/Жданов - 1997.pdf:pdf},
language = {russian},
pages = {258--274},
title = {{Формальная модель нейрона и нейросети в методологии автономного адаптивного управлении}},
year = {1997}
}
@article{Abarbanel1996,
author = {Абарбанель, Г. Д. И. and Рабинович, М. И. and Селверстон, А. and Баженов, М. В. and Хуэрта, Р. and Сущик, М. М. and Рубчинский, Л. Л.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Успехи физических наук/1996/Абарбанель et al. - 1996.pdf:pdf},
journal = {Успехи физических наук},
language = {russian},
number = {4},
pages = {363--390},
title = {{Синхрониазция в нейронных ансамблях}},
volume = {166},
year = {1996}
}
@book{Vygotsky1960,
address = {М.},
author = {Выготский, Л. С.},
editor = {Леонтьев, Алексей Николаевич and Лурия, A. Р. and Теплова, Б. М.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/1960/Выготский - 1960.pdf:pdf},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {130},
publisher = {Издательство Академии педагогических наук},
title = {{Развитие высших психических функций}},
year = {1960}
}
@article{Caro2015,
abstract = {Metacognition has been used in artificial intelligence to increase the level of autonomy of intelligent systems. However the design of systems with metacognitive capabilities is a difficult task due to the number and complexity of processes involved. This paper presents a domain-specific visual language specifically developed for modeling metacognition in intelligent systems called M++. In M++ the specifications of the cognitive level (object-level) and metacognitive level (meta-level) are supported in a metamodel configured according to the standard Meta-Object Facility (MOF) of Model-Driven Architecture (MDA) methodology. M++ allows the generation of metacognitive diagrams in a visual editor named MetaThink. A validation process was conducted to ensure the reliability of M++ in terms of quality of the notation and consistency of generated models. The validation was performed using two techniques: (i) empirical study and (ii) model tracing. The results given in the experimental study demonstrate that M++ is a useful notation for the process of modeling metacognitive components in intelligent systems. Metacognitive models generated from the validation process using the Tracing technique were consistent with the MOF-based metamodel. M++ contribute to cognitive architecture research adding precision to metacognitive concepts and enabling cognitive architecture researchers to do fast and exploratory prototyping of metacognitive systems using MetaThink tool.},
author = {Caro, Manuel F. and Josyula, Darsana P. and Jim{\'{e}}nez, Jovani A. and Kennedy, Catriona M. and Cox, Michael T.},
doi = {10.1016/j.bica.2015.06.004},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2015/Caro et al. - 2015.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Domain-specific visual language,Intelligent system,MOF,Metacognition,Modeling tool},
pages = {75--90},
title = {{A domain-specific visual language for modeling metacognition in intelligent systems}},
volume = {13},
year = {2015}
}
@article{Zador2012,
abstract = {Connectivity determines the function of neural circuits. Historically, circuit mapping has usually been viewed as a problem of microscopy, but no current method can achieve high-throughput mapping of entire circuits with single neuron precision. Here we describe a novel approach to determining connectivity. We propose BOINC ("barcoding of individual neuronal connections"), a method for converting the problem of connectivity into a form that can be read out by high-throughput DNA sequencing. The appeal of using sequencing is that its scale--sequencing billions of nucleotides per day is now routine--is a natural match to the complexity of neural circuits. An inexpensive high-throughput technique for establishing circuit connectivity at single neuron resolution could transform neuroscience research.},
author = {Zador, Anthony M and Dubnau, Joshua and Oyibo, Hassana K and Zhan, Huiqing and Cao, Gang and Peikon, Ian D},
doi = {10.1371/journal.pbio.1001411},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS biology/2012/Zador et al. - 2012.pdf:pdf},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Animals,Brain Mapping,Brain Mapping: methods,Connectome,DNA,DNA: methods,Humans,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Sequence Analysis},
number = {10},
pages = {e1001411},
pmid = {23109909},
title = {{Sequencing the connectome}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3479097{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {10},
year = {2012}
}
@article{Vul2014,
abstract = {In many learning or inference tasks human behavior approximates that of a Bayesian ideal observer, suggesting that, at some level, cognition can be described as Bayesian inference. However, a number of findings have highlighted an intriguing mismatch between human behavior and standard assumptions about optimality: People often appear to make decisions based on just one or a few samples from the appropriate posterior probability distribution, rather than using the full distribution. Although sampling-based approximations are a common way to implement Bayesian inference, the very limited numbers of samples often used by humans seem insufficient to approximate the required probability distributions very accurately. Here, we consider this discrepancy in the broader framework of statistical decision theory, and ask: If people are making decisions based on samples--but as samples are costly--how many samples should people use to optimize their total expected or worst-case reward over a large number of decisions? We find that under reasonable assumptions about the time costs of sampling, making many quick but locally suboptimal decisions based on very few samples may be the globally optimal strategy over long periods. These results help to reconcile a large body of work showing sampling-based or probability matching behavior with the hypothesis that human cognition can be understood in Bayesian terms, and they suggest promising future directions for studies of resource-constrained cognition.},
author = {Vul, Edward and Goodman, Noah and Griffiths, Thomas L. and Tenenbaum, Joshua B.},
doi = {10.1111/cogs.12101},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Science/2014/Vul et al. - 2014.pdf:pdf},
isbn = {1551-6709},
issn = {03640213},
journal = {Cognitive Science},
keywords = {Bayesian,Bounded rationality,Computational,Inference,Sampling},
number = {4},
pages = {599--637},
pmid = {24467492},
title = {{One and done? Optimal decisions from very few samples}},
volume = {38},
year = {2014}
}
@incollection{Hexmoor1996,
abstract = {Routine interactions in the world of an autonomous agent are a major source of learning for the agent. In my approach an agent interacts in the world in several different ways, from cognitive to automatic. I show that an agent can learn and also improve its routine interactions in its different modes of interaction in the world. I present a formalism and use for a goal structure known as goal sketch [11]. Rewards and punishments generated from a goal sketch which indicate progress in goal satisfaction are used to improve automatic interactions and enhance agent's strategies and concepts about action. I will discuss my experiments with a physical robot that uses a goal sketch in order to generate rewards and punishments which are then used in improving robot skills and discovering new actions.},
author = {Hexmoor, Henry},
booktitle = {Intelligent Agents II Agent Theories, Architectures, and Languages},
doi = {10.1007/3540608052_61},
editor = {Wooldridge, Michael and Muller, J{\"{o}}rg P. and Tambe, Milind},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Intelligent Agents II Agent Theories, Architectures, and Languages/1996/Hexmoor - 1996.pdf:pdf},
pages = {97--110},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Learning Routines}},
year = {1996}
}
@article{Galitsky2013,
abstract = {We develop a generic software component for computing consecutive plausible mental states of human agents. The simulation approach to reasoning about mental world is introduced that is based on exhaustive search through the space of available behaviors. This approach to reasoning is implemented as a logic program in a natural language multiagent mental simulator NL-MAMS, which yields the totality of possible mental states few steps in advance, given an arbitrary initial mental state of participating agents. Due to an extensive vocabulary of formally represented mental attitudes, communicative actions and accumulated library of behaviors, NL-MAMS is capable of yielding much richer set of sequences of mental state than a conventional system of reasoning about beliefs, desires and intentions would deliver. Also, NL-MAMS functions in domain-independent manner, outperforming machine learning-based systems for predicting behaviors of human agents in broad domains where training sets are limited. We evaluate the correctness, coverage and maximum complexity of the NL-MAMS and discuss its integration with other reasoning components and its application domains. The proposed component is intended to be integrated into eBay human behavior simulation system, predicting behavior of buyers and sellers in normal and conflict situations. Also, NL-MAMS can be a part of any software system where modeling of human users is necessary, such as a personalized assistant, a tutoring or decision support system, advisor, recommender and conflict resolver. ?? 2013 Elsevier B.V. All rights reserved.},
author = {Galitsky, Boris},
doi = {10.1016/j.knosys.2012.11.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Knowledge-Based Systems/2013/Galitsky - 2013.pdf:pdf},
isbn = {0950-7051, 0950-7051},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Belief,Desire,Intention and other mental attitudes,Interaction between human agents,Reasoning about mental attitudes,Simulation},
pages = {1--20},
title = {{Exhaustive simulation of consecutive mental states of human agents}},
url = {http://dx.doi.org/10.1016/j.knosys.2012.11.001},
volume = {43},
year = {2013}
}
@inproceedings{Ragni2012,
author = {Ragni, Marco and Neubert, Stefanie},
booktitle = {ECAI 2012: 20h European Conference on Artificial Intelligence: Proceedings},
doi = {10.3233/978-1-61499-098-7-666},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/ECAI 2012 20h European Conference on Artificial Intelligence Proceedings/2012/Ragni, Neubert - 2012.pdf:pdf},
isbn = {9781614990987},
pages = {666--671},
title = {{Solving Raven's IQ-tests : An AI and Cognitive Modeling Approach}},
year = {2012}
}
@article{Roy2005,
author = {Roy, D.},
doi = {10.1016/j.artint.2005.04.007},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Artificial Intelligence/2005/Roy - 2005.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {1,action,and consequently our ability,and the physical world,cross-modal,embodied,grounding,language,language and meaning,meaning,multimodal,perception,representation,schemas,semiotic,semiotics,situated,the relationship between words,to},
mendeley-tags = {semiotics},
number = {1-2},
pages = {170--205},
title = {{Semiotic schemas: A framework for grounding language in action and perception}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370205001037},
volume = {167},
year = {2005}
}
@phdthesis{Rasmussen2014,
author = {Rasmussen, Daniel},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2014/Rasmussen - 2014.pdf:pdf},
pages = {175},
school = {Unversetu of Waterloo},
title = {{Hierarchical reinforcement learning in a biologically plausible neural architecture}},
year = {2014}
}
@incollection{Vityaev1998,
address = {Новосибирск},
author = {Витяев, Е. Е.},
booktitle = {Модели когнитивных процессов},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Модели когнитивных процессов/1998/Витяев - 1998.pdf:pdf},
language = {russian},
pages = {14--40},
publisher = {Институт математики им. С.Л. Соболев},
series = {Вычислительные системы},
title = {{Вероятностное прогнозирование и предсказание как принцип работы мозга}},
year = {1998}
}
@inproceedings{Pacer2012,
abstract = {The categories named by spatial terms vary considerably across languages. It is often proposed that underlying this variation is a universal set of primitive spatial concepts that are combined differently in different languages. Despite the inherently cognitive assumptions of this proposal, such spatial primitives have generally been inferred in a top-down manner from linguistic data. Here we show that comparable spatial primitives can be inferred bottom-up from non-linguistic pile-sorting of spatial stimuli by speakers of English, Dutch, and Chichewa. We demonstrate that primitives obtained in this fashion explain meaningful cross-linguistic variation in spatial categories better than primitives designed by hand for that purpose, and reflect both universal and language-specific spatial semantics.},
author = {Pacer, M. and Carstensen, A. and Regier, T.},
booktitle = {Proceedings of the 34th Annual Meeting of the Cognitive Science Society},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the 34th Annual Meeting of the Cognitive Science Society/2012/Pacer, Carstensen, Regier - 2012.pdf:pdf},
isbn = {978-0-9768318-8-4},
keywords = {Language and thought,Linguistic relativity,Spatial cognition,semantic primitives,semantic universals},
pages = {827--832},
title = {{Grounding spatial language in non-linguistic cognition: Evidence for universal and relative spatial semantics in thought}},
year = {2012}
}
@article{Mnatsakanian2004,
abstract = {Objective: We studied the event-related potentials elicited by categorical matching of faces. The purpose was to find cortical sources responsible for face recognition and comparison. Methods: Nineteen healthy volunteers participated in the study. Each trial began with one of the two cues (S1) followed by consecutive pictures (S2 and S3). Each picture was a photograph of a familiar face with a superimposed abstract dot pattern. One cue directed attention to compare faces and another to compare patterns. 128-channel electroencephalogram was recorded. Spatio-temporal multiple dipole source models were generated using Brain Electromagnetic Source Analysis 2000, for the window of 80-600 ms from S3 onset. Results: The obtained model for face recognition and comparison contained 8 dipoles explaining 97{\%} of grand average and about 90{\%} of individual data and showing temporal and spatial separation of sources: in the frontal region, in the occipital cortex, and in the bilateral medial temporal and inferotemporal regions. Different faces elicited larger components than same person's faces around 400 ms, mainly explained by frontal dipoles. Conclusions: The sources in our models estimate the activity common for both Face task conditions (the recognition of a familiar person) and also differential activity, related to the match/mismatch item processing. ?? 2004 International Federation of Clinical Neurophysiology. Published by Elsevier Ireland Ltd. All rights reserved.},
author = {Mnatsakanian, Elena V. and Tarkka, Ina M.},
doi = {10.1016/j.clinph.2003.11.027},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Clinical Neurophysiology/2004/Mnatsakanian, Tarkka - 2004.pdf:pdf},
isbn = {1388-2457 (Print)},
issn = {13882457},
journal = {Clinical Neurophysiology},
keywords = {Eelectroencephalogram,Face processing,Multiple dipole model,N400-like components,Priming},
number = {4},
pages = {880--886},
pmid = {15003769},
title = {{Familiar-face recognition and comparison: Source analysis of scalp-recorded event-related potentials}},
volume = {115},
year = {2004}
}
@article{Ward2011,
abstract = {I propose that primary conscious awareness arises from synchronized activity in dendrites of neurons in dorsal thalamic nuclei, mediated particularly by inhibitory interactions with thalamic reticular neurons. In support, I offer four evidential pillars: (1) consciousness is restricted to the results of cortical computations; (2) thalamus is the common locus of action of brain injury in vegetative state and of general anesthetics; (3) the anatomy and physiology of the thalamus imply a central role in consciousness; (4) neural synchronization is a neural correlate of consciousness.},
author = {Ward, Lawrence M.},
doi = {10.1016/j.concog.2011.01.007},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Consciousness and cognition/2011/Ward - 2011.pdf:pdf},
issn = {1090-2376},
journal = {Consciousness and cognition},
keywords = {Attention,Attention: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Consciousness,Consciousness: physiology,Cortical Synchronization,Cortical Synchronization: physiology,Humans,Models,Neural Pathways,Neural Pathways: physiology,Neurological,Persistent Vegetative State,Persistent Vegetative State: physiopathology,Thalamus,Thalamus: physiology,consciousness},
mendeley-tags = {consciousness},
number = {2},
pages = {464--86},
pmid = {21349742},
publisher = {Elsevier Inc.},
title = {{The thalamic dynamic core theory of conscious experience}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21349742},
volume = {20},
year = {2011}
}
@book{Intelligence,
doi = {10.1007/978-3-662-43505-2},
editor = {Kacprzyk, Janusz and Pedrycz, Witold},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Unknown - 2015.pdf:pdf},
isbn = {9783662435045},
pages = {1634},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Springer Handbook of Computational Intelligence}},
year = {2015}
}
@article{Anderson2010,
abstract = {An emerging class of theories concerning the functional structure of the brain takes the reuse of neural circuitry for various cognitive purposes to be a central organizational principle. According to these theories, it is quite common for neural circuits established for one purpose to be exapted (exploited, recycled, redeployed) during evolution or normal development, and be put to different uses, often without losing their original functions. Neural reuse theories thus differ from the usual understanding of the role of neural plasticity (which is, after all, a kind of reuse) in brain organization along the following lines: According to neural reuse, circuits can continue to acquire new uses after an initial or original function is established; the acquisition of new uses need not involve unusual circumstances such as injury or loss of established function; and the acquisition of a new use need not involve (much) local change to circuit structure (e.g., it might involve only the establishment of functional connections to new neural partners). Thus, neural reuse theories offer a distinct perspective on several topics of general interest, such as: the evolution and development of the brain, including (for instance) the evolutionary-developmental pathway supporting primate tool use and human language; the degree of modularity in brain organization; the degree of localization of cognitive function; and the cortical parcellation problem and the prospects (and proper methods to employ) for function to structure mapping. The idea also has some practical implications in the areas of rehabilitative medicine and machine interface design.},
author = {Anderson, Michael L.},
doi = {10.1017/S0140525X10000853},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/The Behavioral and brain sciences/2010/Anderson - 2010.pdf:pdf},
issn = {1469-1825},
journal = {The Behavioral and brain sciences},
keywords = {Animals,Biological Evolution,Brain,Brain Mapping,Brain: anatomy {\&} histology,Brain: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Cognition,Cognition: physiology,Cognitive Science,Higher Nervous Activity,Higher Nervous Activity: physiology,Humans,Language,Models,Nerve Net,Nerve Net: physiology,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Primates},
number = {4},
pages = {245--66},
pmid = {20964882},
title = {{Neural reuse: a fundamental organizational principle of the brain}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20964882},
volume = {33},
year = {2010}
}
@book{Forstman2015,
booktitle = {Springer},
doi = {10.1007/978-1-4939-2236-9},
editor = {Forstman, Birte U. and Wagenmakers, Eric-Jan},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Springer/2015/Unknown - 2015.pdf:pdf},
isbn = {978-1-4939-2235-2},
publisher = {Springer New York},
title = {{An Introduction to Model-Based Cognitive Neuroscience}},
year = {2015}
}
@book{Machery2011,
address = {Oxford},
author = {Machery, Edouard},
isbn = {0199837562},
pages = {296},
publisher = {Oxford University Press},
title = {{Doing without Concepts}},
year = {2011}
}
@inproceedings{Ananthanarayanan2009,
author = {Ananthanarayanan, Rajagopal and Esser, Steven K and Simon, Horst D and Modha, Dharmendra S},
booktitle = {Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis/2009/Ananthanarayanan et al. - 2009.pdf:pdf},
number = {c},
pages = {1--12},
title = {{The Cat is Out of the Bag : Cortical Simulations with 10 9 Neurons , 10 13 Synapses}},
year = {2009}
}
@article{Riesenhuber1999,
author = {Riesenhuber, Maximilian and Poggio, Tomaso},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature Neuroscience/1999/Riesenhuber, Poggio - 1999.pdf:pdf},
journal = {Nature Neuroscience},
number = {11},
pages = {1019--1025},
title = {{Hierarchical models of object recognition in cortex}},
volume = {2},
year = {1999}
}
@incollection{2005,
author = {Выготский, Л. С.},
booktitle = {Психология развития человека},
editor = {Бобко, С.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Психология развития человека/2005/Выготский - 2005.pdf:pdf},
isbn = {5699137289},
keywords = {Vygotsky2005,psycho},
language = {russian},
mendeley-tags = {psycho},
pages = {664--1019},
publisher = {Эксмо},
title = {{Мышление и речь}},
year = {2005}
}
@article{Taylor1996,
author = {Taylor, John G.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neurocomputing/1996/Taylor - 1996.pdf:pdf},
journal = {Neurocomputing},
pages = {271--292},
title = {{Modelling Consciousness}},
volume = {11},
year = {1996}
}
@book{Aleksandrov2008,
address = {Тюмень},
author = {Александров, Ю. И. and Анохин, К. В. and Безденежных, Б. Н. and Гарина, Н. С. and Греченко, Т. Н. and Латанов, А. В. and Палихова, Т. А. and Савельев, С. В. and Соколов, Е. Н. and Тушмалова, Н. А. and Филиппов, В. А. and Черноризов, А. М.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2008/Александров et al. - 2008.pdf:pdf},
isbn = {9785400000058},
language = {russian},
pages = {548},
publisher = {Издательство Тюменского государственного университета},
title = {{Нейрон. Обработка сигналов. Пластичность. Моделирование: Фундаментальное руководство}},
year = {2008}
}
@article{Llinas1998,
author = {Llinas, R. and Ribary, U. and Contreras, D. and Pedroarena, C.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Philosophical Transactions of the Royal Society of London/1998/Llinas et al. - 1998.pdf:pdf},
journal = {Philosophical Transactions of the Royal Society of London},
keywords = {coincidence detection,consciousness,facilitation,gamma oscillations,thalamocortical,voltage sensitive dye},
pages = {1841--1849},
title = {{The neuronal basis for consciousness}},
volume = {353},
year = {1998}
}
@article{Tkacheva2011,
author = {Горбунов, И. А. and Ткачева, Л. О.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Вестник СПбГУ/2011/Горбунов, Ткачева - 2011.pdf:pdf},
journal = {Вестник СПбГУ},
keywords = {psycho},
language = {russian},
mendeley-tags = {psycho},
number = {1},
pages = {324--329},
title = {{Связь семантических характеристик сознаний с изменениями функционального состояния мозга}},
volume = {12},
year = {2011}
}
@article{Ivanitsky2010a,
author = {Ivanitsky, A. M.},
journal = {Herald of the Russian Academy of Sciences},
keywords = {consciousness},
mendeley-tags = {consciousness},
number = {3},
pages = {229--236},
title = {{Brain science on the way to solving the problem of consciousness}},
volume = {80},
year = {2010}
}
