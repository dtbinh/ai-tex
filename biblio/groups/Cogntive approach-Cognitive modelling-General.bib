Automatically generated by Mendeley Desktop 1.17.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Pulvermuller2010,
abstract = {Action and perception are functionally linked in the brain, but a hotly debated question is whether perception and comprehension of stimuli depend on motor circuits. Brain language mechanisms are ideal for addressing this question. Neuroimaging investigations have found specific motor activations when subjects understand speech sounds, word meanings and sentence structures. Moreover, studies involving transcranial magnetic stimulation and patients with lesions affecting inferior frontal regions of the brain have shown contributions of motor circuits to the comprehension of phonemes, semantic categories and grammar. These data show that language comprehension benefits from frontocentral action systems, indicating that action and perception circuits are interdependent.},
author = {Pulverm{\"{u}}ller, Friedemann and Fadiga, Luciano},
doi = {10.1038/nrn2811},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature reviews. Neuroscience/2010/Pulverm{\"{u}}ller, Fadiga - 2010.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$n1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature reviews. Neuroscience},
keywords = {Animals,Brain,Brain: physiology,Humans,Language,Neural Pathways,Neural Pathways: physiology,Speech,Speech Perception,Speech Perception: physiology,Speech: physiology},
number = {5},
pages = {351--360},
pmid = {20383203},
publisher = {Nature Publishing Group},
title = {{Active perception: sensorimotor circuits as a cortical basis for language.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20383203{\%}5Cnhttp://dx.doi.org/10.1038/nrn2811},
volume = {11},
year = {2010}
}
@article{Glenberg2012,
abstract = {Evolution and the brain have done a marvelous job solving many tricky problems in action control, including problems of learning, hierarchical control over serial behavior, continuous recalibration, and fluency in the face of slow feedback. Given that evolution tends to be conservative, it should not be surprising that these solutions are exploited to solve other tricky problems, such as the design of a communication system. We propose that a mechanism of motor control, paired controller/predictor models, has been exploited for language learning, comprehension, and production. Our account addresses the development of grammatical regularities and perspective, as well as how linguistic symbols become meaningful through grounding in perception, action, and emotional systems. ?? 2011 Elsevier Srl.},
author = {Glenberg, Arthur M. and Gallese, Vittorio},
doi = {10.1016/j.cortex.2011.04.010},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cortex/2012/Glenberg, Gallese - 2012.pdf:pdf},
isbn = {1973-8102 (Electronic)$\backslash$r0010-9452 (Linking)},
issn = {00109452},
journal = {Cortex},
keywords = {Embodiment,HMOSAIC model of action control,Language,Mirror neurons},
number = {7},
pages = {905--922},
pmid = {21601842},
publisher = {Elsevier Srl},
title = {{Action-based language: A theory of language acquisition, comprehension, and production}},
url = {http://dx.doi.org/10.1016/j.cortex.2011.04.010},
volume = {48},
year = {2012}
}
@article{Plebe2016a,
abstract = {Neural computation has an influential role in the study of human capacities and behaviors. It has been the dominant approach in the vision science of the last half century, and it is currently one of the fundamental methods of investigation for most higher cognitive func- tions. Yet, neurocomputational approaches to moral behavior are lacking. Computational modeling in general has been scarcely pursued in morality, and existent non-neural attempts have failed to account for the mental processes involved in morality. In this paper we argue that recently the situation has evolved in a way that subverted the insufficient knowledge on the basic organization of moral cognition in brain circuits, making the project of modeling morality in neurocomputational terms feasible. We will present an original architecture that combines reinforcement learning and Hebbian learning, aimed at simulating forms of moral behavior in a simple artificial context. The relationship between language and morality is controversial. In the analytic tradition of philosophy, morality is essentially the lan- guage of morals. On the other side, current cognitive ethology has shown how non human species display behaviors that are surprisingly similar to those prescribed by human ethics. Nevertheless, morality in humans is deeply entrenched with language, and the semantics of words like ‘wrong' resists consensual explanations. The model here proposed includes an auditory processing pathway, with the purpose of showing how the coding of ‘‘wrong”, even if highly simplified with respect to its rich content in natural language, can emerge in the course of moral learning.},
author = {Plebe, Alessio},
doi = {10.1016/j.cogsys.2015.12.012},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Cognitive Systems Research/2016/Plebe - 2016.pdf:pdf},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {amygdala,moral cognition,neural computation,orbitofrontal cortex,self-organization},
pages = {4--14},
title = {{What is ‘wrong' in a neural model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1389041716000085},
volume = {39},
year = {2016}
}
@article{Fu2014a,
author = {Fu, XiaoLan and Cai, LianHong and Liu, Ye YongJin and Jia, Jia and Chen, WenFeng and Yi, Zhang and Zhao, GuoZhen and Liu, Ye YongJin and Wu, ChangXu},
doi = {10.1007/s11432-013-4911-9},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Science China Information Sciences/2014/Fu et al. - 2014.pdf:pdf},
issn = {1674-733X},
journal = {Science China Information Sciences},
keywords = {computational cognition model,judgment,memory,perception},
language = {english},
number = {3},
pages = {1--15},
title = {{A computational cognition model of perception, memory, and judgment}},
url = {http://link.springer.com/10.1007/s11432-013-4911-9},
volume = {57},
year = {2014}
}
@incollection{Dobnik2013,
author = {Dobnik, Simon and Cooper, Robin},
booktitle = {Constraint Solving and Language Processing},
doi = {10.1007/978-3-642-41578-4_5},
editor = {Duchier, Denys and Parmentier, Yannick},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Constraint Solving and Language Processing/2013/Dobnik, Cooper - 2013.pdf:pdf},
keywords = {action,formal semantics,language,learning and classification,perception,scriptions,spatial de-},
pages = {70--91},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Modelling language, action, and perception in Type Theory with Records}},
year = {2013}
}
@article{Thilakarathne2015,
author = {Thilakarathne, Dilhan J.},
doi = {10.1016/j.bica.2015.04.010},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2015/Thilakarathne - 2015(2).pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {prior and retrospective,situation awareness},
publisher = {Elsevier B.V.},
title = {{Modelling of situation awareness with perception, attention, and prior and retrospective awareness}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X15000195},
year = {2015}
}
@article{Chernavsky2012a,
author = {Чернавская, О. Д. and Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Сложные системы/2012/Чернавская et al. - 2012(2).pdf:pdf},
journal = {Сложные системы},
language = {russian},
number = {3},
pages = {46--65},
title = {{Процесс мышления в контексте динамической теории информации. Часть II: понятие «образ» и «символ» как инструменты моделирования процесса мышления средствами нейрокомпьютинга}},
volume = {2},
year = {2012}
}
@article{Habenschuss2013,
abstract = {Experimental data from neuroscience suggest that a substantial amount of knowledge is stored in the brain in the form of probability distributions over network states and trajectories of network states. We provide a theoretical foundation for this hypothesis by showing that even very detailed models for cortical microcircuits, with data-based diverse nonlinear neurons and synapses, have a stationary distribution of network states and trajectories of network states to which they converge exponentially fast from any initial state. We demonstrate that this convergence holds in spite of the non-reversibility of the stochastic dynamics of cortical microcircuits. We further show that, in the presence of background network oscillations, separate stationary distributions emerge for different phases of the oscillation, in accordance with experimentally reported phase-specific codes. We complement these theoretical results by computer simulations that investigate resulting computation times for typical probabilistic inference tasks on these internally stored distributions, such as marginalization or marginal maximum-a-posteriori estimation. Furthermore, we show that the inherent stochastic dynamics of generic cortical microcircuits enables them to quickly generate approximate solutions to difficult constraint satisfaction problems, where stored knowledge and current inputs jointly constrain possible solutions. This provides a powerful new computing paradigm for networks of spiking neurons, that also throws new light on how networks of neurons in the brain could carry out complex computational tasks such as prediction, imagination, memory recall and problem solving.},
author = {Habenschuss, Stefan and Jonke, Zeno and Maass, Wolfgang},
doi = {10.1371/journal.pcbi.1003311},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS Computational Biology/2013/Habenschuss, Jonke, Maass - 2013.PDF:PDF},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {11},
pages = {e1003311},
pmid = {24244126},
title = {{Stochastic Computations in Cortical Microcircuit Models}},
volume = {9},
year = {2013}
}
@article{Vartanov2011,
author = {Вартанов, А. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Нейрокомпьютеры разработка, применение/2011/Вартанов - 2011.pdf:pdf},
journal = {Нейрокомпьютеры: разработка, применение},
keywords = {coding,consciousness,meaning,semantics,sign},
language = {russian},
number = {12},
pages = {54--64},
title = {{Механизмы семантики: человек - нейрон - модель}},
year = {2011}
}
@article{Fitch2014,
abstract = {Progress in understanding cognition requires a quantitative, theoretical framework, grounded in the other natural sciences and able to bridge between implementational, algorithmic and computational levels of explanation. I review recent results in neuroscience and cognitive biology that, when combined, provide key components of such an improved conceptual framework for contemporary cognitive science. Starting at the neuronal level, I first discuss the contemporary realization that single neurons are powerful tree-shaped computers, which implies a reorientation of computational models of learning and plasticity to a lower, cellular, level. I then turn to predictive systems theory (predictive coding and prediction-based learning) which provides a powerful formal framework for understanding brain function at a more global level. Although most formal models concerning predictive coding are framed in associationist terms, I argue that modern data necessitate a reinterpretation of such models in cognitive terms: as model-based predictive systems. Finally, I review the role of the theory of computation and formal language theory in the recent explosion of comparative biological research attempting to isolate and explore how different species differ in their cognitive capacities. Experiments to date strongly suggest that there is an important difference between humans and most other species, best characterized cognitively as a propensity by our species to infer tree structures from sequential data. Computationally, this capacity entails generative capacities above the regular (finite-state) level; implementationally, it requires some neural equivalent of a push-down stack. I dub this unusual human propensity "dendrophilia", and make a number of concrete suggestions about how such a system may be implemented in the human brain, about how and why it evolved, and what this implies for models of language acquisition. I conclude that, although much remains to be done, a neurally-grounded framework for theoretical cognitive science is within reach that can move beyond polarized debates and provide a more adequate theoretical future for cognitive biology. {\textcopyright} 2014.},
author = {Fitch, W. Tecumseh},
doi = {10.1016/j.plrev.2014.04.005},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Physics of Life Reviews/2014/Fitch - 2014.pdf:pdf},
issn = {15710645},
journal = {Physics of Life Reviews},
keywords = {Cognitive science,Comparative cognition,Computational neuroscience,Formal language theory,Mathematical psychology,Neurolinguistics},
number = {3},
pages = {329--364},
pmid = {24969660},
publisher = {Elsevier B.V.},
title = {{Toward a computational framework for cognitive biology: Unifying approaches from cognitive neuroscience and comparative cognition}},
url = {http://dx.doi.org/10.1016/j.plrev.2014.04.005},
volume = {11},
year = {2014}
}
@article{Chernavsky2012b,
author = {Чернавская, О. Д. and Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Сложные системы/2012/Чернавская et al. - 2012.pdf:pdf},
journal = {Сложные системы},
language = {russian},
number = {2},
pages = {25--41},
title = {{Процесс мышления в контексте динамической теории информации. Часть I. Цели и задачи мышления}},
volume = {1},
year = {2012}
}
@article{Sandamirskaya2013,
abstract = {Dynamic Field Theory (DFT) is an established framework for modeling embodied cognition. In DFT, elementary cognitive functions such as memory formation, formation of grounded representations, attentional processes, decision making, adaptation, and learning emerge from neuronal dynamics. The basic computational element of this framework is a Dynamic Neural Field (DNF). Under constraints on the time-scale of the dynamics, the DNF is computationally equivalent to a soft winner-take-all (WTA) network, which is considered one of the basic computational units in neuronal processing. Recently, it has been shown how a WTA network may be implemented in neuromorphic hardware, such as analog Very Large Scale Integration (VLSI) device. This paper leverages the relationship between DFT and soft WTA networks to systematically revise and integrate established DFT mechanisms that have previously been spread among different architectures. In addition, I also identify some novel computational and architectural mechanisms of DFT which may be implemented in neuromorphic VLSI devices using WTA networks as an intermediate computational layer. These specific mechanisms include the stabilization of working memory, the coupling of sensory systems to motor dynamics, intentionality, and autonomous learning. I further demonstrate how all these elements may be integrated into a unified architecture to generate behavior and autonomous learning.},
author = {Sandamirskaya, Yulia},
doi = {10.3389/fnins.2013.00276},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in neuroscience/2014/Sandamirskaya - 2014.pdf:pdf},
issn = {1662-4548},
journal = {Frontiers in neuroscience},
keywords = {Dynamic Neural Fields,autonomous learning,cognitive neuromorphic architecture,neural dynamics,soft winner take all},
pages = {276},
pmid = {24478620},
title = {{Dynamic neural fields as a step toward cognitive neuromorphic architectures}},
url = {http://journal.frontiersin.org/Journal/10.3389/fnins.2013.00276/abstract{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pmc/articles/PMC3898057/},
volume = {7},
year = {2014}
}
@inproceedings{Ragni2012,
author = {Ragni, Marco and Neubert, Stefanie},
booktitle = {ECAI 2012: 20h European Conference on Artificial Intelligence: Proceedings},
doi = {10.3233/978-1-61499-098-7-666},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/ECAI 2012 20h European Conference on Artificial Intelligence Proceedings/2012/Ragni, Neubert - 2012.pdf:pdf},
isbn = {9781614990987},
pages = {666--671},
title = {{Solving Raven's IQ-tests : An AI and Cognitive Modeling Approach}},
year = {2012}
}
@article{Griffiths2010,
abstract = {Cognitive science aims to reverse-engineer the mind, and many of the engineering challenges the mind faces involve induction. The probabilistic approach to modeling cognition begins by identifying ideal solutions to these inductive problems. Mental processes are then modeled using algorithms for approximating these solutions, and neural processes are viewed as mechanisms for implementing these algorithms, with the result being a top-down analysis of cognition starting with the function of cognitive processes. Typical connectionist models, by contrast, follow a bottom-up approach, beginning with a characterization of neural mechanisms and exploring what macro-level functional phenomena might emerge. We argue that the top-down approach yields greater flexibility for exploring the representations and inductive biases that underlie human cognition.},
author = {Griffiths, Thomas L and Chater, Nick and Kemp, Charles and Perfors, Amy and Tenenbaum, Joshua B},
doi = {10.1016/j.tics.2010.05.004},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Trends in cognitive sciences/2010/Griffiths et al. - 2010.pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Bias (Epidemiology),Brain,Brain: physiology,Cognition,Cognition: physiology,Humans,Models,Predictive Value of Tests,Probability,Psychological},
number = {8},
pages = {357--64},
pmid = {20576465},
publisher = {Elsevier Ltd},
title = {{Probabilistic models of cognition: exploring representations and inductive biases}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20576465},
volume = {14},
year = {2010}
}
@inproceedings{Tarasov2016,
author = {Тарасов, В. Б.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2016/Тарасов - 2016.pdf:pdf},
language = {russian},
pages = {94--114},
title = {{От спецификации когнитонов и инженерии интенций к обобщенной архитектуре деятельности агентов}},
year = {2016}
}
@article{Deco2015,
abstract = {The brain regulates information flow by balancing the segregation and integration of incoming stimuli to facilitate flexible cognition and behaviour. The topological features of brain networks - in particular, network communities and hubs - support this segregation and integration but do not provide information about how external inputs are processed dynamically (that is, over time). Experiments in which the consequences of selective inputs on brain activity are controlled and traced with great precision could provide such information. However, such strategies have thus far had limited success. By contrast, recent whole-brain computational modelling approaches have enabled us to start assessing the effect of input perturbations on brain dynamics in silico.},
author = {Deco, Gustavo and Tononi, Giulio and Boly, Melanie and Kringelbach, Morten L},
doi = {10.1038/nrn3963},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature reviews. Neuroscience/2015/Deco et al. - 2015.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$r1471-003X (Linking)},
issn = {1471-0048},
journal = {Nature reviews. Neuroscience},
number = {7},
pages = {430--439},
pmid = {26081790},
publisher = {Nature Publishing Group},
title = {{Rethinking segregation and integration: contributions of whole-brain modelling}},
url = {http://www.nature.com.sire.ub.edu/nrn/journal/v16/n7/full/nrn3963.html},
volume = {16},
year = {2015}
}
@article{Stankevich2006,
author = {Станкевич, Л. А. and Серебряков, С. В.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Труды СПИИРАН/2006/Станкевич, Серебряков - 2006.pdf:pdf},
journal = {Труды СПИИРАН},
language = {russian},
number = {3},
pages = {71--87},
title = {{Когнитивные системы и агенты}},
volume = {1},
year = {2006}
}
@book{Vityaev2006,
address = {Новосибирск},
author = {Витяев, Е. Е.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2006/Витяев - 2006.pdf:pdf},
language = {russian},
pages = {293},
publisher = {Новосиб. гос. ун-т},
title = {{Извлечение знаний из данных. Компьютерное познание. Модели когнитивных процессов: Монография}},
year = {2006}
}
@article{Chernavsky2012c,
abstract = {Рассматривается одна из возможных схем нейропроцессорной конструкции, способной решать задачи, традиционно относимые к мышлению и творчеству. Выделена подсистема, обрабатывающая образную информацию; ее важная составляющая — ―размытое множество‖, содержащее всю образную информацию, доступную системе. Выделена подсистема, способная решать логические задачи. Подсистема распознавания процесса и построения прогноза позволяет ввести понятие континуального времени. Показано, что решение творческих задач (при недостатке информации или противоречивости алгоритмов) в символьной подсистеме невозможно и требует обращения к размытому (образному) множеству.},
author = {Чернавский, Д. С. and Карп, В. П. and Никитин, А. П. and Рожило, Я. А. and Чернавская, О. Д.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Сложные системы/2012/Чернавский et al. - 2012.pdf:pdf},
journal = {Сложные системы},
keywords = {мышление,научное творчество,нейропроцессор,самоорганизация,символьная система},
language = {russian},
number = {4},
pages = {25--37},
title = {{Процесс мышления в контексте динамической теории информации. Часть III: один из вариантов конструкции нейропроцессоров для моделирования процесса мышления}},
volume = {3},
year = {2012}
}
