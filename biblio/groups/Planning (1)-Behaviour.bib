Automatically generated by Mendeley Desktop 1.17.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@incollection{Matari2008,
abstract = {Nature is filled with examples of autonomous creatures capable of dealing with the diversity, unpredictability, and rapidly changing conditions of the real world. Such creatures must make decisions and take actions based on incomplete perception, time constraints, limited knowledge about the world, cognition, reasoning and physical capabilities, in uncontrolled conditions and with very limited cues about the intent of others. Consequently, one way of evaluating intelligence is based on the creature ºs ability to make the most of what it has available to handle the complexities of the real world. The main objective of this chapter is to clarify behavior-based systems and their use in single- and multi-robot autonomous control problems and applications. The chapter is organized as follows. Section 38.1 overviews robot control, introducing behavior-based systems in relation to other established approaches to robot control. Section 38.2 follows by outlining the basic principles of behavior-based systems that make them distinct from other types of robot control architectures. The concept of basis behaviors, the means of modularizing behavior-based systems, is presented in Sect. 38.3. Section 38.4 describes how behaviors are used as building blocks for creating representations for use by behavior-based systems, enabling the robot to reason about the world and about itself in that world. Section 38.5 presents several different classes of learning methods for behavior-based systems, validated on single-robot and multi-robot systems. Section 38.6 provides an overview of various robotics problems and application domains that have successfully been addressed with behavior-based control. Finally, Sect. 38.7 concludes the chapter.},
author = {Matari, Maja J and Matari{\'{c}}, MajaJ and Michaud, Fran{\c{c}}ois},
booktitle = {Springer Handbook of Robotics},
doi = {10.1007/978-3-540-30301-5_39},
editor = {Siciliano, Bruno and Khatib, Oussama},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Springer Handbook of Robotics/2008/Matari, Matari{\'{c}}, Michaud - 2008.pdf:pdf},
isbn = {978-3-540-23957-4},
pages = {891--909},
publisher = {Springer Berlin Heidelberg},
title = {{Behavior-Based Systems}},
url = {http://dx.doi.org/10.1007/978-3-540-30301-5{\_}39{\%}5Cnhttp://link.springer.com/static-content/0.5480/pdf/226/chp:10.1007/978-3-540-30301-5{\_}39.pdf?token=1350549054544--122ebaddec4dac9fd256e387955adc88e8fcf10b7024158e19c7a3cbe9ae727bb1e85ec450386a0e24b038d38b1480},
year = {2008}
}
@article{Musliner2001,
author = {Musliner, D.J. and Goldman, R.P. and Pelican, M.J.S.},
doi = {10.1109/IROS.2001.976385},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings 2001 IEEERSJ International Conference on Intelligent Robots and Systems/2001/Musliner, Goldman, Pelican - 2001.pdf:pdf},
isbn = {0-7803-6612-3},
journal = {Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems},
pages = {2124--2130},
title = {{Planning with increasingly complex executive models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=976385},
volume = {4},
year = {2001}
}
@article{Rueckert2016,
abstract = {A recurrent spiking neural network is proposed that implements planning as probabilistic inference for finite and infinite horizon tasks. The architecture splits this problem into two parts: The stochastic transient firing of the network embodies the dynamics of the planning task. With appropriate injected input this dynamics is shaped to generate high-reward state trajectories. A general class of reward- modulated plasticity rules for these afferent synapses is presented. The updates optimize the likelihood of getting a reward through a variant of an Expectation Maximization algorithm and learning is guaranteed to convergence to a local maximum. We find that the network dynamics are qualitatively similar to transient firing patterns during planning and foraging in the hippocampus of awake behaving rats. The model extends classical attractor models and provides a testable prediction on identifying modulating contextual information. In a real robot arm reaching and obstacle avoidance task the ability to represent multiple task solutions is investigated. The neural planning method with its local update rules provides the basis for future neuromorphic hardware implementations with promising potentials like large data processing abilities and early initiation of strategies to avoid dangerous situations in robot co-worker scenarios.},
author = {Rueckert, Elmar and Kappel, David and Tanneberg, Daniel and Pecevski, Dejan and Peters, Jan},
doi = {10.1038/srep21142},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Scientific Reports/2016/Rueckert et al. - 2016.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
pages = {21142},
publisher = {Nature Publishing Group},
title = {{Recurrent Spiking Networks Solve Planning Tasks}},
url = {http://www.nature.com/articles/srep21142},
volume = {6},
year = {2016}
}
@article{DeCarolis2001a,
abstract = {The aim of our research is to build a Reflexive Agent, that is able to either manifest an emotion it is feeling or to hide it. If the Agent decides to manifest its emotion, it can establish what verbal or nonverbal signals to employ communication in its and how to combine and synchronize them. In the decision of whether to express an emotion in a given context, a number of factors are considered, such as the Agent's own personality and goals, the Interlocutor's characteristics and the context. In planning how to communicate an emotion, various factors are considered as well: the available modalities (face, gaze, voice etc); the cognitive ease in producing and processing the various the expressiveness of every signal in communicating specific meanings; and, finally, the appropriateness of signals to social situations.},
author = {{De Carolis}, Berardina and Pelachaud, Catherine and Poggi, Isabella and {De Rosis}, Fiorella},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/IJCAI International Joint Conference on Artificial Intelligence/2001/De Carolis et al. - 2001.pdf:pdf},
isbn = {1-55860-812-5, 978-1-558-60812-2},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {1059--1064},
title = {{Behavior planning for a reflexive agent}},
year = {2001}
}
@article{Kaelbling2013,
abstract = {We describe an integrated strategy for planning, perception, state estimation and action in complex mobile manipulation domains based on planning in the belief space of probability distributions over states using hierarchical goal regression (pre-image back-chaining). We develop a vocabulary of logical expressions that describe sets of belief states, which are goals and subgoals in the planning process. We show that a relatively small set of symbolic operators can give rise to task-oriented perception in support of the manipulation goals. An implementation of this method is demonstrated in simulation and on a real PR2 robot, showing robust, flexible solution of mobile manipulation problems with multiple objects and substantial uncertainty.},
author = {Kaelbling, Leslie Pack and Lozano-P{\'{e}}rez, Tomas},
doi = {10.1177/0278364913484072},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/The International Journal of Robotics Research/2013/Kaelbling, Lozano-P{\'{e}}rez - 2013.pdf:pdf},
isbn = {0278-3649},
issn = {0278-3649},
journal = {The International Journal of Robotics Research},
number = {9-10},
pages = {1194--1227},
title = {{Integrated task and motion planning in belief space}},
url = {http://ijr.sagepub.com/content/32/9-10/1194.abstract?etoc},
volume = {32},
year = {2013}
}
@inproceedings{Best2003,
abstract = {Agents must be able to effectively employ teamwork, coordination, navigation, and planning to succeed in multi-agents virtual environments. These high-level abilities depend on reliable navigation and perception of the environment. We present cognitively plausible agents used for training in virtual simulations of Military Operations on Urban Terrain (MOUT). These cognitive agents are developed using the ACT-R cognitive architecture, an architecture used to model human performance in a wide variety of psychological experiments. These agents use their real-time perceptions to shape their interactions with other agents and human players on both the friendly and opposing sides of the conflict. Planning is accomplished on-line by combining schematic plans with the current context, resulting in flexible and appropriate action. Roles within plans are negotiated between agents on an as-needed basis while plans are selected based on the availability of other agents. 1},
author = {Best, B J and Lebiere, Christian},
booktitle = {Proceedings of the 2003 IJCAI Workshop on Cognitive Modeling of Agents and Multi-Agent Interactions},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the 2003 IJCAI Workshop on Cognitive Modeling of Agents and Multi-Agent Interactions/2003/Best, Lebiere - 2003.pdf:pdf},
pages = {64--72},
title = {{Teamwork, Communication, and Planning in ACT-R Agents Engaging in Urban Combat in Virtual Environments}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.5632{\&}rep=rep1{\&}type=pdf},
year = {2003}
}
@article{Billing2015,
abstract = {A technique for simultaneous planning and action based on dynamic field theory is presented. The model builds on previous work on representation of sequential behavior as attractors in dynamic neural fields. Here, we demonstrate how chains of competing attractors can be used to represent dynamic plans towards a goal state. The present work can be seen as an addition to a growing body of work that demonstrates the role of dynamic field theory as a bridge between low-level reactive approaches and high-level symbol processing mechanisms. The architecture is evaluated on a set of planning problems using a simulated e-puck robot, including analysis of the system's behavior in response to noise and temporary blockages of the planned route. The system makes no explicit distinction between planning and execution phases, allowing continuous adaptation of the planned path. The proposed architecture exploits the dynamic field theory property of stability in relation to noise and changes in the environment. The neural dynamics are also exploited such that stay-or-switch action selection emerges where blockage of a planned path occurs; stay until the transient blockage is removed versus switch to an alternative route to the goal.},
author = {Billing, E. and Lowe, R. and Sandamirskaya, Y.},
doi = {10.1177/1059712315601188},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Adaptive Behavior/2015/Billing, Lowe, Sandamirskaya - 2015.pdf:pdf},
issn = {1059-7123},
journal = {Adaptive Behavior},
keywords = {dynamic field theory,goal directed behavior,plan,simultaneous planning and action},
mendeley-tags = {plan},
number = {5},
pages = {243--264},
title = {{Simultaneous planning and action: neural-dynamic sequencing of elementary behaviors in robot navigation}},
url = {http://adb.sagepub.com/cgi/doi/10.1177/1059712315601188},
volume = {23},
year = {2015}
}
@book{Tampra2012,
address = {Atibaia},
editor = {Cirillo, Marcello and Gerkey, Brian and Pecora, Federico and Stilman, Mike},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2012/Unknown - 2012(2).pdf:pdf},
keywords = {plan},
mendeley-tags = {plan},
pages = {61},
title = {{TAMPRA'12: Proceedings of the 2012 ICAPS Workshop on Combining Task and Motion Planning for Real-World Applications}},
year = {2012}
}
@article{2009a,
author = {–ö–∞—Ä–ø–æ–≤, –í. –≠. and –í–∞–ª—å—Ü–µ–≤, –í. –ë.},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –∏ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏–π/2009/–ö–∞—Ä–ø–æ–≤, –í–∞–ª—å—Ü–µ–≤ - 2009.pdf:pdf},
journal = {–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –∏ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏–π},
keywords = {plan},
language = {russian},
mendeley-tags = {plan},
number = {2},
pages = {58--69},
title = {{–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–≤–µ–¥–µ–Ω–∏—è —Ä–æ–±–æ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ—Ç–∏ ``–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö'' –Ω–µ–π—Ä–æ–Ω–æ–≤}},
year = {2009}
}
@article{DeGiacomo2015,
abstract = {This work proposes a novel high-level paradigm, agent planning programs, for modeling agents behavior, which suitably mixes automated planning with agent-oriented programming. Agent planning programs are finite-state programs, possibly containing loops, whose atomic instructions consist of a guard, a maintenance goal, and an achievement goal, which act as precondition-invariance-postcondition assertions in program specification. Such programs are to be executed in possibly nondeterministic planning domains and their execution requires generating plans that meet the goals specified in the atomic instructions, while respecting the program control flow. In this paper, we define the problem of automatically synthesizing the required plans to execute an agent planning program, propose a solution technique based on model checking of two-player game structures, and use it to characterize the worst-case computational complexity of the problem as EXPTIME-complete. Then, we consider the case of deterministic domains and propose a different technique to solve agent planning programs, which is based on iteratively solving classical planning problems and on exploiting goal preferences and plan adaptation methods. Finally, we study the effectiveness of this approach for deterministic domains through an experimental analysis on well-known planning domains.},
author = {{De Giacomo}, Giuseppe and Gerevini, Alfonso Emilio and Patrizi, Fabio and Saetti, Alessandro and Sardina, Sebastian},
doi = {10.1016/j.artint.2015.10.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Artificial Intelligence/2015/De Giacomo et al. - 2015.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {agent-oriented programming,plan},
mendeley-tags = {plan},
pages = {64--106},
publisher = {Elsevier B.V.},
title = {{Agent planning programs}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370215001563},
volume = {231},
year = {2015}
}
@inproceedings{Kaelbling2011,
author = {Kaelbling, Leslie Pack},
booktitle = {Proceedings og 2011 IEEE International Conference on Robotics and Automation},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings og 2011 IEEE International Conference on Robotics and Automation/2011/Kaelbling - 2011.pdf:pdf},
isbn = {9781612843858},
keywords = {plan},
mendeley-tags = {plan},
pages = {1470--1477},
publisher = {IEEE},
title = {{Hierarchical task and motion planning in the now}},
year = {2011}
}
@inproceedings{Panteleev2012,
address = {–ë–µ–ª–≥–æ—Ä–æ–¥},
author = {–ü–∞–Ω—Ç–µ–ª–µ–µ–≤, –ú. –ì.},
booktitle = {–¢—Ä–∏–Ω–∞–¥—Ü–∞—Ç–∞—è –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è –ø–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º—É –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É —Å –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–º —É—á–∞—Å—Ç–∏–µ–º –ö–ò–ò-2012 (16-20 –æ–∫—Ç—è–±—Ä—è 2012 –≥., –≥. –ë–µ–ª–≥–æ—Ä–æ–¥, –†–æ—Å—Å–∏—è): –¢—Ä—É–¥—ã –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/–¢—Ä–∏–Ω–∞–¥—Ü–∞—Ç–∞—è –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è –ø–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º—É –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É —Å –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–º —É—á–∞—Å—Ç–∏–µ–º –ö–ò–ò-2012 (16. –ë–µ–ª–≥–æ—Ä–æ–¥, –†–æ—Å—Å–∏—è) –¢—Ä—É–¥—ã –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏/2012/–ü–∞–Ω—Ç–µ–ª–µ–µ–≤ - 2012.pdf:pdf},
keywords = {plan},
language = {russian},
mendeley-tags = {plan},
pages = {25--33},
publisher = {–ò–∑–¥-–≤–æ –ë–ì–¢–£},
title = {{–ö–æ–Ω—Ü–µ–ø—Ü–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏ –æ–ø–µ—Ä–µ–∂–∞—é—â–µ–≥–æ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è}},
volume = {3},
year = {2012}
}
@article{Hexmoor2006,
abstract = {Agent teaming and autonomy are foundational themes in multi-agent systems. Agents may work as singletons or they may work in environments where other agents exist. In multi-agent systems, agents may form teams by sharing common goals with other agents. Cooperation is essential for any collaborative, group activity. Beyond coordination and judicious role assignment, cooperation enables members of a team to be aware and account for collection of their goals as well as the performance of agents on individual goals. This paper presents a general model of cooperation and illustrates how it may enhance group performance. In this paper, we present results of an application of the concept of cooperation in a simulated swarm of reconnaissance urban UAVs that are tracking vehicles in an urban environment.},
author = {Hexmoor, Henry and Eluru, Swetha and Sabaa, Hadi},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Informatica (Ljubljana)/2006/Hexmoor, Eluru, Sabaa - 2006.pdf:pdf},
issn = {03505596},
journal = {Informatica (Ljubljana)},
keywords = {Agents,Benevolence,Collaboration,Help,UAV},
number = {2},
pages = {183--192},
title = {{Plan sharing: Showcasing coordinated UAV formation flight}},
volume = {30},
year = {2006}
}
@article{Dehaene1997,
abstract = {Planning a goal-directed sequence of behavior is a higher function of the human brain that relies on the integrity of prefrontal cortical areas. In the Tower of London test, a puzzle in which beads sliding on pegs must be moved to match a designated goal configuration, patients with lesioned prefrontal cortex show deficits in planning a goal-directed sequence of moves. We propose a neuronal network model of sequence planning that passes this test and, when lesioned, fails in a way that mimics prefrontal patients' behavior. Our model comprises a descending planning system with hierarchically organized plan, operation, and gesture levels, and an ascending evaluative system that analyzes the problem and computes internal reward signals that index the correct/erroneous status of the plan. Multiple parallel pathways connecting the evaluative and planning systems amend the plan and adapt it to the current problem. The model illustrates how specialized hierarchically organized neuronal assemblies may collectively emulate central executive or supervisory functions of the human brain.},
author = {Dehaene, S and Changeux, J P},
doi = {10.1073/pnas.94.24.13293},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences of the United States of America/1997/Dehaene, Changeux - 1997.pdf:pdf},
isbn = {0027-8424 (Print)$\backslash$n0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {24},
pages = {13293--13298},
pmid = {9371839},
title = {{A hierarchical neuronal network for planning behavior}},
volume = {94},
year = {1997}
}
@inproceedings{Hayes2015,
abstract = {In this work, we present an algorithm for improv- ing collaborator performance on sequential manipulation tasks. Our agent-decoupled, optimization-based, task and motion planning approach merges considerations derived from both symbolic and geometric planning domains. This results in the generation of supportive behaviors enabling a teammate to reduce cognitive and kinematic burdens during task completion. We describe our algorithm alongside representative use cases, with an evaluation based on solving complex circuit building problems. We conclude with a discussion of applications and extensions to human-robot teaming scenarios.},
author = {Hayes, Bradley and Scassellati, Brian},
booktitle = {International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2015.7354288},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/International Conference on Intelligent Robots and Systems/2015/Hayes, Scassellati - 2015.pdf:pdf},
isbn = {9781479999934},
issn = {21530866},
pages = {6374--6380},
title = {{Effective Robot Teammate Behaviors for Supporting Sequential Manipulation Tasks}},
url = {http://www.bradhayes.info/papers/iros15.pdf},
year = {2015}
}
@inproceedings{Karlsson2012,
abstract = {The ability to perform both causal (means-end) and geometric reasoning is important in order to achieve au- tonomy for advanced robotic systems. In this paper, we describe work in progress on planning for a humanoid two-arm robotic system where task and path planning capabilities have been integrated into a coherent planning framework. We address a number of challenges of integrating combined task and path planning with the complete robotic system, in particular concerning perception and execution. Geometric backtracking is considered: this is the process of revisiting geometric choices (grasps, positions etc.) in previous actions in order to be able to satisfy the geometric preconditions of the action presently under consideration of the planner. We argue that geometric backtracking is required for resolution completeness. Our approach is demon- strated on a real robotic platform, Justin at DLR, and in a simulation of the same robot. In the latter, we consider the consequences of geometric backtracking.},
author = {Karlsson, Lars and Bidot, Julien and Lagriffoul, Fabien and Saffiotti, Alessandro and Hillenbrand, Ulrich and Schmidt, Florian},
booktitle = {TAMPRA 2012: Proceedings of the Workshop on Combining Task and Motion Planning for Real-World Applications},
editor = {Cirillo, Marcello and Gerkey, Brian and Pecora, Federico and Stilman, Mike},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/TAMPRA 2012 Proceedings of the Workshop on Combining Task and Motion Planning for Real-World Applications/2012/Karlsson et al. - 2012.pdf:pdf},
keywords = {plan},
mendeley-tags = {plan},
pages = {13--20},
title = {{Combining Task and Path Planning for a Humanoid Two-arm Robotic System}},
year = {2012}
}
