Automatically generated by Mendeley Desktop 1.17.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Keramati2011a,
abstract = {Reinforcement learning models address animal's behavioral adaptation to its changing “external” environment, and are based on the assumption that Pavlo- vian, habitual and goal-directed responses seek to maximize reward acquisition. Negative-feedback models of homeostatic regulation, on the other hand, are con- cerned with behavioral adaptation in response to the “internal” state of the animal, and assume that animals' behavioral objective is to minimize deviations of some key physiological variables from their hypothetical setpoints. Building upon the drive-reduction theory of reward, we propose a new analytical framework that in- tegrates learning and regulatory systems, such that the two seemingly unrelated objectives of reward maximization and physiological-stability prove to be identi- cal. The proposed theory shows behavioral adaptation to both internal and external states in a disciplined way. We further show that the proposed framework allows for a unified explanation of some behavioral pattern like motivational sensitivity of different associative learning mechanism, anticipatory responses, interaction among competing motivational systems, and risk aversion.},
author = {Keramati, Mehdi and Gutkin, Boris},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nips/2011/Keramati, Gutkin - 2011.pdf:pdf},
isbn = {9781618395993},
journal = {Nips},
pages = {82--90},
title = {{A Reinforcement Learning theory for homeostatic regulation}},
year = {2011}
}
