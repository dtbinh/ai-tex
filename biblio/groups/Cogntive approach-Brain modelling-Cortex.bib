Automatically generated by Mendeley Desktop 1.16.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{George2009,
abstract = {The theoretical setting of hierarchical Bayesian inference is gaining acceptance as a framework for understanding cortical computation. In this paper, we describe how Bayesian belief propagation in a spatio-temporal hierarchical model, called Hierarchical Temporal Memory (HTM), can lead to a mathematical model for cortical circuits. An HTM node is abstracted using a coincidence detector and a mixture of Markov chains. Bayesian belief propagation equations for such an HTM node define a set of functional constraints for a neuronal implementation. Anatomical data provide a contrasting set of organizational constraints. The combination of these two constraints suggests a theoretically derived interpretation for many anatomical and physiological features and predicts several others. We describe the pattern recognition capabilities of HTM networks and demonstrate the application of the derived circuits for modeling the subjective contour effect. We also discuss how the theory and the circuit can be extended to explain cortical features that are not explained by the current model and describe testable predictions that can be derived from the model.},
author = {George, Dileep and Hawkins, Jeff},
doi = {10.1371/journal.pcbi.1000532},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLoS computational biology/2009/George, Hawkins - 2009.pdf:pdf},
issn = {1553-7358},
journal = {PLoS computational biology},
keywords = {Artificial Intelligence,Automated,Automated: methods,Bayes Theorem,Cerebral Cortex,Cerebral Cortex: physiology,Feedback,Markov Chains,Memory,Memory: physiology,Models,Neurological,Pattern Recognition,Pyramidal Cells,Pyramidal Cells: physiology,htm},
mendeley-tags = {htm},
number = {10},
pages = {e1000532},
pmid = {19816557},
title = {{Towards a mathematical theory of cortical micro-circuits}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2749218{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {5},
year = {2009}
}
@article{Pfister2014,
author = {Bauer, Roman and Zubler, Frederic and Pfister, Sabina and Hauri, Andreas and Pfeiffer, Michael and Muir, Dylan R and Douglas, Rodney J},
doi = {10.1371/journal.pcbi.1003994},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/PLOS Computational Biology/2014/Bauer et al. - 2014.pdf:pdf},
journal = {PLOS Computational Biology},
number = {12},
pages = {e1003994},
title = {{Developmental Self-Construction and -Configuration of Functional Neocortical Neuronal Networks}},
volume = {10},
year = {2014}
}
@article{Izhikevich2008,
abstract = {The understanding of the structural and dynamic complexity of mammalian brains is greatly facilitated by computer simulations. We present here a detailed large-scale thalamocortical model based on experimental measures in several mammalian species. The model spans three anatomical scales. (i) It is based on global (white-matter) thalamocortical anatomy obtained by means of diffusion tensor imaging (DTI) of a human brain. (ii) It includes multiple thalamic nuclei and six-layered cortical microcircuitry based on in vitro labeling and three-dimensional reconstruction of single neurons of cat visual cortex. (iii) It has 22 basic types of neurons with appropriate laminar distribution of their branching dendritic trees. The model simulates one million multicompartmental spiking neurons calibrated to reproduce known types of responses recorded in vitro in rats. It has almost half a billion synapses with appropriate receptor kinetics, short-term plasticity, and long-term dendritic spike-timing-dependent synaptic plasticity (dendritic STDP). The model exhibits behavioral regimes of normal brain activity that were not explicitly built-in but emerged spontaneously as the result of interactions among anatomical and dynamic processes. We describe spontaneous activity, sensitivity to changes in individual neurons, emergence of waves and rhythms, and functional connectivity on different scales.},
author = {Izhikevich, Eugene M. and Edelman, Gerald M.},
doi = {10.1073/pnas.0712231105},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences of the United States of America/2008/Izhikevich, Edelman - 2008.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Action Potentials,Animals,Biological,Brain,Brain: anatomy {\&} histology,Cats,Cerebral Cortex,Cerebral Cortex: anatomy {\&} histology,Computer Simulation,Humans,Mammals,Models,Neurological,Neurons,Synapses,Thalamic Nuclei,Visual Cortex,Visual Cortex: anatomy {\&} histology},
number = {9},
pages = {3593--8},
pmid = {18292226},
title = {{Large-scale model of mammalian thalamocortical systems}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2265160{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {105},
year = {2008}
}
@phdthesis{George2008,
author = {George, Dileep},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2008/George - 2008.pdf:pdf},
keywords = {htm},
mendeley-tags = {htm},
number = {June},
pages = {191},
school = {Stanford University},
title = {{How the Brain Might Work: a Hierarchical and Temporal Model for Learning and Recognition}},
year = {2008}
}
@article{Lorincz2015b,
abstract = {Ever since the discovery of columnar structures, their function remained enigmatic. As a potential explanation for this puzzling function, we introduce the 'Columnar Machine'. We join two neural network types, Structured Sparse Coding (SSC) of generative nature exploiting sparse groups of neurons and Feed-Forward Networks (FFNs) into one architecture. Memories supporting recognition can be quickly loaded into SSC via supervision or can be learned by SSC in a self-organized manner. However, SSC evaluation is slow. We train FFNs for predicting the sparse groups and then the representation is computed by fast undercomplete methods. This two step procedure enables fast estimation of the overcomplete group sparse representations. The suggested architecture works fast and it is biologically plausible. Beyond the function of the minicolumnar structure it may shed light onto the role of fast feed-forward inhibitory thalamocortical channels and cortico-cortical feed-back connections. We demonstrate the method for natural image sequences where we exploit temporal structure and for a cognitive task where we explain the meaning of unknown words from their contexts.},
author = {Lorincz, Andras and Milacski, Zoltan and Pinter, Bal{\'{a}}zs and Vero, Anita L.},
doi = {10.1016/j.bica.2015.10.003},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2016/Lorincz et al. - 2016.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {Feed-forward inhibition,Minicolumns,Sparsity,Structured representation},
pages = {19--33},
title = {{Columnar Machine: Fast estimation of structured sparse codes}},
volume = {15},
year = {2016}
}
@article{VandenHeuvel2013,
abstract = {The human brain shows several characteristics of an efficient communication network architecture, including short communication paths and the existence of modules interlinked by a small set of highly connected regions. Studies of structural networks comprising macroscopic white matter projections have shown that these putative hubs are densely interconnected, giving rise to a spatially distributed and topologically central collective called the “rich club.” In parallel, studies of intrinsic brain activity have consistently revealed distinct functional communities or resting-state networks (RSNs), indicative of specialized processing and segregation of neuronal information. However, the pattern of structural connectivity interconnecting these functional RSNs and how such inter-RSN structural connections might bring about functional integration between RSNs remain largely unknown. Combining high-resolution diffusion weighted imaging with resting-state fMRI, we present novel evidence suggesting that the rich club structure plays a central role in cross-linking macroscopic RSNs of the human brain. Rich club hub nodes were present in all functional networks, accounted for a large proportion of “connector nodes,” and were found to coincide with regions in which multiple networks overlap. In addition, a large proportion of all inter-RSN connections were found to involve rich club nodes, and these connections participated in a disproportionate number of communication paths linking nodes in different RSNs. Our findings suggest that the brain's rich club serves as a macroscopic anatomical substrate to cross-link functional networks and thus plays an important role in the integration of information between segregated functional domains of the human cortex.},
author = {van den Heuvel, M. P. and Sporns, O.},
doi = {10.1523/JNEUROSCI.2128-13.2013},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Journal of Neuroscience/2013/van den Heuvel, Sporns - 2013.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {36},
pages = {14489--14500},
title = {{An Anatomical Substrate for Integration among Functional Networks in Human Cortex}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2128-13.2013},
volume = {33},
year = {2013}
}
@unpublished{Project2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1505.02142v1},
author = {Billaudelle, Sebastian and Ahmad, Subutai},
eprint = {arXiv:1505.02142v1},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2015/Billaudelle, Ahmad - 2015.pdf:pdf},
keywords = {htm},
mendeley-tags = {htm},
pages = {1--10},
title = {{Porting HTM Models to the Heidelberg Neuromorphic Computing Platform}},
year = {2015}
}
@inproceedings{Rohrbein2007,
author = {Rohrbein, Florian and Eggert, Julian and Korner, Edgar},
booktitle = {ICCM-2007-Eighth International Conference on Cognitivy Modeling},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/ICCM-2007-Eighth International Conference on Cognitivy Modeling/2007/Rohrbein, Eggert, Korner - 2007.pdf:pdf},
keywords = {biologically,columnar-like nodes and do,cortical column,detailed modeling of the,knowledge representation,not target at a,relational structures,single cortical column,the},
pages = {307--312},
title = {{Prototypical Relations for Cortex-Inspired Semantic Representations}},
year = {2007}
}
@article{Chalita2016,
author = {Chalita, Mario Andr{\'{e}}s and Lis, Diego and Caverzasi, Agust{\'{i}}n},
doi = {10.1016/j.bica.2016.03.001},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Biologically Inspired Cognitive Architectures/2016/Chalita, Lis, Caverzasi - 2016.pdf:pdf},
issn = {2212683X},
journal = {Biologically Inspired Cognitive Architectures},
keywords = {reinforcement learning},
pages = {45--63},
title = {{Reinforcement learning in a bio-connectionist model based in the thalamo-cortical neural circuit}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S2212683X16300159},
year = {2016}
}
@article{Litvak2009,
abstract = {In this letter, we develop and simulate a large-scale network of spiking neurons that approximates the inference computations performed by graphical models. Unlike previous related schemes, which used sum and product operations in either the log or linear domains, the current model uses an inference scheme based on the sum and maximization operations in the log domain. Simulations show that using these operations, a large-scale circuit, which combines populations of spiking neurons as basic building blocks, is capable of finding close approximations to the full mathematical computations performed by graphical models within a few hundred milliseconds. The circuit is general in the sense that it can be wired for any graph structure, it supports multistate variables, and it uses standard leaky integrate-and-fire neuronal units. Following previous work, which proposed relations between graphical models and the large-scale cortical anatomy, we focus on the cortical microcircuitry and propose how anatomical and physiological aspects of the local circuitry may map onto elements of the graphical model implementation. We discuss in particular the roles of three major types of inhibitory neurons (small fast-spiking basket cells, large layer 2/3 basket cells, and double-bouquet neurons), subpopulations of strongly interconnected neurons with their unique connectivity patterns in different cortical layers, and the possible role of minicolumns in the realization of the population-based maximum operation.},
author = {Litvak, Shai and Ullman, Shimon},
doi = {10.1162/neco.2009.05-08-783},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural computation/2009/Litvak, Ullman - 2009.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
number = {11},
pages = {3010--3056},
pmid = {19686065},
title = {{Cortical circuitry implementing graphical models}},
volume = {21},
year = {2009}
}
@article{Alexander2011,
abstract = {The medial prefrontal cortex (mPFC) and especially anterior cingulate cortex is central to higher cognitive function and many clinical disorders, yet its basic function remains in dispute. Various competing theories of mPFC have treated effects of errors, conflict, error likelihood, volatility and reward, using findings from neuroimaging and neurophysiology in humans and monkeys. No single theory has been able to reconcile and account for the variety of findings. Here we show that a simple model based on standard learning rules can simulate and unify an unprecedented range of known effects in mPFC. The model reinterprets many known effects and suggests a new view of mPFC, as a region concerned with learning and predicting the likely outcomes of actions, whether good or bad. Cognitive control at the neural level is then seen as a result of evaluating the probable and actual outcomes of one's actions.},
author = {Alexander, William H and Brown, Joshua W},
doi = {10.1038/nn.2921},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature neuroscience/2011/Alexander, Brown - 2011.pdf:pdf},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Animals,Brain Mapping,Choice Behavior,Choice Behavior: physiology,Cognition,Cognition: physiology,Computer Simulation,Computer-Assisted,Conflict (Psychology),Humans,Image Processing,Magnetic Resonance Imaging,Models,Movement,Movement: physiology,Neurological,Oxygen,Oxygen: blood,Photic Stimulation,Predictive Value of Tests,Prefrontal Cortex,Prefrontal Cortex: blood supply,Prefrontal Cortex: physiology,Reward,Time Factors,Visual Perception},
number = {10},
pages = {1338--44},
pmid = {21926982},
publisher = {Nature Publishing Group},
title = {{Medial prefrontal cortex as an action-outcome predictor}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3183374{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {14},
year = {2011}
}
@techreport{Hawkins2011,
author = {Hawkins, Jeff and Ahmad, Subutai and Dubinsky, Donna},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Hawkins, Ahmad, Dubinsky - 2011.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Hawkins, Ahmad, Dubinsky - 2011(2).pdf:pdf},
institution = {Numenta},
keywords = {htm},
mendeley-tags = {htm},
pages = {1--68},
title = {{Hiearachical Temporal Memory including HTM Cortical Learning Algorithms}},
year = {2011}
}
@book{Mountcastle1998,
address = {Cambridge},
author = {Mountcastle, V. B.},
pages = {512},
publisher = {Harvard University Press},
title = {{Perceptual Neuroscience. The Cerebral Cortex}},
year = {1998}
}
@techreport{Cortical2014,
author = {Hawkins, Jeff and Ahmad, Subutai and Byrne, Fergal and Surpur, Chetan},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2014/Hawkins et al. - 2014.pdf:pdf},
institution = {Numenta},
keywords = {htm},
mendeley-tags = {htm},
pages = {62},
title = {{Hierarchical Temporal Memory including HTM Cortical Learning Algorithms}},
url = {numenta.org},
year = {2014}
}
@article{Cadieu2014,
abstract = {The primate visual system achieves remarkable visual object recognition performance even in brief presentations and under changes to object exemplar, geometric transformations, and background variation (a.k.a. core visual object recognition). This remarkable performance is mediated by the representation formed in inferior temporal (IT) cortex. In parallel, recent advances in machine learning have led to ever higher performing models of object recognition using artificial deep neural networks (DNNs). It remains unclear, however, whether the representational performance of DNNs rivals that of the brain. To accurately produce such a comparison, a major difficulty has been a unifying metric that accounts for experimental limitations such as the amount of noise, the number of neural recording sites, and the number trials, and computational limitations such as the complexity of the decoding classifier and the number of classifier training examples. In this work we perform a direct comparison that corrects for these experimental limitations and computational considerations. As part of our methodology, we propose an extension of "kernel analysis" that measures the generalization accuracy as a function of representational complexity. Our evaluations show that, unlike previous bio-inspired models, the latest DNNs rival the representational performance of IT cortex on this visual object recognition task. Furthermore, we show that models that perform well on measures of representational performance also perform well on measures of representational similarity to IT and on measures of predicting individual IT multi-unit responses. Whether these DNNs rely on computational mechanisms similar to the primate visual system is yet to be determined, but, unlike all previous bio-inspired models, that possibility cannot be ruled out merely on representational performance grounds.},
archivePrefix = {arXiv},
arxivId = {1406.3284},
author = {Cadieu, Charles F. and Hong, Ha and Yamins, Daniel L. K. and Pinto, Nicolas and Ardila, Diego and Solomon, Ethan a. and Majaj, Najib J. and DiCarlo, James J.},
doi = {10.1371/journal.pcbi.1003963},
eprint = {1406.3284},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Arxiv/2014/Cadieu et al. - 2014.pdf:pdf},
issn = {15537358},
journal = {Arxiv},
number = {12},
pages = {35},
pmid = {25521294},
title = {{Deep Neural Networks Rival the Representation of Primate IT Cortex for Core Visual Object Recognition}},
url = {http://arxiv.org/abs/1406.3284},
volume = {10},
year = {2014}
}
@article{Gallese1996,
author = {Gallese, Vittorio and Fadiga, Luciano and Fogassi, Leonardo and Rizzolatti, Giacomo},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Brain/1996/Gallese et al. - 1996.pdf:pdf},
journal = {Brain},
keywords = {action encoding,macaque monkey,premotor cortex,visual responses},
number = {5},
pages = {593--609},
title = {{Action recognition in the premotor cortex}},
volume = {119},
year = {1996}
}
@inproceedings{Dura-Bernal2011,
author = {Dura-Bernal, Salvador and Wennekers, Thomas and Denham, Susan L.},
booktitle = {45th Annual Conference on Information Sciences and Systems},
doi = {10.1109/CISS.2011.5766096},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/45th Annual Conference on Information Sciences and Systems/2011/Dura-Bernal, Wennekers, Denham - 2011.pdf:pdf},
isbn = {978-1-4244-9846-8},
keywords = {bayesian belief propagation,hierarchical percep-},
pages = {1--6},
publisher = {IEEE},
title = {{Modelling object perception in cortex: Hierarchical Bayesian networks and belief propagation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5766096},
year = {2011}
}
@phdthesis{Price2011a,
author = {Price, Ryan William},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Price - 2011.pdf:pdf;:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Unknown/2011/Price - 2011(2).pdf:pdf},
keywords = {htm},
mendeley-tags = {htm},
pages = {115},
school = {Portland State University},
title = {{Hierarchical Temporal Memory Cortical Learning Algorithm for Pattern Recognition on Multi-core Architectures}},
year = {2011}
}
@article{Rinkus2010,
abstract = {No generic function for the minicolumn - i.e., one that would apply equally well to all cortical areas and species - has yet been proposed. I propose that the minicolumn does have a generic functionality, which only becomes clear when seen in the context of the function of the higher-level, subsuming unit, the macrocolumn. I propose that: (a) a macrocolumn's function is to store sparse distributed representations of its inputs and to be a recognizer of those inputs; and (b) the generic function of the minicolumn is to enforce macrocolumnar code sparseness. The minicolumn, defined here as a physically localized pool of approximately 20 L2/3 pyramidals, does this by acting as a winner-take-all (WTA) competitive module, implying that macrocolumnar codes consist of approximately 70 active L2/3 cells, assuming approximately 70 minicolumns per macrocolumn. I describe an algorithm for activating these codes during both learning and retrievals, which causes more similar inputs to map to more highly intersecting codes, a property which yields ultra-fast (immediate, first-shot) storage and retrieval. The algorithm achieves this by adding an amount of randomness (noise) into the code selection process, which is inversely proportional to an input's familiarity. I propose a possible mapping of the algorithm onto cortical circuitry, and adduce evidence for a neuromodulatory implementation of this familiarity-contingent noise mechanism. The model is distinguished from other recent columnar cortical circuit models in proposing a generic minicolumnar function in which a group of cells within the minicolumn, the L2/3 pyramidals, compete (WTA) to be part of the sparse distributed macrocolumnar code.},
author = {Rinkus, Gerard J},
doi = {10.3389/fnana.2010.00017},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Frontiers in neuroanatomy/2010/Rinkus - 2010.pdf:pdf},
issn = {1662-5129},
journal = {Frontiers in neuroanatomy},
keywords = {NeuroModels,learning,macrocolumn,memory,minicolumn,novelty detection,population coding,sparse distributed representations,winner-take-all},
mendeley-tags = {NeuroModels},
number = {June},
pages = {17},
pmid = {20577587},
title = {{A cortical sparse distributed coding model linking mini- and macrocolumn-scale functionality}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2889687{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {4},
year = {2010}
}
@article{George2005,
abstract = {We describe a hierarchical model of invariant visual pattern recognition in the visual cortex. In this model, the knowledge of how patterns change when objects move is learned and encapsulated in terms of high probability sequences at each level of the hierarchy. Configuration of object parts is captured by the patterns of coincident high probability sequences. This knowledge is then encoded in a highly efficient Bayesian Network structure.The learning algorithm uses a temporal stability criterion to discover object concepts and movement patterns. We show that the architecture and algorithms are biologically plausible. The large scale architecture of the system matches the large scale organization of the cortex and the micro-circuits derived from the local computations match the anatomical data on cortical circuits. The system exhibits invariance across a wide variety of transformations and is robust in the presence of noise. Moreover, the model also offers alternative explanations for various known cortical phenomena.},
author = {George, Dileep and Hawkins, Jeff},
doi = {10.1109/IJCNN.2005.1556155},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN)/2005/George, Hawkins - 2005.pdf:pdf},
isbn = {0780390482},
journal = {Proceedings of the IEEE International Joint Conference on Neural Networks (IJCNN)},
keywords = {Bayes methods,Bayesian model,Bayesian network structure,anatomical data,belief networks,cortical circuit,cortical phenomena,htm,invariant visual pattern recognition,large scale architecture,learning (artificial intelligence),learning algorithm,micro-circuits,movement pattern,neural nets,object concept,pattern recognition,probability,probability sequence,temporal stability,visual cortex},
mendeley-tags = {htm},
pages = {1812--1817},
pmid = {1556155},
title = {{A hierarchical Bayesian model of invariant pattern recognition in the visual cortex}},
volume = {3},
year = {2005}
}
@inproceedings{Ananthanarayanan2009,
author = {Ananthanarayanan, Rajagopal and Esser, Steven K and Simon, Horst D and Modha, Dharmendra S},
booktitle = {Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis/2009/Ananthanarayanan et al. - 2009.pdf:pdf},
number = {c},
pages = {1--12},
title = {{The Cat is Out of the Bag : Cortical Simulations with 10 9 Neurons , 10 13 Synapses}},
year = {2009}
}
@article{Riesenhuber1999,
author = {Riesenhuber, Maximilian and Poggio, Tomaso},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Nature Neuroscience/1999/Riesenhuber, Poggio - 1999.pdf:pdf},
journal = {Nature Neuroscience},
number = {11},
pages = {1019--1025},
title = {{Hierarchical models of object recognition in cortex}},
volume = {2},
year = {1999}
}
