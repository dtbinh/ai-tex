Automatically generated by Mendeley Desktop 1.17.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Bengio1996,
abstract = {Hidden Markov Models (HMMs) are statistical models of sequential data that have been used successfully in many machine learning applications, especially for speech recognition. We first summarize the basics of HMMs, and then review several recent related learning algorithms and extensions of HMMs, including hybrids of HMMs with artificial neural networks, Input-Output HMMs (which are conditional HMMs using neural networks to compute probabilities), weighted transducers, variable-length Markov models and Markov switching state-space models. Finally, we discuss some of the challenges of future research in this area. 1 Introduction Hidden Markov Models (HMMs) are statistical models of sequential data that have been used successfully in many applications in artificial intelligence, pattern recognition, speech recognition, and modeling of biological sequences. The focus of this paper is on learning algorithms which have been developed for HMMs and many related models, such as hybrids of HM...},
author = {Bengio, Y.},
doi = {10.1.1.54.1926},
file = {:C$\backslash$:/Users/sanek/Documents/Mendeley Desktop/Neural Computing Surveys/1996/Bengio - 1996.pdf:pdf},
journal = {Neural Computing Surveys},
keywords = {arti cial neural networks,hidden markov models,input-output hidden markov models,learning algorithms,markov switching models,state space models,transducers,weighted},
pages = {129----162},
title = {{Markovian Models for Sequential Data}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.54.1926},
volume = {2},
year = {1996}
}
