\documentclass[12pt]{scrartcl}

\usepackage{fontspec}
\usepackage{polyglossia}
\setdefaultlanguage{russian}
\newcommand{\docfont}{Times New Roman}
\setmainfont[Ligatures=TeX]{\docfont}
\newfontfamily\cyrillicfont[Ligatures=TeX]{\docfont}
\newfontfamily\cyrillicfontsf[Ligatures=TeX]{\docfont}
\newfontfamily\cyrillicfonttt[Ligatures=TeX]{\docfont}

\usepackage{amsmath,amsfonts,amsthm,amssymb} % nice math symbols
\newtheorem{definition}{Определение}
\usepackage{hyperref}

\hypersetup{%
	pdfencoding=auto,
	pdfauthor={Александр Панов},
	pdftitle={Планирование в знаковой картине мира}
}
\usepackage{csquotes}
\usepackage{graphicx}
\graphicspath{{../../images/}}

\usepackage[plain]{algorithm}
\usepackage[noend]{algpseudocode}

\usepackage[
%	autolang=hyphen,
	language=auto,
	autolang=other,
	backend=biber,
	style=gost-numeric
]{biblatex}
\addbibresource{../../biblio/library.bib}
\DeclareSourcemap{
	\maps[datatype=bibtex, overwrite]{
		\map{
			\step[fieldset=langid, fieldvalue=english]
			\step[fieldset=doi, null]
			\step[fieldset=issn, null]
			\step[fieldset=isbn, null]
			\step[fieldset=url, null]
			\step[fieldsource=language, fieldset=langid, origfieldval]
		}
	}
}

\linespread{2}

\title{Семиотический способ представления знаний: планирование в знаковой картине мира}
\author{Панов~А.\,И.\\
	{\large\slshape ФИЦ ИУ РАН, пр. 60-летия Октября, 9, gos@isa.ru}}

\begin{document}
%	\affil{ФИЦ ИУ РАН}
	
	\maketitle{}
	\begin{abstract}
		В работе представлен новый способ представления знаний как на уровне сенсорных данных так и на уровне концептуальной информации, - знаковая картина мира. Базовым элементом картины мира является четырехкомпонентная структура - знак, строение которого подтверждается как психологическими теориями, так и нейрофизиологическими данными. В работе представлены принципы работы математической структуры - каузальной матрицы, которая описывает строение компонент знака. Предложены алгоритмы пополнения отношений на множестве знаков, определены операции в знаковой картине мира, который моделируют важные психологические особенности поведения человека.
		\par\bigskip
		\textit{Ключевые слова}: знаковая картина мира, образ, значение, личностный смысл, каузальная матрица, семиотическая сеть.
	\end{abstract}
	
	
	
	\section*{Введение}
	Про постановку задачи \cite{Osipov2014c,Osipov2015d}.
	
	Психологические и нейрофизиологические основания трехкомпонентной структуры знака (Станович, Гроссберг и др. более новые).
	
	\section{Картина мира}

	Про компоненты знака, функции связывания и три типа картин мира.
	
	Введем два знака,~которые мы будем рассматривать на протяжении всей статьи в качестве примеров, иллюстрирующих положения, которые приводятся в настоящей работе (квадрат, выстрел).
	
	
	\section{Строение компонент знака}
	
	Далее рассмотрим структуру компонент знака на примере образной компоненты, которая участвует в актуализации знака, выделении представления об опосредуемом объекте или процессе на основе поступающей из внешней среды сенсорной информации и регистрируемой внутренними сенсорами моторной информации. До именования знак будем называть протознаком или признаком.
	
	Предположим, что во входном потоке данных выделена последовательность $(x_1,x_2,\dots,x_h)$ длины $h$ векторов действительных чисел от 0 до 1, которые будем называться \textit{событиями}. Каждое событие $x_t$ длины $q$ представляет собой запись выходов от $q$ сенсоров, а каждый элемент события означает уверенность в срабатывании данного сенсора. Например, событие $(0.1, 0.9, 0.9)$ поступает с трех сенсоров - датчиков красного, синего и зеленого света - и означает, что уверенность в срабатывании датчика красного света составляет 10\%, а синего и зеленого - по 90\%.
	
	Образная компонента знака должна по входной последовательности данных определить, присутствует ли (закодирован ли) опосредуемый объект или процесс в этой последовательности. Для этого мы будем кодировать характерные признаки объекта или процесса в специальной структуре - каузальной матрице $z=(e_1,e_2,\dots,e_h)$ размерности $q$ на $h$, где $q$ - размерность входных событий, а $h$ - длина последовательности входных событий. При этом каждый столбец $e_t$ каузальной матрицы является битовым вектором длины $q$ и кодирует те признаки (которым соответствуют 1), которые необходимо должны присутствовать во входном событии в момент времени $t$, чтобы опосредуемый объект или процесс мог быть распознан во входном потоке данных, т.е. задают множество одновременных характерных признаков. Например, образу знака $s$, опосредующему объект <<квадрат>>, может соответствовать каузальная матрица 	\[z=((1,0,1,1,0),(1,1,0,1,0),(1,1,0,0,1),(1,0,1,0,1)),\]
	где первая строчка является характеристическим вектором информации с датчика углов на изображении, вторая - с датчика положения визуального сенсора (верхнее положение), третья - нижнее положение сенсора, четвертая - левое положение сенсора, пятая - правое положение (см. рис.\ref{fig:square}).

	\begin{figure}
		\label{fig:square}
		\centering
		\includegraphics[width=0.5\textwidth]{examples/square}
		\caption{Визуальная интерпретация каузальной матрицы}		
	\end{figure}

	Образу каждого знака может соответствовать несколько каузальных матриц, которые задают различные проявления опосредуемого объекта или процесса. Весь кортеж каузальных матриц образа знака $s$ будем обозначать как $Z^p(s)$. 
	
	Случай, когда характерными признаками образа данного знака выступают данные с сенсоров, является частным. В более общей постановке, признаками для образа знака служат другие знаки, которые опосредуют эти характерные признаки. Таким образом, мы можем сопоставить образу знака $s$ множество $S_p(s)$ мощности $q$, каждому элементу которого соответствует номер строчки каузальной матрицы $z$ размера $q$ на $h$, т.е. каждому признаку $s_i\in S_p(s)$ соответствует характеристический битовый вектор, задающий на местах 1 те моменты времени, когда данный признак должен присутствовать во входных данных, чтобы успешно актуализировать знак (распознать образ знака) $s$. 
	
	Для уточнения определения множества $S_p(s)$ введем семейство бинарных отношений $\{\sqsubset_p,\sqsubset_p^1,\sqsubset_p^2,\dots\}$, определённых на декартовом произведении $S\times S$. Будем считать, что знак $s_i$ \textit{поглощается} знаком $s$ по образу, $(s_i,s)\in\sqsubset_p$ или $s_i\sqsubset_p s$, в том случае, если $s_i\in S_p(s)$. Если известно, что знаку $s_i$ соответствует 1 в $t$-м столбце некоторой каузальной матрицы $z\in Z^p(s)$ знака $s$, то мы будем использовать уточненное отношение $\sqsubset_p^t\subset \sqsubset_p$.
	
	\subsection{Актуализация образной компоненты знака}
	
	Кратко опишем работу алгоритма актуализации знака (распознавания образа знака) по рис.~\ref{fig:percept}. Будем считать, что образы знаков сгруппированы по схожести множеств $S_p(s)$ в узлы, которые организованы в иерархические структуры (подробнее см. \cite{Panov2014d}).
	
	\begin{figure}
		\centering
		\includegraphics[width=0.8\textwidth]{algo/perception}
		\caption{Схема алгоритма актуализации знака}
		\label{fig:percept}		
	\end{figure}

	Вычислительный цикл распознавания в узле уровня $j$ начинается с определения начального состояния узла при помощи предсказывающего воздействия с верхнего уровня иерархии - вектора ожиданий $\hat x_i^{j+1}(\tau_s)$ (шаги \ref{alst:init_start}--\ref{alst:init_end}) в момент времени $\tau_s$. Начальное состояние определяется как подмножество таких знаков, образы которых предсказываются на основе состояния узла верхнего уровня. Первая константа $c_1$ определяет порог предсказываемого веса распознаваемых образов, выше которого соответствующие каузальные матрицы попадают во множество активных матриц $Z^*$ (шаг \ref{alst:select_f}). Далее производится отбор тех каузальных матриц из множества активных, для которых обычное расстояние по норме $\|x\|=\sum_i |x_i|$ первого столбца $\bar z_1^r$ от входного вектора $\bar x_i^j$ в начальный момент времени не превышает второй константы $c_2$ (шаг \ref{alst:select_z}). Обновленное множество полученных таким образом активных каузальных матриц является текущим состоянием узла (шаг \ref{alst:init_state}). На основе активных каузальных матриц методом голосования вычисляется выходной вектор узла  в начальный момент времени $\bar x_i^{j*}(\tau_s)$ (шаги \ref{alst:init_calc_out2} -- \ref{alst:init_calc_out3}).

	\linespread{1}
	\begin{algorithm}[H]
		\label{alg:automato}
		\begin{algorithmic}[1]
			\input{../../algorithms/alg_perc_init}
			\algstore{algst:store1}
		\end{algorithmic}
	\end{algorithm}
	\linespread{2}

	Вектор ожиданий $\hat x_i^j(\tau_s+1)$ определяется как нормированный вектор, $s$-ый компонент которого равен сумме всех $s$-ых элементов вторых колонок активных каузальных матриц с весами, соответствующими элементам вектора ожиданий $\hat x_i^{j+1}(\tau_s)$ (шаг \ref{alst:init_control}). Т.к. используется представление о будущем входном сигнале (вторая колонка матриц предсказания), то $\hat x_i^j(\tau_s+1)$ играет роль предсказывающего вектора для нижнего уровня иерархии.

	\linespread{1}
	\begin{algorithm}[H]
		\begin{algorithmic}[1]
			\algrestore{algst:store1}
			\input{../../algorithms/alg_perc_cyrcle}
		\end{algorithmic}
	\end{algorithm}
	\linespread{2}
		
	После определения начального состояния начинает выполняться тело основного цикла, в котором до тех пор, пока время не превысит характерное время узла $h_i^j$ (размер каузальных матриц, входящих в него образов знаков) повторяется вычисление выходного вектора и состояния в следующий момент времени (шаги \ref{alst:cycle_start}--\ref{alst:cycle_end}). В начале обновляется состояние, т.е. множество активных каузальных матриц $Z^*$, за счёт удаления тех матриц, соответствующие столбцы которых достаточно сильно отличаются от текущего входного вектора $\bar x_i^j$ (шаг \ref{alst:update_z}). Далее методом голосования по количеству матриц в множестве активных каузальных матриц, отвечающих за соответствующий образ, вычисляется выходной вектор $\bar x_i^{j*}$ (шаги \ref{alst:calc_out1}--\ref{alst:calc_out3}).

	
	В завершение тела основного цикла вычисляется выходной вектор ожиданий в следующий момент времени $\hat x_i^j(\tau_s+t+1)$. Вектор ожиданий равен нормированному вектору, элементы которого равны сумме элементов столбцов всех активных кауазальных матриц, соответствующих текущему моменту времени с учётом весов начального вектора ожиданий $\hat x_i^{j+1}(\tau_s)$ (шаг \ref{alst:calc_state1}).

	\subsection{Каузальная сеть}
	
	Введем специальную процедуру $\Lambda_p: 2^Z\rightarrow 2^{\mathbb N}\times 2^{\mathbb N}$, которая каждому кортежу каузальных матриц $Z^p(s)\subset Z$ образа знака $s$ ставит в соответствие два не пересекающихся подмножества индексов собственных столбцов $I^c\subset\mathbb N, \forall i\in I^c\ i\leq h$ (индексы столбцов условий) и $I^e\subset\mathbb N, \forall i\in I^e\ i\leq h$ (индексы столбцов эффектов): $\Lambda_p(Z^p(s))=(I^c,I^e), I^c\cap I^e=\varnothing$. Например, если для множества матриц $Z=\{((1, 0), (0, 1))\}$ процедура $\Lambda_p$ выдает два множества $\{1\}$ и $\{2\}$, то это означает, что появление признака, соответствующего первой строчке матрицы, вызывает появление признака, соответствующего второй строчке. Процедура $\Lambda_p$ по сути является функцией установления причинно-следственного отношения на множестве входных событий и может реализовываться различными способами, в т.ч. на основе алгоритмов Норриса, FCO и др. (см. \cite{Kuznetsov2001})
	

	В том случае, когда для матриц $Z^p(s)$ образа знака $s$ множество столбцов эффектов пусто $I^e=\varnothing$, т.е. когда по данному множеству каузальных матриц не возможно однозначно определить, какие события всегда предшествуют другим, мы будем считать, что причинно-следственная связь не установлена и знак опосредует некоторый объект или ситуацию. В противном случае будем считать, что знак опосредует некоторое действие или процесс, результат которого кодируется в столбцах эффектов, а условие - в столбцах условий. 

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.6\textwidth]{automata/caus_matr}
		\caption{Схема каузальной матрицы}	
		\label{fig:caus_matr}	
	\end{figure}
	
	Справедливы следующие утверждения относительно свойств процедуры $\Lambda_p$:
	\begin{itemize}
		\item $I^c\cap I^e=\varnothing$ --- столбец матрицы предсказания не может быть одновременно и условием и эффектом,
		\item $|I^c\cup I^e|=h$ --- столбец матрицы предсказания является либо условием либо эффектом,
		\item $I^c\not = \varnothing$ --- среди столбцов матрицы предсказания должен быть хотя бы один столбец условий, в то время как эффектов может и не быть (в случае объектных признаков),
		\item $\forall i\in I^e, j\in I^c\ i>j$ --- все условия предшествуют эффектам по времени.
	\end{itemize}
	
	Схема каузальной матрицы, с учетом выше сказанного, приведена на рис. \ref{fig:caus_matr}.
	
	Теперь введем понятие каузальной сети, которая будет определять гетерархию на множестве образов. Каузальная сеть $W_p=\langle V_p, E_p \rangle$ - является помеченным ориентированным графом, в котором
	\begin{itemize}
		\item каждому узлу $v\in V_p$ ставится в соответствие кортеж казуальных матриц $Z^p(s)$ образа некоторого знака $s$, что будем обозначать как $v\rightarrow Z^p(s)$;
		\item ребро $e=(v_1, v_2)$ принадлежит множеству ребер графа $E$, если $v_1\rightarrow Z^p(s_1), v_2\rightarrow Z^p(s_2)$ и $s_1\in S_p(s_2)$, т.е. если знак $s_1$ поглощается знаком $s_2$;
		\item каждому ребру графа $e=(v_1, v_2), v_1\rightarrow Z^p(s_1), v_2\rightarrow Z^p(s_2)$ ставится в соответствие метка $\epsilon=(\epsilon_1,\epsilon_2,\epsilon_3)$ - кортеж трех натуральных чисел:
		\begin{itemize}
			\item $\epsilon_1$ - индекс исходной матрицы в кортеже $Z^p(s_1)$, может принимать специальное значение 0, если исходными могут служить любые матрицы из кортежа;
			\item $\epsilon_2$ - индекс целевой матрицы в кортеже $Z^p(s_2)$, строка которой ставится в соответствие признаку $s_1$;
			\item $\epsilon_2$ - индекс столбца в целевой матрице, в которой в соответствующей признаку $s_1$ строке стоит 1, может принимать положительные значения (столбцы условий) и отрицательные (столбцы эффектов).
		\end{itemize}		
	\end{itemize}
	
	Пример такой сети изображен на рис. \ref{fig:caus_net}.
	
	Аналогичным образом определяются каузальные сети для остальных компонент знака - для значения и личностного смысла. Для каждого знака $s$ задаются множества $S_m(s)$ и $S_a(s)$, т.е. определяются семейства отношений $\{\sqsubset_m,\sqsubset_m^1,\sqsubset_m^2,\dots\}$ и $\{\sqsubset_a,\sqsubset_a^1,\sqsubset_a^2,\dots\}$. Множество $S_m(s)$ интерпретируется как ролевой состав знака $s$, например, элементы подкласса или роль действия. Множество $S_a(s)$ интерпретируется как мгновенный компонентный состав некоторой ситуации, наблюдаемой и переживаемой субъектом, носителем картины мира, в настоящее время. Аналогично определяются множества $Z^m(s)$, $Z^a(s)$, процедуры $\Lambda_m$ и $\Lambda_a$.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.5\textwidth]{automata/caus_net}
		\caption{Схема каузальной сети. Здесь каузальные матрицы изображены в виде квадратов, столбцы условий - левая белая часть квадрата, столбцы эффектов - черная правая часть квадратов. Метка $\epsilon_1$ отображается в начале каждой стрелки, метка $\epsilon_2$ определяется как номер квадрата, к которому идет стрелка, а метка $\epsilon_3$ отображается в конце каждой стрелки.}
		\label{fig:caus_net}		
	\end{figure}
	
	\section{Семиотическая сеть}
	
	Далее определим три семейства бинарных отношений на множестве знаков, которые  генерируются на основе структуры фрагментов трех типов каузальных сетей, к которым принадлежат соответствующие компоненты знаков.
		
	Будем называть \textit{семиотической сетью} пятерку $\Omega=\langle W_p, W_m, W_a, R_n, \Theta \rangle$, где
	\begin{itemize}
		\item $W_p, W_m, W_a$ - соответственно каузальные сети на множестве образов, значений и личностных смыслах,
		\item $R_n$ - семейство отношений на множестве знаков, сгенерированных на основе трех каузальных сетей, т.е. $R_n=\{R_p, R_m, R_a\}$,
		\item $\Theta$ - семейство операция на множестве знаков, которые будут определены ниже.
	\end{itemize} 
	
	Еще раз отметим, что знак представляет не только объекты внешнего мира, но также процессы, протекающие в нем, выполнимые действия, а также ситуации, наблюдаемые во внешней среде.

	Активность в семиотической сети. Распространение активности на некоторую глубину. Его связь с процедурой распознавания образов.
	
	Функции перехода от одной сети к другой через знак $\Psi_a^m$.
	
	\section{Планирование в знаковой картине мира}
	Процесс планирования в знаковой картине мира реализуется с помощью MAP-алгоритма и идет в обратном направлении: от конечной ситуации к начальной. Кратко опишем основные этапы его работы. На входе алгоритма поступает описание задачи 
	\[T = \langle N_T,S,Sit_{start}, Sit_{goal}\rangle,\]
	где {$N_T$ - идентификатор задачи, $S$ - множество знаков семиотической сети, $Sit_{start}=\langle \varnothing, \varnothing, a_{start} \rangle$ - начальная ситуация со смыслом $a_{start}$, $Sit_{goal}=\langle \varnothing, \varnothing, a_{goal} \rangle$ - целевая ситуация со смыслом $a_{goal}$. MAP-алгоритм осуществляет итеративную генерацию новых фрагментов каузальной сети на личностных смыслах $F_{next}$ на основе текущего активного фрагмента $F_{cur}$ до тех пор, пока не будет достигнуто предельное количество шагов $i_{max}$ или не будет целиком активирован начальный фрагмент $F_{start}$, являющийся личностным смыслом $a_{start}$ начальной ситуации. В качестве текущего активного фрагмента для первой итерации выступает личностный смысл целевой ситуации $a_{goal}$. 
		
	На каждой итерации повторяется следующий набор операций:
	\begin{itemize}
		\item $M$-шаг: распространение активности на сети личностных смыслов на глубину $d_a$ и формирование 
	\end{itemize}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.6\textwidth,page=1]{plan/plan_nets}
		\caption{Начальная ситуация}	
		\label{fig:caus_matr}	
	\end{figure}
	
	\section*{Заключение}
	
	\printbibliography
\end{document}