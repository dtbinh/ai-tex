\begingroup
\chapter{Моделирование картины мира}\label{chap:swm_model}

\section{Синтаксический и~семантический уровни модели}\label{sect:sint_level}

Напомним описание синтаксического уровня модели КМ следуя
п.~\ref{sect:first_def} и работам \cite{Osipov2014c,Osipov2016c}. Пусть
задано множество $S,$ которое будем называть множеством знаков. Каждый элемент
$s\in S$ имеет вид $s=\langle n,p,m,a\rangle,$ где $n\in N,$ $p\subseteq P,$
$a\subseteq A,$ $m\subseteq M.$ Здесь $N$~--- множество слов конечной длины
в некотором алфавите, которое будем называть множеством имен; $P$~--- множество
замкнутых атомарных формул языка исчисления предикатов первого порядка, которое
будем называть множеством свойств; $M$ будем называть множеством значений;
$A$~--- множеством смыслов. Как множество значений $M,$ так и множество
смыслов $A$ (поскольку это следует из психологических соображений)
интерпретируются множеством действий. Каждое действие, как это принято
в искусственном интеллекте, представим с помощью правила \cite{Osipov2008b}.
Правилом называется упорядоченная тройка множеств: $r=\langle
Con,Add,Del\rangle,$ где $Con$~--- условие правила $r$; $Add$~--- множество фактов,
добавляемых правилом $r$; $Del$~--- множество фактов, удаляемых правилом $r.$
Каждое из этих множеств в общем случае представляет собой множество атомарных формул
исчисления предикатов первого порядка. Более детально указанная роль правил
в знаковой модели будет описана ниже\hbox{}.

Введем операторы связывания. $\Psi_p^m":2^P\rightarrow 2^M$~--- оператор
связывания образов $p$  со значениями $m.$ Второй оператор
$\Psi_m^a":2^M\rightarrow 2^A$ связывает значения со смыслами. Третий оператор
$\Psi_a^p": 2^A\rightarrow 2^P$ связывает смыслы с об\-разами.

На семантическом уровне описания картины мира уточняется операционная семантика
введенных операторов связывания, а компоненты знака интерпретируются символами
исчисления предикатов и правилами, определенными выше\hbox{}.

\fig{{operrelat-0}}{\caption{Оператор связывания образа и значения
знака}\label{fg:relat_c}}

Определим оператор связывания (рис.\:\ref{fg:relat_c})
$\Psi_p^m(p^{(i)})=m^{(i)}$ так, что $m^{(i)}=\{ r"|\mathcal{P}_c(r)\subseteq
\mathcal{P}(p^{(i)})\}$. Здесь $\mathcal{P}_c(r)$~--- множество различных
предикатных символов условия $Con$ правила $r,$ интерпретирующего значение $m.$
Иначе говоря, то обстоятельство, что значение $m^{(i)}$ связано с образом
$p^{(i)}$ некоторого знака, означает, что условие правила $r,$
интерпретирующего значение $m^{(i)}\!,$ выполняется на образе $p^{(i)}\!.$
(Здесь и далее для простоты мы будем с каждым значением связывать ровно одно
действие, т.\,е. одно правило). $\mathcal{P}(p^{(i)})$~--- множество
предикатных символов образа $p^{(i)}$; $p^{(i)}\in 2^P,$ $m^{(i)}\in 2^M,$
$2^P$ и $2^M$~--- булеаны $P$ и $M$ со\-от\-вет\-ственно.

Второй оператор $\Psi_m^a(m^{(i)})=a^{(i)},$ где $a^{(i)}=\{
r^*|\mathcal{P}_c(r)\cap \mathcal{P}_c(r^*)\ne \varnothing\} ,$ где
$\mathcal{P}_c(r^*)$~--- множество предикатных символов условия $Con$
правила $r^*\!,$  интерпретирующего личностный смысл $a^{(i)}\!.$ То есть
личностный смысл $a^{(i)}$ интерпретируется таким правилом $r^*\!,$ пересечение
условия которого с условием правила $r,$ интерпретирующего значение, непусто
(рис.\:\ref{fg:relat_a}). (Здесь, как и в случае со значением, для простоты
с каждым личностным смыслом связывается ровно одно действие, т.\,е. одно
правило.) $m^{(i)}\in 2^M,$ $a^{(i)}\in 2^A,$ $2^A$~--- булеан $A.$ Третий
оператор $\Psi_a^p(a^{(i)})=p^{(i+1)},$ где $p^{(i+1)}\subseteq
\mathcal{P}_c(r_j^*),$ $a^{(i)}\in 2^A,$ $p^{(i+1)}\in 2^P,$ где
$\mathcal{P}_c(r_j^*)$~--- множество предикатных символов из множества условий
правила $r_j^*.$ Таким образом, отображение ставит в соответствие каждому правилу $r^*_j,$
интерпретирующему личностный смысл, некоторый образ из
множества образов, такой что множество предикатных символов образа включено
в множество предикатных символов правила $r^*_j$ (рис.\:\ref{fg:relat_b}).

\dfig{{operrelat-1}}{\caption{Оператор связывания
$\Psi_m^a$}\label{fg:relat_a}}{{operrelat-2}}{\caption{Оператор
связывания $\Psi_a^p$}\label{fg:relat_b}}

Разумеется, $p^{(i)}\ne p^{(i+1)}.$ Можно показать, что при определенном
начальном приближении этот итеративный процесс сходится к некоторому $p.$ Легко
видеть, что достаточным условием сходимости является $\mathcal
P_c(r)\subseteq\mathcal P_c(r^*).$ Если ввести оператор
$\Psi_m^p=\Psi_a^p\Psi_m^a,$ то пара операторов $\Psi_p^m$ и $\Psi_m^p$
образует соответствие Галуа, а знак является неподвижной точкой замыкания Галуа
операторов $\Psi_p^m$ и~$\Psi_m^p.$

Действуя на основе приведенной в начале п.~\ref{sect:first_def} схемы
0"~~9, рассмотрим стадии формирования знака предмета в микрогенезе, или стадии
актуализации знака\hbox{}.

\subsection{Формирование функционального значения и образа вос\-приятия}

Как было сказано выше, мы исходим их того, что субъект обладает некоторым опытом
действования, который зафиксирован, в частности, в прецедентах (примерах)
применения отображения $\Psi_p^m":2^P\rightarrow 2^M.$ Будем считать, что
множество прецедентов~--- это множество упорядоченных пар вида $\langle
p,m\rangle$, таких что $\Psi_p^m(p^{(i)})=m^{(i)},$ где $p^{(i)}\in
2^P,$~$m^{(i)}\in 2^M.$

Применим для описания процесса формирования перцепта и функционального значения
элементарные топологические соображения. Заметим, что $(P, T_P)$ и $(M, T_M)$
суть дискретные топологические пространства с топологиями $T_P=2^P$ и $T_M=2^M$
соответственно. Тогда отображение $\Psi_p^m": 2^P\rightarrow 2^M$~--- это
отображение топологического пространства $(P, T_P)$ в топологическое
пространство $(M, T_M).$ Пусть $N=\langle i_1,i_2,\ldots,i_n\rangle$~---
последовательность итераций отображения $\Psi_p^m$ топологического пространства
$(P, T_P)$ в топологическое пространство $(M, T_M).$ Тогда бинарное
отношение~${\ge}$ является направлением на $N,$ а $(\Psi_p^m\,|\,N, \ge)$~---
последовательностью по направленному множеству $N.$ Поскольку
$\Psi_p^m(p^{(i)})=m^{(i)},$ где $m^{(i)}\in (M,T_M),$ то $\Psi_p^m$~---
направленность в~$M.$

Пусть $m$~--- некоторая точка в пространстве $(M,T_M),$ $\sigma$~--- система
окрестностей точки $m.$ В~результате применения отображения $\Psi_m^p$ (т.\,е.
отображения, обратного $\Psi_p^m$) возникает некоторый начальный
перцепт~$p^{(0)}\!.$

В~результате работы механизмов распознавания образов (рассмотрение которых
здесь опущено) в $(P,T_P)$ формируется перцепт $p^{(1)}\!.$
Отображение $\Psi_p^m$  ставит ему в соответствие функциональное значение
$m^{(1)}$ из~$(M,T_M).$

Далее возможны три случая:
\begin{enumerate}
 \item\label{choise_1} $m^{(1)}=m,$
 \item\label{choise_2} $m^{(1)}\not\in\sigma,$
 \item\label{choise_3} $m^{(1)}\in\sigma.$
\end{enumerate}

Начнем с рассмотрения случая \ref{choise_2}. Для большей определенности допустим, что
$p^{(1)}$~--- одноэлементное множество. Тогда если $m^{(1)}\not\in\sigma,$ то
следует выбрать, вообще говоря, другое одноэлементное множество $p^{(2)}$
и вновь применить отображение $\Psi_p^m(p^{(2)})=m^{(2)}.$ Содержательно это
означает, что признак $p^{(1)}$ был выбран неудачно и не являлся существенным.
С~точки зрения распознавания образов требуется настройка процедур
распознавания. Этот процесс продолжается до тех пор, пока не будет получен
случай \ref{choise_3}.

В~случае \ref{choise_3} имеет место следующее: последовательность $(\Psi_p^m,{\ge})$ сходится к точке $m$ тогда и только тогда, когда, начиная с некоторого $k,$ по
направленному множеству $(\Psi_p^m | N,{\ge})$ она остается в окрестности $\sigma$
точки $m$. Однако топология $(M,T_M)$ является
дискретной, следовательно, любое множество в ней открыто; тогда из того, что $m$~---
предел последовательности $(\Psi_p^m,{\ge}),$ следует, что $m^{(i)}=m$ начиная
с некоторого $k.$ Этим исчерпывается и случай \ref{choise_1}.
Следовательно,~$p^{(i)}={(\Psi_p^m)}^{-1}(m)=\Psi_m^p(m).$

Далее в соответствии с приведенной схемой субъект получает из внешней
культурно"=исторической среды пару "<имя~--- значение">~--- $\langle
n,m^0\rangle.$ Пусть $\sigma^0$~--- система окрестностей точки $m^0$
в $(M,T_M).$ Тогда вновь следует рассмотреть три случая\hbox{}:
\begin{enumerate}
 \item\label{choise0_1} $m=m^0\!,$
 \item\label{choise0_2} $m\not\in\sigma^0\!,$
 \item\label{choise0_3} $m\in\sigma^0\!.$
\end{enumerate}

Если $m\not\in\sigma^0\!,$ то необходимо вновь использовать процедуры распознавания
и отображение $\Psi_p^m$, пока не будет получен
случай \ref{choise0_3}. Остается только использовать приведенные в предыдущем
абзаце соображения, заменив $\sigma$ на $\sigma^0\!,$ а $m$~--- на $m^0\!.$
Завершается эта стадия монотонным продолжением функции $\Psi_p^m$ на
множество~$\{ \langle p^{(i)},m^0\rangle\} .$

\subsection{Именование}

Будем рассматривать процедуру получения из внешней среды пары $\langle
n,m\rangle$ как функцию $\mathfrak M(n),$ выдающую по имени $n$ значение $m.$
Тогда ${(\Psi_p^m)}^{-1}(\mathfrak M(n))$ есть функция, присваивающая имя $n$
перцепту $p^\prime\!.$ Обозначим ее через $\mathfrak P(n).$ Иначе говоря,
$\mathfrak P(n)$~--- функция именования перцепта. С~получением имени $n$
перцепт $p^\prime$ превращается в образ $p.$ На следующем шаге выполняется
именование биологических смыслов и тем самым~--- трансформация их в личностные
смыслы\hbox{}.

Множество личностных смыслов, как было замечено выше, формируется на основе
опыта действий субъекта деятельности с предметом, соответствующим
рассматриваемому знаку, и оценки успешности этих действий с помощью механизмов
самосознания. Для определенности будем полагать, что этот опыт зафиксирован
в отображении $a=\Psi_m^a(m),$ т.\,е. в виде пары $\langle m,a\rangle.$ Тогда
функция $\mathfrak A(n)$ именования биологического смысла $a^\prime$ будет
иметь следующий вид: $\mathfrak A(n)=\Psi_m^a(\mathfrak M(n)).$ Биологический
смысл $a^\prime$ становится личностным смыслом $a$
(рис.\:\ref{fg:sign_naming}). Завершается этот процесс монотонным продолжением
функции $\Psi_a^p$ на множество~$\{ a\} .$

\fig{{sign_naming_colored}}{\caption{Процедуры связывания компонент
знака и функция именования}\label{fg:sign_naming}}

Легко видеть, что имеют место следующие факты.
\begin{Pred}
 {\unct\label{pred:fixed_point}}Если $s$~--- знак, $p,$ $m,$ $a$~--- его
образ, значение и личностный смысл соответственно, то тройка $\langle
 p,m,a\rangle$ представляет собой неподвижную точку оператора $\Psi_a^p\Psi_m^a\Psi_p^m.$
\end{Pred}
\begin{Proof}
Действительно, если $n$~--- имя знака $s,$ то тогда значениями функций
именования $\mathfrak P,$ $\mathfrak M$ и $\mathfrak A$ в точке $n$ являются
соответствующие компоненты знака. В~этом случае из определения процедур
связывания следует, что $\Psi_p^m(\mathfrak P(n))=\mathfrak M(n),$
$\Psi_m^a(\mathfrak M(n))=\mathfrak A(n)$ и $\Psi_a^p(\mathfrak
 A(n))=\mathfrak P(n).$ Рассмотрим пространство $Z,$ в котором каждая
точка $z_i$ представлена тройкой $\langle p_i,m_i,a_i\rangle.$ В~этом
пространстве действие операторов $\Psi_x^y,$  $x,y\in\{ p,m,a\} ,$ является
поокординатным преобразованием точки, т.\,е. применение, скажем,
оператора $\Psi_p^m$  к точке $z_i=\langle p_i,m_i,a_i\rangle$ означает
преобразование второй координаты таким образом, что в результирующей точке
$z'_i=\langle p_i,m'_i,a_i\rangle$ $m'_i=\Psi_p^m(p_i).$ Тогда последовательное
покоординатное применение операторов $\Psi_a^p,$ $\Psi_m^a,$ $\Psi_p^m$ к точке
$\langle p,m,a\rangle,$ для которой существуют указанные выше функции
именования, не приведет к изменению ее координат, т.\,е.
$\Psi_a^p\Psi_m^a\Psi_p^m(\langle p,m,a\rangle)=\langle p,m,a\rangle,$ что
и требовалось доказать.
\end{Proof}
%

\begin{Pred}
Если $s$~--- знак, то $\Psi_m^a\Psi_p^m\Psi_a^p,$ $\Psi_a^p\Psi_m^a\Psi_p^m$
и $\Psi_p^m\Psi_a^p\Psi_m^a$~--- тождественные операторы.
\end{Pred}
\begin{Proof}
Так как задан знак со своими компонентами, то выполняется условие
утверждения \ref{pred:fixed_point} и действие оператора
$\Psi_a^p\Psi_m^a\Psi_p^m$ можно записать следующим образом:
$p=\Psi_a^p(a)=\Psi_a^p(\Psi_m^a(m))=\Psi_a^p(\Psi_m^a(\Psi_p^m(p))),$ что
и означает тождественность данного оператора. Аналогичным образом
выписывается и тождественность остальных операторов.
\end{Proof}

\begin{Pred}
Если $s$~--- знак, то \[ \Psi_p^m(\mathfrak P(n))=\mathfrak M(n),\quad
\Psi_m^a\Psi_p^m(\mathfrak P(n))=\mathfrak A(n). \]
\end{Pred}
\begin{Proof}
Данные тождества следуют из доказательства утверждения \ref{pred:fixed_point}.
\end{Proof}

Подобным образом выписываются еще шесть фактов такого рода\hbox{}.

\subsection{Процедуры самоорганизации} \label{subsect4_4}

Рассмотрим структуры, которые могут возникать на множестве знаков как результат
их самоорганизации. Моделирование самоорганизации в картине мира позволяет
операционализировать представление об "<активности знаний"> \cite{Osipov2002d},
сформировавшееся в искусственном интеллекте под влиянием предложенной в 1956\;году
Л.~Фестингером концепции побуждающей роли знаний в поведении
человека. Согласно Л.~Фестингеру, знания не просто накапливаются и используются
субъектом~--- знания живут своей жизнью, вступают в отношения, образуют то
гармоничные, согласованные системы представлений, то оказываются втянуты
в конфликты и противопоставляются друг другу. Последний случай, случай
рассогласования в знаниях, и выступает как побуждающая поведение сила:
"<Взгляды и установки имеют свойство объединяться в систему,
характеризующуюся согласованностью входящих в нее элементов{\ldots}
существование противоречивых отношений между отдельными элементами в системе
знаний само по себе является мотивирующим фактором"> \cite{Festinger1999}.

\subsubsection{Отношения и операции на множестве образов}\label{subsubsect4_4_1}

Пусть $S=\{ s_1,s_2,\ldots,s_k\} $~--- множество знаков,
$p=(x_1,x_2,\ldots,x_g)$ и $q=(y_1,y_2,\ldots,y_h)$~--- образы знаков $s_p$
и $s_q$ соответственно ($p,q\in(2,\ldots,k)$). Пусть $\pi$~--- множество
образов знаков из $S.$  Образы $p$ и $q$ из $\pi$ суть множества значений
признаков; индексы признаков указывают на их принадлежность тем или иным
множествам признаков (доменам); так, равенство $i=j$ свидетельствует
о принадлежности значений признаков $x_i$ и $y_j$ одному и тому же множеству,
например~$X_i.$

Упорядоченные множества $\tau_p=\langle i_1,i_2,\ldots,i_p\rangle$
и $\tau_q=\langle j_1,j_2,\ldots,j_q\rangle,$ где
$i_1,i_2,\ldots,i_p\in(1,\ldots,g),$ $j_1,j_2,\ldots,j_q\in(1\ldots,h),$ будем
называть типами образов знаков $s_p$ и $s_q$ со\-от\-вет\-ственно.

Введем процедуру $\Pi^p\!,$ которая для всякого знака $s_p$ просматривает все
остальные знаки и выполняет указанные ниже действия (пополняет бинарные
от\-но\-шения).
\begin{enumerate}
 \renewcommand\labelenumi{\theenumi.}
 \item Если для знака $s_p$ и некоторого знака $s_q$  ($p\ne q$)
$\tau_p=\tau_q$ и $x_i=y_i,$ то $R^p_{eq}:=R^p_{eq}\cup\{ (p,q)\}
 ,$ $R^p_{eq}\subseteq\pi\times\pi$ (рис.\:\ref{fig:relat_0}).
\end{enumerate}

\fig{{sign_relations-00}}{\caption{Определение отношения
эквивалентности $R^p_{eq}$ на множестве образов}\label{fig:relat_0}}

Легко видеть, что отношение $R^p_{eq}$ является отношением эквивалентности на
множестве образов $\pi.$ Определенные ниже отношения $R^p_{in},$ $R^p_{sim},$
$R^p_{con}$ суть отношения включения, сходства и противопоставления
со\-от\-вет\-ственно.
\begin{enumerate}
 \setcounter{enumi}{1}
 \renewcommand\labelenumi{\theenumi.}
 \item Если для знака $s_p$ и некоторого знака $s_q$ $\tau_p\subset\tau_q$
и $\forall\,  i\in\tau_p$ имеет место $x_i=y_i,$ то
$R^p_{in}:=R^p_{in}\cup\{ (p,q)\} ,$
$R^p_{in}\subseteq\pi\times\pi$ (отношение включения)
 (рис.\:\ref{fig:relat_1}).
 \item Если для знака $s_p$ и некоторого знака $s_q$  $\tau_p\cap\tau_q\ne
 \varnothing$ и $\forall\,  i\in(\tau_p\cap\tau_q)$ имеет место $x_i=y_i,$ то
$R^p_{sim}:=R^p_{sim}\cup\{ (p,q)\} ,$
$R^p_{sim}\subseteq\pi\times\pi$ (отношение сходства)
 (рис.\:\ref{fig:relat_2}).
 \item Если для знака $s_p$ и некоторого знака $s_q$  $\tau_p\cap\tau_q\ne
 \varnothing$ и $\forall\,  i\in(\tau_p\cap\tau_q)$ имеет место $x_i\ne y_i,$
то $R^p_{con}:=R^p_{con}\cup\{ (p,q)\} ,$
$R^p_{con}\subseteq\pi\times\pi$ (отношение противопоставления)
 (рис.\:\ref{fig:relat_3}).
\end{enumerate}

\fig{{sign_relations-01}}{\caption{Определение отношения включения
$R^p_{in}$ на множестве образов}\label{fig:relat_1}}

\fig{{sign_relations-02}}{\caption{Определение отношения сходства
$R^p_{sim}$ на множестве образов}\label{fig:relat_2}}

\fig{{sign_relations-03}}{\caption{Определение отношения
противопоставления $R^p_{con}$ на множестве образов}\label{fig:relat_3}}

По существу, приведенные определения суть процедуры порождения новых элементов
отношений на множестве знаков. Стартуя всякий раз, когда множество знаков
пополняется новым знаком (или когда множество знаков начинает использоваться),
описанные процедуры либо формируют новое отношение, либо пополняют какое"=либо
из отношений на знаках новым элементом. Это означает, что взаимодействие
образов различных знаков приводит к формированию на множестве образов
неоднородной семантической сети \cite{Osipov1990} с четырьмя типами отношений:
эквивалентность образов, включение образов, сходство образов
и противопоставление об\-разов.

Рассмотрим в качестве примера операцию обобщения. Частичная операция
обобщения $\Theta^p$ определена на множестве пар образов, принадлежащих
отношению $R^p_{sim}$; результатом работы $\Theta$ является новый образ,
включающий все общие признаки исходных образов. Пусть $\pi$~--- множество
образов, $p_1,p_2\in\pi,$ $p_1=(x_1,x_2,\ldots,x_g)$
и $p_2=(y_1,y_2,\ldots,y_h),$ тогда $\Theta^p":\pi\times\pi\rightarrow\pi$, так
что для всяких $p_1,p_2\in\pi$, таких что $(p_1,p_2)\in R^p_{sim},$
$\Theta^p(p_1,p_2)=p_3,$ где $p_3=(z_1,z_2,\ldots,z_l)$, так что для $\forall\,
j\ \exists\,  j,k,$ такие что~$z_i=x_j=y_k.$

Построенный в результате выполнения операции обобщения образ может послужить
основой для формирования нового знака. Новый знак образуется аналогично
формированию знака, описанному в п.~\ref{sect:first_def}, с некоторыми
мо\-ди\-фи\-ка\-циями.
\begin{enumerate}
 \renewcommand\labelenumi{\theenumi.}
 \item Порождение на основе прошлого опыта или на основе прецедентов множества
пар вида "<образ~--- значение">~--- значения знака.
 \item Получение субъектом из культурной среды, аккумулированной в системе
естественного языка, пары "<имя знака~--- значение">.
 \item Связывание имени из пары "<имя знака~--- значение"> с образом.
 \item Формирование личностных смыслов знака на основе прецедентов действий
с предметами, описываемыми обобщенным образом.
 \item Связывание имени из пары "<имя знака~--- значение"> со сформированным личностным смыслом.
 \item Продолжение отображения "<личностный смысл~--- образ"> включением
в область определения отображения личностного смысла, полученного
в предыдущем пункте, а в область значений~--- образа, построенного в~п.\:1.
\end{enumerate}

В~результате образуется знак, соответствующий обобщенному образу. При этом пары
образов $(p_3,p_1)$ и $(p_3,p_2)$ пополняют отношение включения $R^p_{in}.$
Новый знак $s_3$ является для знаков $s_1$ и $s_2$ их обобщением по образам
(рис.\:\ref{fg:pattern_gen}).

\fig{{sign_relations-8}}{\caption{Пример обобщения по признакам.
В~результате работы операции обобщения $\Theta^p$ пары знаков $s_1$ и $s_2,$
принадлежащих отношению сходства $R^p_{sim},$ формируется образ $p_3$ нового
знака $s_3$, так что пары $(p_3, p_1)$ и $(p_3, p_2)$ пополняют отношение
включения $R^p_{in}$}\label{fg:pattern_gen}}

\subsubsection{Отношения и операции на множестве личностных смыслов\hbox{}}

Как мы видели, с каждым знаком связан некоторый личностный смысл. На множествах
личностных смыслов различных знаков процедура $\Pi^a$ естественным образом
порождает отношения поглощения, противопоставления и агглютинации (т.\,е.
склеивания, присоединения) смыслов. Определим эти отношения. Пусть по"=прежнему
$S=\{ s_1 s_2,\ldots,s_k\} $~--- множество знаков\hbox{}.

Введем множество действий $ACT$ и функцию $I,$  отображающую множество
личностных смыслов в булеан $2^{ACT}$ множества действий \cite{Osipov2000},
т.\,е. функцию, ставящую
в соответствие каждому личностному смыслу $a$  из $2^A$ некоторое подмножество $act\in ACT$: $I":2^A\rightarrow 2^{ACT}$,
так что для~$\forall\,a\in 2^A I(a)=act,$~$act\in 2^{ACT}\!.$

Для всякого знака $s$ отображение $I$  ставит в соответствие каждому
личностному смыслу $a$  этого знака множество действий $act,$ применимых
к объекту, опосредуемому знаком $s.$ Эту функцию назовем ин\-тер\-пре\-тацией.

Пусть теперь $I(a_1)=(\alpha_1,\alpha_2,\ldots,\alpha_g)$
и $I(a_2)=(\beta_1,\beta_2,\ldots,\beta_h)$~--- интерпретации личностных
смыслов знаков $s_1$ и $s_2.$ Если действие $\alpha_i$ добавляет некоторый
факт \cite{Osipov2000}, а действие $\beta_j$ удаляет тот же
факт \cite{Osipov2000}, то будем говорить, что $\alpha_i$ и $\beta_j$
противопоставлены друг другу и принадлежат отношению ${\perp}\,:=\perp\cup\{
(\alpha_i,\beta_j)\} ,$ ${\perp}\,\subseteq ACT\times ACT$~--- отношению
оппозиции, т.\,е. множеству пар действий, образующих оппозиционные шкалы
в смысле \cite{Kelly1991}.

Определим следующие отношения на множестве личностных смыслов\hbox{}:
\begin{enumerate}
 \item $(a_1,a_2)\in R^a_{sub}$ (читается "<смысл $a_2$ поглощает смысл
$a_1$">), если $I(a_1)\subseteq I(a_2)$ (рис.\:\ref{fig:relat_4});
 \item $(a_1,a_2)\in R^a_{con}$ ("<смысл $a_1$ противопоставлен смыслу
$a_2$">), если $\exists\, \alpha_1\in a_1,$ $\beta_j\in a_2,$ что
$(\alpha_i,\beta_j)\in \perp$ (рис.\:\ref{fig:relat_5});
 \item $(a_1,a_2,a_3)\in R^a_{agg}$~--- трехместное отношение агглютинации
смыслов, если $I(a_1)\cup I(a_2)=I(a_3).$
\end{enumerate}

\fig{{sign_relations-04}}{\caption{Определение отношения поглощения
$R^a_{sub}$ на множестве смыслов}\label{fig:relat_4}}

\fig{{sign_relations-05}}{\caption{Определение отношения
противопоставления $R^a_{con}$ на множестве смыслов}\label{fig:relat_5}}

\subsubsection{Отношения и операции на множестве значений}\label{subsubsect:signif}

Как было сказано выше, значение всякого знака отражает принятые в обществе
способы использования соответствующего знаку предмета и поэтому может
интерпретироваться некоторым действием. Тогда интерпретация значения напрямую
связана с интерпретациями элементов личностного смысла знака. Отметим, что
личностный смысл, в отличие от значения, отражает индивидуальные предпочтения
субъекта, в то время как значение отражает принятые в обществе способы
использования соответствующего знаку предмета. В~лексике языка значение, таким
образом, может отражаться некоторой группой синонимичных предикатных слов:
глаголом, девербативом (т.\,е. отглагольным существительным), причастием,
деепричастием, которые единственным образом характеризуются своим набором
семантических валентностей \cite{Schank1972}.

Пусть $I=\{ i_1,i_2,\ldots,i_q\} $~--- множество всех возможных
семантических валентностей, тогда каждую группу синонимичных предикатных слов
можно характеризовать каким"=либо подмножеством этого множества: $I_m=\{
j_1,j_2,\ldots,j_k\} ,$ $I_m\subseteq I.$ Например, группу предикатных
слов движения ("<ехать">, "<бежать">, "<идти">) можно охарактеризовать набором
семантических валентностей "<субъект">, "<средство">, "<направление движения">,
"<цель">, "<количественная ха\-рак\-те\-ри\-стика">.

Пусть $s$~--- некоторый знак со значением $m.$  Экземпляр $\mu$ значения $m$
знака $s$ выражается, в силу сказанного, некоторым предикатным словом
и семантической валентностью. Это обстоятельство будем обозначать следующим
образом: $\mu(I_m,i),$ где $\mu\in m$~--- экземпляр значения знака $s$  и $i\in
I_m$~--- семантическая валентность предикатного слова, характеризуемого
набором $I_m.$  На рис.\:\ref{fg:mean_scene} приведен пример знака $s,$
значение $m$ которого включает два экземпляра: $\mu_1(I_1,i_3)$
и~$\mu_2(I_2,j_2).$

\fig{{sign_relations-09}}{\caption{Пример структуры значения $m$
знака $s,$ который включает в себя два экземпляра, $\mu_1(I_1, i_3)$
и $\mu_2(I_2, j_2),$ где $I_1=\{ i_1,i_2,i_3\} $ и $I_2=\{
j_1,j_2,j_3,j_4\} $~--- наборы семантических
валентностей}\label{fg:mean_scene}}

Рассмотрим знаки $s_1$  и $s_2$; $\mu_1(I_1,i)$ и $\mu_2(I_2,j)$~--- экземпляры
значений $s_1$  и $s_2$ соответственно. Введем процедуру $\Pi^m\!,$ которая для
всякого знака $s_1$ просматривает все остальные знаки и пополняет указанные
ниже отношения по следующим пра\-вилам.
\begin{enumerate}
 \renewcommand\labelenumi{\theenumi.}
 \item Если $I_1=I_2$ и $i=j,$ то $R^m_{eq}:=R^m_{eq}\cup\{
 (\mu_1,\mu_2)\} ,$ $R^m_{eq}\subseteq M\times M.$
 \item Если для экземпляра значения $\mu_1$ знака $s_1$ существует экземпляр
значения $\mu_2$ знака $s_2$, такой что $I_1\cap I_2\ne \varnothing,$
$I_1\ne I_2$ и $i=j,$ то $R^m_{sim}:=R^m_{sim}\cup\{
 (\mu_1,\mu_2)\} ,$ $R^m_{sim}\subseteq M\times M.$
 \item Если для экземпляра значения $\mu_1$ знака $s_1$ существует экземпляр
значения $\mu_2$ знака $s_2$, такой что $I_1=I_2,$ и $i\ne j,$ то
$R^m_{sit}:=R^m_{sit}\cup\{ (\mu_1,\mu_2)\} ,$ $R^m_{sit}\subseteq
 M\times M$~--- ситуационное отношение.
\end{enumerate}
Аналогично отношениям $R^p_{eq}$ и $R^p_{sim}$ отношения $R^m_{eq}$
и $R^m_{sim}$ являются соответственно отношениями эквивалентности и сходства на
множестве зна\-чений.

С~каждым экземпляром значения $\mu$ свяжем теперь метку $\tau$ и будем
записывать: $\mu_1(\tau_1,I_1,i)$ и $\mu_2(\tau_2,I_2,j).$ На множестве меток
вводится линейный порядок: для $\forall\, \tau_1,\tau_2$ справедливо
$\tau_1\le\tau_2$ либо $\tau_1\ge\tau_2.$ Рассмотрим некоторое отношение на
$M\times M.$ Ограничение этого отношения на $M_{scen}\times M_{scen},$ где
$M_{scen}\subseteq M,$ будем называть сценарным отношением $R^m_{sc},$ если оно
строится следующим об\-разом.
\begin{enumerate}
 \setcounter{enumi}{3}
 \renewcommand\labelenumi{\theenumi.}
 \item Если $\mu_1\in M_{scen},$ $\mu_2\in M_{scen},$ $I_1\ne I_2,$ $i\ne j$
и $\tau_1<\tau_2,$ то $R^m_{sc}:=R^m_{sc}\cup\{ (\mu_1,\mu_2)\} .$
\end{enumerate}

Элементарным сценарием, порожденным знаком $s,$ будем называть множество
экземпляров значений $M_{est}(s)$, такое что для $\forall\, \mu_1\in M_{est}(s)$
и $\mu_2\in M_{est}(s)$\hbox{}
\begin{itemize}
 \item если $\mu_1\in m,$ $\mu_2\in m$ и $\tau_1\ge\tau_2,$ то
$(\mu_1,\mu_2)\in R_sc^m$ (в~этом случае сценарное отношение $R^m_{sc}$
определено на множестве экземпляров значения знака $s,$ т.\,е.
$M_{scen}=m$);
 \item если $\mu_1\in m$ и $\mu_2\not\in m$ и $\tau_1\ge\tau_2,$ то $(\mu_1,\mu_2)\in R^m_{sit}.$
\end{itemize}

На рис.\:\ref{fg:mean_relat} приведен пример элементарного сценария
$M_{est}(s_1),$ порожденного знаком $s_1,$ а именно сформированного двумя
экземплярами $\mu_2$ и $\mu_3$ значения знака $s_1$, такими что
$(\mu_2,\mu_3)\in R^m_{sc}.$ В~примере на рис.\:\ref{fg:mean_relat}
в $M_{est}(s_1)$ входят и экземпляры значений $\mu_1$ и $\mu_4$, такие что $\{
(\mu_1,\mu_2),(\mu_3,\mu_4)\} \subseteq R^m_{sit},$ где $\mu_1$ и $\mu_4$ суть
экземпляры значений знаков $s_2$ и $s_3$ со\-от\-вет\-ственно.

\fig{{sign_relations-10}}{\caption{Пример элементарного сценария
$M_{est}(s_1)=\{ \mu_1,\mu_2,\mu_3,\mu_4\} ,$ порожденного значениями
знака $s_1.$ Так как в приведенном примере пары экземпляров значений
$(\mu_1,\mu_2)$ и $(\mu_3,\mu_4)$ принадлежат отношению $R^m_{sit},$ а пара
$(\mu_2,\mu_3)$~--- отношению $R^m_{sc},$ то по определению эти экземпляры
принадлежат элементарному сценарию $M_{est}(s_1)$}\label{fg:mean_relat}}

\section{Структурный уровень модели: динамика}\label{sect:automato}

Введем структурный уровень описания модели картины
мира с использованием формализма теории автоматов. Данное описание строится
с использованием ряда существенных упрощений, призванных облегчить изложение
и позволяющих сконцентрироваться на изучении основных свойств возникающих
математических объектов. В~начале будет дано структурное определение образной
компоненты и процедуры ее функционирования в процессе восприятия, а затем будут
введены описания остальных компонент знака, синтаксические определения которых
давались в разделе \ref{sect:first_def}. В~конце раздела дано описание одной из
основных функций картины мира~--- процедуры образования нового знака на
структурном уровне~--- и приведены результаты исследования процесса формирования
и связывания образа и значения нового знака\hbox{}.

\subsection{Образная компонента знака}\label{subsect4_2_1}

\subsubsection{Основные принципы работы образной компоненты} \label{subsubsect4_2_1_1}

Далее будем рассматривать модель образной компоненты знака, которая возникает
при описании моделей зрительного восприятия, построенных на следующих основных
прин\-ципах:
\begin{enumerate}
 \item иерархичность,
 \item реализация функции выдвижения перцептивных гипотез,
 \item реализация способности распознавать как динамические, так и статические явления,
 \item управляемость.
\end{enumerate}

Эти принципы согласуются с выводами, сделанными при анализе существующей
литературы по нейрофизиологическим данным (см.~п.~\ref{sect:neuro}).
Приведем обоснование выбора именно этих свойств в качестве базовых для
построения структурного уровня модели~КМ.

Первый принцип был выдвинут в работах когнитивных психологов А.~Трисман
(A.\,M.~Triesman) и Дж.~Джелед (G.~Gelade) \cite{Triesman1980} и заключается
в том, что на уровне работы сетчатки имеется набор базовых признаков или
протобъектов (на уровне вторичных зрительных отделов коры головного мозга)
\cite{Rensink2000}, из которых в процессе научения образуются более сложные
признаки. Из полученных сложных признаков строятся еще более сложные и~т.\,д.
При этом процесс восприятия представляет собой последовательную активацию части
получающейся иерархии начиная с базовых признаков и заканчивая сложным
объектом, предъявляемым зрительной системе. Основным критерием принадлежности
разных признаков одному объекту (сложному признаку) является пространственная
и временная когерентность. Иерархичность процесса восприятия как одного из
процессов, протекающих в картине мира, проявляется также и в функциональной
иерархичности коры головного мозга, что подтверждается большим количеством
нейрофизиологических данных \cite{Hawkins2009,Bolotova2011}.

Основной задачей образной компоненты на каждом уровне иерархии, таким образом,
становится выявление в поступающем наборе сигналов и низкоуровневых при\-знаков повторяющихся временных и пространственных шаблонов.

По данными анализа движения глаз испытуемых доказано, что любой процесс
восприятия как динамического, так и статического явления представляет собой
развернутый во времени процесс, каждый этап которого с той или иной степенью
точности предсказывается на основе предыдущих
этапов \cite{Velichkovsky2006a,Hawkins2009}. Именно в этом заключается второй
принцип: модель элемента картины мира должна включать в себя процессы
выдвижения гипотез о том, какая часть иерархии признаков будет активирована
в следующий момент времени\hbox{}.

Третий принцип определяет важность параметра времени: образная компонента
должна с самого начала уметь работать с меняющимися во времени признаками, не
выделяя явно случай статического изображения. Наконец, четвертый принцип
основан на теории активного зрения и том факте, что каждый этап распознавания
признака на каком"=либо уровне иерархии в процессе восприятия чередуется
с активным этапом моторной реакции. Особенно ярко этот факт проявляется
в случае зрительного восприятия при наблюдении саккадических движений глаза\hbox{}.

С учетом перечисленных принципов, на которых строится большинство существующих
моделей восприятия (не только зрительного), в следующем разделе вводится
определение распознающего автомата, являющегося основным структурным элементом
как образной, так и других компонент знака (рис.\:\ref{fg:sign_rb}). Далее
приводится алгоритм работы образной компоненты, исследуются его свойства путем
постановки ряда задач рас\-по\-зна\-вания.

\fig{{sign_details2_ru}}{\caption{Знак и его компоненты}\label{fg:sign_rb}}

\subsubsection{Распознающий автомат} \label{subsect:recogn_block}
Рассмотрим автомат $R_i^j$ вида $\<A,Q,B,\varphi,\eta\>$ с множествами
входов $A,$ выходов $B$, состояний $Q$ и определенными в соответствии
с нейрофизиологическими данными функциями переходов $\varphi$
и выходов $\eta.$ Такой автомат будем называть \textit{распознающим автоматом}
уровня $j$ с индексом $i$ или просто $R$"~автоматом. Опишем кратко его
автоматную функцию \cite{Kudryavtcev1985}, а затем определим алгоритм его
работы формально. Для этого воспользуемся понятием \textit{признака}, который
будем понимать как составную часть информационного представления некоторой
сущности, явления или процесса \cite{Vapnik1974}.

Каждый распознающий автомат распознает или, применительно к~низкоуровневым
сигналам, измеряет некоторые признаки на основе входного вектора данных.
Процесс распознавания (измерения) заключается в установлении соответствия признака и числа, определяющего оценку успешности построения (измерения) признака из
составляющих его входных признаков, информация о которых содержится во входном
векторе. Такое число будем называть \textit{весом при\-знака}.

Входной вектор, в свою очередь, представляет собой вектор весов признаков
предыдущего уровня иерархии, по которым распознаются выходные признаки.
Распознающий автомат обладает множеством состояний, каждое из которых
представляет собой набор бинарных матриц, каждый столбец которых задает
ожидание входных признаков в следующий момент времени. Такие матрицы будем
называть \textit{каузальными матрицами}. Опишем выше изложенное более строго\hbox{}.

Пусть заданы множества $\mathcal R$ и $\mathcal F.$ Множество $\mathcal R$
будем называть совокупностью распознающих автоматов, а множество $\mathcal
F$~--- совокупностью допустимых признаков. Введем бинарное отношение $\dashv,$
определенное на паре множеств $\mathcal F$ и $\mathcal R,$ и будем читать
$f_k\dashv R_i^j,$ $f_k\in\mathcal F,$ как "<признак $f_k$ распознается
$R$"~автоматом $R_i^j$"> или как "<признак $f_k$ измеряется $R$"~автоматом
$R_i^j$">. Множество всех распознаваемых $R$"~автоматом $R_i^j$ признаков
будем обозначать $F_i^{*j},$ т.\,е.~${\forall\, }f^*{\in}F_i^{*j}
f^*{\dashv}R_i^j,$~$F_i^{*j}{\subseteq}\mathcal F.$

Рассмотрим связный ориентированный (ярусный) граф $G_R=(V,E),$ где $V=\mathcal
R$~--- множество вершин, $E\subset \mathcal R\times \mathcal R$~--- множество
ребер. Каждая вершина $v,$ принадлежащая $j$"~му ярусу графа $G_R,$ является
распознающим автоматом $R_{i_1}^{j_1}$ уровня $j_1,$ а ребро
$e=(R_{i_1}^{j_1},R_{i_2}^{j_2}){\in}E$ обозначает иерархическую связь между
$R$"~автоматом $R_{i_1}^{j_1}$ и $R$"~автоматом $R_{i_2}^{j_2}.$ $R$"~автомат
$R_{i_1}^{j_1}$ в данном случае будем называть дочерним, а $R$"~автомат
$R_{i_2}^{j_2}$~--- родительским (рис.\:\ref{fg:rb_hier}).

\fig{{rb_hierarchy}}{\caption{Пример иерархии распознающих
автоматов. Так, узел $R_{i_2}^{j_2}$ является родительским распознающим
автоматом, а узел $R_{i_1}^{j_1}$~--- дочерним автоматом}\label{fg:rb_hier}}

Рассмотрим распознающий автомат $R_i^j.$ Определим множество
$F_i^j{\subseteq}\mathcal F$ таких признаков, что для любого $f{\in}F_i^j$
существует распознающий автомат $R_k^{j-1}$ уровня $j-1,$ дочерний по отношению
к $R$"~автомату $R_i^j,$ такой что $f{\dashv}R_k^{j-1}.$ Такое
множество $F_i^j$ будем называть совокупностью входных признаков распознающего
автомата $R_i^j.$ Некоторые части векторов весов выходных признаков
распознающих автоматов $R_{i_1}^j,R_{i_2}^j,\ldots,R_{i_q}^j$ за счет
конкатенации составляют вектор весов входных признаков для родительского
автомата $R_k^{j+1}$ следующего уровня иерархии\hbox{}.

Для каждого признака $f^*{\in}F_i^{*j}$ введем функцию распознавания $\hat
f":X\rightarrow\mathbb R,$ $\hat{f}(x_1,\ldots,x_q )=x^*\!,$ где $x^*{\in}[0,
1]$~--- вес распознаваемого признака $f^*$ в выходном векторе,
а $x_1,\ldots,x_q{\in}[0, 1]$~--- веса признаков из множества $F_i^j$
в текущем входном векторе. Множество таких функций для распознающего
автомата $R_i^j$ обозначим $\hat{F}_i^j.$

Пусть мощность множества распознаваемых признаков $F_i^{*j}$ и множества
функций распознавания $\hat{F}_i^j$ равна $l_i^j,$ а мощность множества
входных признаков $F_i^j$ равна $q_i^j.$ Введем упорядоченное множество
локальных моментов времени $T_i^j$ для распознающего автомата $R_i^j.$ Будем
называть \textit{вычислительным циклом} полуинтервал между соседними моментами
времени поступления сигналов обратной связи с верхнего уровня иерархии
(см.~ниже). Для каждого распознающего автомата определим характерное
время $h_i^j,$  за которое выполняется один цикл вы\-чис\-ления.

В~начале $s$"~го цикла вычисления (момент времени $\tau_s\in{T_i^j}$)
распознающий автомат $R_i^j$ получает на вход вектор длины $l_i^j$ ожиданий
$\hat{x}_i^{j+1}(\tau_s),$ вычисляемый по формуле среднего от векторов
ожиданий, поступающих от родительских относительно $R$"~автомата $R_i^j$
распознаю\-щих автоматов~$R_k^{j+1}$:
\[!E
 \hat{x}_i^{j+1}(\tau_s)=\frac{1}{N_i^j}\ssum_{k{\in}K_i^{j+1}}\hat{x}_k^{j+1}(\tau_s),
\]
где $N_i^j$~--- количество родительских $R$"~автоматов, $K_i^{j+1}$~---
множество индексов родительских относительно $R_i^j$ распознающих автоматов.
Далее в~каждый момент времени $t\in{T_i^j},$ $\tau_s\le{t}\le\tau_s+h_i^j,$
распознающий автомат $R_i^j$ получает на~вход вектор весов $\olitco{x}_i^j(t)$
входных признаков из~множества $F_i^j$  длины $l_i^j,$  вычисляет выходной
вектор весов $\olitco{x}_i^{*j}(t)$ распознаваемых признаков из~множества
$F_i^{*j}$ длины $l_i^j,$ вычисляет вектор ожиданий $\hat{x}_i^j(t)$ входных
признаков в следующий момент времени длины $q_i^j$ (рис.\:\ref{fg:rb_cycle}).
Параметр $h_i^j,$ таким образом, служит характеристикой глубины памяти
$R$"~ав\-томата.

\fig{{rb_cycle_simple}}{\caption{Вычислительные циклы распознающего
автомата. Индексы $i$ и $j$ опущены, верхний уровень обозначен с индексом
${+}.$ В~моменты времени $0,h,2h,{\ldots}$ происходит определение нового
начального состояния}\label{fg:rb_cycle}}

\subsubsection{Алгоритм $\mathfrak A_{\op{th}}$ работы распознающего
автомата}\label{subsubsect:rb_algorithm}

Будем рассматривать распознающий автомат $R_i^j$ как автомат с конечным
множеством состояний. Для этого каждой функции распознавания $\hat{f}_k$ из
множества $\hat{F}_i^j$ будем ставить в соответствие набор \textit{каузальных
матриц} $Z_k=\{ Z_1^k,\ldots,Z_m^k\} $ размерности $q_i^j\times h_i^j,$ где
$h_i^j$~--- характерное время распознающего автомата $R_i^j.$ Столбец
$\olitco{z}_u^r=(z_{u1}^k,\ldots,z_{uq}^k)$ матрицы $Z_r^k$ интерпретируется
как вектор предсказания присутствия входных признаков из множества $F_i^j$
в момент времени $\tau_s+u,$ при этом $z_{uv}^k\in\{ 0,1\} ,$ т.\,е. вектор
$\olitco{z}_u^r$ является булевым вектором. Сама матрица $Z_r^k$ задает, таким
образом, последовательность событий, наличие которых свидетельствует
о~присутствии распознаваемого функцией $\hat{f}_k$ признака. Множество всех
каузальных матриц распознающего автомата $R_i^j$ будем обозначать
$\mathcal{Z}_i^j.$

Таким образом, $R$"~автомат $R_i^j$ является бесконечным автоматом Мили
с переменной структурой и конечной памятью и определяется следующим набором:
$R_i^j=<X_i^j\times \hat{X}_i^{j+1},$ $2^{\mathcal Z_i^j}, X_i^{*j}\times
\hat{X}_i^j,$ $\varphi_i^j,\overrightarrow\eta_i^j,>,$~где
\begin{itemize}
 \item $X_i^j$~--- множество входных сигналов (пространство векторов
длины $q_i^j$ действительных чисел от $0$ до $1$),
 \item $X_i^{*j}$~--- множество выходных сигналов (пространство векторов
длины $l_i^j$ действительных чисел от $0$ до $1$),
 \item $\hat{X}_i^{j+1}$~--- множество управляющих сигналов с верхнего уровня
иерархии (пространство векторов длины $l_i^j$ действительных чисел от $0$
до $1$),
 \item $\hat{X}_i^j$~--- множество управляющих сигналов на нижний уровень
иерархии (пространство векторов длины $q_i^j$ действительных чисел от $0$
до $1$),
 \item $2^{\mathcal Z_i^j}$~--- множество состояний (множество подмножеств
множества каузальных матриц),
 \item $\varphi_i^j:X_i^j\times \hat{X}_i^{j+1}\to 2^{\mathcal Z_i^j}$~--- функция переходов,
 \item $\overrightarrow\eta_i^j:2^{\mathcal Z_i^j} \to X_i^{*j}\times
 \hat{X}_i^j$~--- вектор"=функция выходов.
\end{itemize}

Для удобства определения автоматной функции обозначим \textit{входное
воздействие} через $\omega_i^j:T{\to}X_i^j,$ а \textit{выходную величину} через
$\gamma_i^j:T{\to}X_i^{*j}$, как это принято в~теории динамических
систем \cite{Kalman1971} (рис.\:\ref{fg:rb_io}).

\fig{{rb_io}}{\caption{Схема входных и выходных отображений
распознающего автомата}\label{fg:rb_io}}

На страницах \pageref{alg:th_init} и \pageref{alg:th_cycle} приведен алгоритм
$\mathfrak{A}_{\op{th}}$ вычислительного цикла распознающего $R$"~автомата,
в котором рассчитываются значения функции переходов
$\varphi_i^j(\hat{x}_i^{j+1}(\tau_s+t),\omega_i^j),$ $1\le{t}\le h_i^j-1,$
и выходной функции $\overrightarrow\eta_i^j(\mathcal Z_i^{*j}(\tau_s+t)),$
$1\le{t}\le h_i^j-1,$ $\mathcal Z_i^{*j}(\tau_s+t)$~--- текущее состояние.
В~алгоритме используется функция $W$ нормировки весовых зна\-чений:
\[!E
 W(\olitco x)=\bleft(\frac{x_1}{\max\limits_i x_i},\ldots,\frac{x_n}{\max\limits_i x_i}\right)\!,
\]
где $\olitco x=(x_1,\ldots,x_n)$~--- вектор с ненормированными компонентами.
Кратко опишем шаги ал\-го\-ритма.

Вычислительный цикл распознающего автомата начинается с определения начального
состояния при~помощи управляющего воздействия с верхних уровней иерархии~---
вектора ожиданий $\hat x_i^{j+1}(\tau_s)$
(шаги \ref{alst:init_start}--\ref{alst:init_end}). Начальное состояние
определяется как подмножество таких распознаваемых признаков множества
$F_i^{*j},$ которые предсказываются на основе состояния $R$"~автоматов верхнего
уровня. Первая константа $c_1$  определяет порог предсказываемого веса
распознаваемых признаков, выше которого соответствующие функции распознавания
попадают во множество активных функций $\hat F^*$ (шаг \ref{alst:select_f}).
Далее производится отбор тех матриц предсказания активных функций
распознавания, для которых обычное расстояние по норме $\|x\|=\ssum_i |x_i|$
первого столбца $\olitco z_1^r$ от входного вектора $\olitco x_i^j$ в начальный
момент времени не превышает второй константы $c_2$ (шаг \ref{alst:select_z}).
Множество полученных таким образом активных каузальных матриц и является
текущим состоянием распознающего автомата (шаг \ref{alst:init_state}).
На основе активных каузальных матриц методом голосования вычисляется выходной
вектор в начальный момент времени $\olitco x_i^{j*}(\tau_s)$
(шаги \ref{alst:init_calc_out2}"~~\ref{alst:init_calc_out3}).

\begin{algorithm}[h]
 \caption{Алгоритм $\mathfrak{A}_{\op{th}}$ (часть~I, задание начального
состояния)}\label{alg:th_init}
 \begin{algorithmic}[1]
 \Require $\tau_s, \hat{x}_i^{j+1}(\tau_s), \omega_i^j.$
 \vspace*{.5ex}\Ensure $\varphi_{i\Delta t}^j, \overrightarrow\eta_{i\Delta t}^j.$

 \State $\hat{F}^*=\varnothing,$ $Z^*=\varnothing,$ $t=0$; \Comment{активные
функции распознавнаия и каузальных матрицы}
 \State $c_1\in(0,1),$ $c_2\in(0,1)$; \Comment{пороговые кон\-станты}

 \Statex \Comment{определение начального со\-стояния}

 \ForAll{компонент $\hat{x}_{ik}^{j+1}$ вектора
$\hat{x}_i^{j+1}(\tau_s)=(\hat{x}_{i1}^{j+1},\hat{x}_{i2}^{j+1},\ldots,\hat{x}_{il}^{j+1})$}
 \label{alst:init_start}
 \If{$\hat{x}_{ik}^{j+1}{\ge}c_1$} \label{alst:select_f}
 \State $\hat{F}^*:=\hat{F}^*\cup\{ \hat{f}_k\} $;
 \EndIf
 \EndFor

 \State $\olitco x_i^j:=\omega_i^j(\tau_s)$;

 \ForAll{функций распознавания $\hat{f}_k\in\hat{F}^*$}
 \ForAll{$Z_r^k\in Z_k,$ соответствующих функции распознавания $\hat{f}_k$,}
 \If{$\frac{\|\olitco{z}_1^r-\olitco{x}_i^j\|}{\|\olitco{z}_1^r\|+\|\olitco{x}_i^j\|}<c_2$}
 \label{alst:select_z}
 \State $Z^*:=Z^*\cup\{ Z_r^k\} $;
 \EndIf
 \EndFor
 \EndFor

 \State $\varphi_i^j(\olitco x_i^j,\hat{x}_i^{j+1}(\tau_s)) := Z^*$;
 \Comment{значение функции переходов в начальный момент
времени}\label{alst:init_state}
 \State $\olitco N:=(|\{ Z_r^1|Z_r^1\in Z^*\} |,\ldots,|\{
 Z_r^{l_i^j}|Z_r^{l_i^j}\in Z^*\} |)$; \label{alst:init_calc_out2}
 \State $\eta(Z^*)=\olitco{x}_i^{*j}:=W(\olitco N)$; \Comment{значение
функции выходов в начальный момент времени} \label{alst:init_calc_out3}
 \State $\hat x_i^j=W\bigl(\ssum_{\hat f_k\in\hat F^*}\hat
 x_{ik}^{j+1}\ssum_{Z_r^k\in Z^*}\olitco z_2^r\bigr)$;\label{alst:init_control}
 \label{alst:init_end}
 \algstore{algst:store1}
 \end{algorithmic}
\end{algorithm}

Вектор управления $\hat x_i^j(\tau_s+1)$ определяется как нормированный вектор,
$s$"~я компонента которого равна сумме всех $s$"~х элементов вторых колонок
активных каузальных матриц с весами, соответствующими элементам вектора
ожиданий $\hat x_i^{j+1}(\tau_s)$ (шаг \ref{alst:init_control}). Так как
используется представление о будущем входном сигнале (вторая колонка каузальных
матриц), то $\hat x_i^j(\tau_s+1)$ играет роль предсказывающего вектора для
нижних уровней иерархии\hbox{}.

После определения начального состояния начинает выполняться тело основного
цикла, в котором вычисление выходного вектора
и состояния в следующий момент времени повторяется до тех пор, пока время не превысит характерное время
распознающего автомата $h_i^j$ 
(шаги \ref{alst:cycle_start}--\ref{alst:cycle_end}). В~начале обновляется
состояние, т.\,е. множество активных каузальных матриц $Z^*\!,$ за счет удаления
тех матриц, соответствующие столбцы которых достаточно сильно отличаются от
текущего входного вектора $\olitco x_i^j$ (шаг \ref{alst:update_z}). Далее
методом голосования по количеству матриц в множестве активных каузальных
матриц, отвечающих за соответствующий выходной признак, вычисляется выходной
вектор $\olitco x_i^{j*}$ (шаги \ref{alst:calc_out1}--\ref{alst:calc_out3}).

\begin{algorithm}[h]
 \caption{Алгоритм $\mathfrak{A}_{\op{th}}$ (часть \rim{II}, основной цикл)}\label{alg:th_cycle}
 \begin{algorithmic}[1]
 \algrestore{algst:store1}
 \Statex \Comment{основной цикл\hbox{}}

 \State $t=1$;
 \While{$t\le{h_i^j}-1$} \label{alst:cycle_start}
 \State~$\olitco{x}_i^j:=\omega(\tau_s+t)$;

 \ForAll{каузальных матриц $Z_r^k$ из множества $Z^*$}
 \If{$\frac{\|\olitco{z}_{t+1}^r-\olitco{x}_i^j\|}{\|\olitco{z}_{t+1}^r\|+\|\olitco{x}_i^j\|}\ge{c_2}$}
 \label{alst:update_z}
 \State $Z^*:=Z^*\setminus\{ Z_r^k\} $;
 \EndIf
 \EndFor

 \State $\varphi_i^j(\olitco x_i^j,\hat{x}_i^{j+1}(\tau_s)) := Z^*$;
 \Comment{значение функции переходов в момент времени $t$}
 \State $\olitco N=(|\{ Z_r^1|Z_r^1\in Z^*\} |,\ldots,|\{
 Z_r^{l_i^j}|Z_r^{l_i^j}\in Z^*\} |)$; \label{alst:calc_out1}
 \State $\eta(Z^*)=\olitco{x}_i^{*j}:=W(\olitco N)$;\Comment{значение
функции выходов в момент времени $t$} \label{alst:calc_out3}

 \State $t=t+1$;
 \If{$t\le{h}_i^j-2$}
 \State $\hat{x}_i^j:=W\bigl(\ssum_{\hat f_k\in\hat F^*}\hat
 x_{ik}^{j+1}\ssum_{Z_r^k\in Z^*}\olitco z_t^r\bigr)$; \label{alst:calc_state1}
 \EndIf
 \EndWhile \label{alst:cycle_end}

 \Return $\varphi_{i\Delta t}^j,\overrightarrow\eta_{i\Delta t}^j.$
 \end{algorithmic}
\end{algorithm}

В~завершение тела основного цикла вычисляется выходной управляющий вектор
ожиданий в следующий момент времени: $\hat x_i^j(\tau_s+t+1).$ Как и на этапе
определения начального состояния, вектор ожиданий равен нормированному вектору,
элементы которого равны сумме элементов столбцов всех активных каузальных
матриц, соответствующих текущему моменту времени с учетом весов начального
управляющего вектора $\hat x_i^{j+1}(\tau_s)$ (шаг \ref{alst:calc_state1}).

\subsection{Исследование алгоритма $\mathfrak A_{\op{th}}$ работы образной
компоненты}\label{subsect4_5}

Для обоснования корректности сформулированного алгоритма работы образной
компоненты знака в данном параграфе будет поставлен рад задач распознавания
(классификации) и построено семейство операторов распознавания. Корректность
алгоритма будет продемонстрирована исходя из корректности линейных замыканий
множеств построенных операторов рас\-по\-зна\-вания.

\subsubsection{Статическая задача классификации}

В~начале рассмотрим статический случай, т.\,е. зафиксируем момент времени $t,$
равный началу некоторого $s$"~го вычислительного цикла $\tau_s.$ В~этом
случае распознающий автомат $R_i^j$ можно рассматривать как
\textit{статический оператор распознавания} $R_i^j(\hat
x_i^{j+1}(\tau_s),\mathcal Z_i^j,\olitco x_i^j(\tau_s))=R_i^j(\hat
x_i^{j+1},\mathcal Z_i^j,\olitco x_i^j)=\olitco{x}_i^{*j}.$ Напомним, что
$\olitco{x}_i^{*j}$~--- это вектор весов распознаваемых признаков
$f_1^*,\ldots,f_l^*$ из множества $F_i^{*j}.$ Далее кратко будем записывать
$R^0(\hat{x},\mathcal{Z},\olitco{x})=\olitco{x}^{\,*}$ и везде, где это
возможно, будем опускать индексы $j$ и~$i.$

Введем совокупность задач $\mathcal Q^0$ аналогично работам
Ю.\,И.~Журавлева \cite{Zhuravlev1977}. Задача
$Q^0(\hat{x},\olitco{x},\alpha_1,\ldots,\alpha_l)\in\mathcal Q^0$ состоит
в построении оператора, вычисляющего по поступившему вектору ожиданий $\hat{x}$
и входному вектору $\olitco{x}$ значения $\alpha_1,\ldots,\alpha_l\in\{
0,1\} $ присутствия признаков $f_1^*,\ldots,f_l^*.$ Другими словами,
искомый алгоритм $A^{0*}$ переводит набор $(\hat{x},\olitco{x})$ в вектор
$\bar{\alpha}=(\alpha_1,\ldots,\alpha_l),$ который будем называть
\textit{информационным вектором} входного вектора $\olitco{x}$
(рис.\:\ref{fg:rb_correct_stat0}).

\wfig{{rb_correct-0}}{\caption{Статическая схема корректности для
момента времени $\tau_s$}\label{fg:rb_correct_stat0}}

Пусть множество $\mathcal A^0$ состоит из алгоритмов, переводящих пары
$(\hat{x},\olitco{x})$ в векторы $\bar{\beta},$ составленные из элементов
$0,1,\Delta:A(\hat{x},\olitco{x})=\bar{\beta}.$ Если $\beta_i\in\{
0,1\} ,$ то $\beta_i$~--- значение величины $\alpha_i,$  вычисленное
алгоритмом $A.$ Если $\beta_i=\Delta,$ то алгоритм $A$ не вычислил
значение $\alpha_i$ информационного вектора~$\bar\alpha.$

\begin{Def}
Алгоритм $A^0$ называется корректным для задачи $Q^0\!,$ если выполнено ра\-венство
 \[!E
 A^0(\hat{x},\olitco{x})=\bar{\alpha}.
\]
Алгоритм $A,$ не являющийся корректным для $Q^0\!,$ называется некорректным.
\end{Def}

Далее будем считать, что множество $\mathcal A^0$ является совокупностью,
вообще говоря, некорректных ал\-го\-ритмов.

\begin{Pred}[о введении пространства оценок]
 {\unct\label{pred:decompositon}}Каждый алгоритм $A^0\in\mathcal A^0$
представим в виде последовательности выполнения алгоритмов $R^0$ и $C^0\!,$ где
$R^0(\hat{x},\olitco{x})=\olitco{x}^{\,*},$ $\olitco{x}^{\,*}$~--- вектор
действительных чисел, $C^0(\olitco{x}^{\,*})=\bar{\beta},$ $\beta_i\in\{
 0,1,\Delta\} .$
\end{Pred}
%

\begin{Proof}
Пусть $D$~--- алгоритм перехода вектора $\bar{\beta}$ к числовому вектору
$\olitco{y}.$ В~качестве $D$  можно рассмотреть, например, $y_i=\beta_i,$
если $\beta_i\in\{ 0,1\} ,$ и $y_i=1/2,$ если $\beta_i=\Delta.$
Очевидно, что существует обратный алгоритм $D^{-1}$ перехода от $\olitco{y}$
к $\bar{\beta}.$ Положим $R^0=A^0\cdot D,$ $C^0=D^{-1}.$ Тогда очевидно, что
$A^0=R^0\cdot C^0=(A^0\cdot D)\cdot D^{-1}=A^0.$
\end{Proof}

Из утверждения \ref{pred:decompositon} следует, что множество алгоритмов
$\mathcal A^0$ порождает множества $\mathcal R^0$ и $\mathcal C^0\!,$ которые
будем называть \textit{множеством операторов распознавания} и \textit{множеством решающих правил} соответственно. В~качестве операторов из
множества $\mathcal R^0$ будем рассматривать операторы~$R^0(\hat x,\mathcal
Z,\olitco x).$

\begin{Def}
Решающее правило $C^{0*}$ называется корректным на множестве входных
векторов $X,$ если для всякого вектора $\olitco x$ из $X$ существует хотя
бы один числовой вектор $\olitco x^{\,*}$, такой что $C^{0*}(\olitco
 x^{\,*})=\bar\alpha,$ где $\bar\alpha$~--- информационный вектор входного
вектора $\olitco x.$
\end{Def}

В~множестве операторов $\mathcal R^0$ введем операции умножения на скаляр,
сложения и умножения. Пусть $r'$~--- скаляр, $R',R''\in\mathcal R^0\!.$ Определим
операторы $r'\cdot R',$ $R'+R''$ и $R\cdot R''$ следующим об\-разом:
\[!E
 \label{eq:oper_scalar}
 r'{\,\cdot\,}R'=(r'{\,\cdot\,}{x_1^*}',\ldots,r'{\,\cdot\,}{x_l^*}'),
\]
\[!E
 \label{eq:oper_sum}
 R'+R''=({x_1^*}'+{x_1^*}'',\ldots,{x_1^*}'+{x_l^*}''),
\]
\[!E
 \label{eq:oper_mult}
 R'{\,\cdot\,}R''=({x_1^*}'{\,\cdot\,}{x_1^*}'',\ldots,{x_1^*}'{\,\cdot\,}{x_l^*}'').
\]

\begin{Pred}
Замыкание $L(\mathcal R^0)$ множества $\mathcal R^0$ относительно операций
 {\unct\eqref{eq:oper_scalar}} и {\unct\eqref{eq:oper_sum}} является векторным
пространством.
\end{Pred}

\begin{Def}
Множество $L(\mathcal A^0)$ алгоритмов $A^0=R^0\cdot C^{0*}$, таких что
$R^0\in L(\mathcal R^0),$ называется линейным замыканием множества~$\mathcal
 A^0\!.$
\end{Def}

Зафиксируем пару $(\hat{x},\olitco{x})$ вектора ожидания и входного вектора.
Аналогично \cite{Zhuravlev1977} будем рассматривать задачи
$Q^0(\hat{x},\olitco{x}),$ обладающие следующим свойством относительно
множества операторов распознавания~$\mathcal R^0\!.$

\begin{Def}
Если множество векторов $\{ R^0(\hat{x},\olitco{x})|R^0\in\mathcal
 R^0\} $ содержит базис в пространстве числовых векторов длины $l,$ то
задача $Q^0(\hat x,\olitco x,\bar\alpha)$ называется полной относительно
$\mathcal R^0\!.$
\end{Def}

\begin{Pred}[о корректности линейного замыкания]
 {\unct\label{pred:correctness}}Если множество задач $\mathcal Q^0$ состоит
лишь из задач, полных относительно $\mathcal R^0\!,$ то линейное замыкание
$L(\{ R^0\cdot C^{0*}|R^0\in\mathcal R^0\} )$ ($C^{0*}$~---
произвольное фиксированное корректное решающее правило) является корректным
относительно $\mathcal Q^0\!.$
\end{Pred}
%

\begin{Corollary}
Пусть $\mathcal A^0$~--- совокупность некорректных алгоритмов, $\mathcal
 R^0$~--- соответствующее множество операторов распознавания, $C^{0*}$~---
фиксированное корректное решающее правило. Тогда $L(\mathcal A^0)=L(\{
 R^0\cdot C^{0*}|R^0\in\mathcal R^0\} )$ является корректным относительно
множества задач $\mathcal Q^0\!,$ если $\mathcal Q^0$ состоит из задач, полных
относительно $\mathcal R^0\!.$
\end{Corollary}

Будем рассматривать только такие задачи $Q^0(\hat{x},\olitco{x},\bar{\alpha}),$
для которых удовлетворяется следующее условие: ${\exists\, }k$, такое что
$\olitco x$ не равен нулевому вектору. Это условие является естественным,
иначе вектор $\olitco{x},$ в котором отсутствуют веса больше $0,$ не может
рассматриваться как достоверный с точки зрения порогового алгоритма~$\mathfrak
A_{\op{th}}.$

\begin{Theorem}
 {\unct\label{th:correctness}}Линейное замыкание $L(\mathcal A^0)$ семейства
алгоритмов $\mathcal A^0=\{ R^0\cdot C^{0*}|R^0\in\mathcal R\} $
с произвольным корректным решающим правилом $C^*$ и операторами
распознавания $\mathcal R,$ определенными шагами
 {\unct\ref{alst:init_start}--\ref{alst:init_end}} алгоритма $\mathfrak
 A_{\op{th}},$ является корректным на множестве задач $\mathcal Q^0\!.$
\end{Theorem}
%

\begin{Proof}
В~силу утверждения \ref{pred:correctness} достаточно доказать, что
произвольная задача $Q^0\in\mathcal Q^0$ является полной относительно
$\mathcal R^0\!.$ Доказательство полноты $Q^0$  состоит в прямом построении
операторов $R_k, k=1,2,\ldots,l$ из $L(\mathcal R^0),$ переводящих пару
$(\hat{x},\olitco{x}), \hat{x}=(\hat{x}_1,\ldots,\hat{x}_l),$
$\olitco{x}=(x_1,\ldots,x_q)$ в числовой вектор\hbox{}
 \[!E
 \label{crit:fillness}
 \olitco{x}_k^*=(x_{k1}^*,\ldots,x_{kl}^*),\ x_{kk}^*=1,\ \forall\,  u\neq k\ x_{ku}^*=0.
\]

Пусть мощность множества $Z_k$ признака $f_k$ равна $N,$ норма $\|\olitco
 x\|$ равна $M{\le}q,$ максимальная компонента вектора $\olitco{x}$ равна
$x_{\op{max}}.$ Зафиксируем величину $k$ и коэффициенты $c_1=\min_v\hat
 x_v,$ $c_2=\frac{M}{1+M}.$ Рассмотрим каузальные матрицы из множеств
$Z_1,\ldots,Z_l$ признаков $f_1^*,\ldots,f_l^*,$ удовлетворяющие следующим
условиям\hbox{}:

 \begin{enumerate}[label*=\arabic*)]
 \item в каждой каузальной матрице $Z_r^k\in Z_k$ в столбце
$\olitco{z}_1^r=(z_{11}^r,\ldots,z_{1q}^r)$ компонента $z_{1v}^r=1,$ если
$x_v=x_{\op{max}},$ и $z_{1v}^r=0,$ если $x_v<x_{\op{max}}$;
 \label{cond:ii}

 \item в каждой каузальной матрице $Z_r^u\in Z_u,$ $u\neq k$ в столбце
$\olitco{z}_1^r=(z_{11}^r,\ldots,z_{1q}^r)$ компонента $z_{1v}^r=0$ при
любых $v.$  \label{cond:ij}
 \end{enumerate}

Вычислим величину $x_{kk}^*.$ Так как $c_1=\min_u\hat x_u,$ то условие $\hat
 x_k\ge c_1$ на шаге \ref{alst:select_f} алгоритма $\mathfrak A_{\op{th}}$
автоматически выполняется и функция измерения $\hat f_k$ попадает
в множество $\hat F^*\!.$ Из условия \ref{cond:ii} следует, что каждая матрица
$Z_r^k\in Z_k$ попадает в множество $Z^*$ на шаге \ref{alst:select_z}
алгоритма~$\mathfrak A_{\op{th}}$:
 \[!E
 \frac{\|\olitco{z}_1^r-\olitco{x}\|}{\|\olitco{z}_1^r\|+\|\olitco{x}\|}<\frac{\sum_v|z_{1v}^r-x_v|}{1+M}<\frac{M}{1+M}=c_2,
\]
так как минимум одна компонента в $\olitco{z}_1^r$ равна $1$ и существует
элемент $x_v>1/2.$ В~этом случае $x_{kk}^*=\gamma{\,\cdot\,}N,$ где $\gamma$~---
весовой ко\-эф\-фи\-циент.

Вычислим величины $x_{ku}^*.$ Так как $c_1=\min_v\hat x_v,$ то условие $\hat
 x_u\ge c_1$ на шаге \ref{alst:select_f} алгоритма $\mathfrak{A}_{\op{th}}$
автоматически выполняется и все функции измерения $\hat f_u$  попадают
в множество $\hat F^*\!.$ Из условия \ref{cond:ij} следует, что каждая матрица
$Z_r^u\in\mathcal Z_u$ не попадает в множество $Z^*$  на
шаге \ref{alst:select_z} алгоритма~$\mathfrak A_{\op{th}}$:
 \[!E
 \frac{\|\olitco{z}_1^r-\olitco{x}\|}{\|\olitco{z}_1^r\|+\|\olitco{x}\|}=\frac{M}{M}=1>\frac{M}{1+M}=c_2.
\]
В~этом случае $x_{ku}^*=0.$

Рассмотрим оператор распознавания $\frac{1}{\gamma\cdot N}\,R_k(\hat
 x,\mathcal Z,\olitco x),$ каузальные матрицы которого $\mathcal Z=\{
 Z_1,\ldots,Z_l\} $ удовлетворяют условиям \ref{cond:ii}--\ref{cond:ij}
и который переводит задачу $Q^0$ в вектор $\olitco x_k^*,$ причем $\olitco
 x_{kk}^*=1,$ а $\olitco x_{ku}^*=0,$ $u\neq k.$ Данный оператор удовлетворяет
критериям (\ref{crit:fillness}) на вектор $\olitco x_k^*,$ а значит,
необходимый базис в пространстве выходных векторов построен. Полнота
задачи $Q^0$  доказана.
\end{Proof}

Фиксация момента времени не в начале вычислительного цикла, а на~любом другом
значении $\tau_s<t<\tau_s+h_i^j$ приводит к~операторам вида $R_i^j(\hat
x_i^j(\tau_s), \mathcal Z_i^j, \omega_{i\Delta t}^j),$ $\Delta t=[\tau_s, t],$
которые кратко будем записывать $R^t\!.$  Использование здесь функции входного
воздействия $\omega_{i\Delta t}^j,$ которую в виду дискретности времени можно
представлять в виде последовательности входных векторов, связано с тем, что
состояние распознающего автомата к моменту времени $t$  зависит не только от
текущего входа $\olitco x_i^j(t),$ но и от предыстории поступления входных
векторов с момента начала вычислительного цикла $\tau_s.$ Для операторов $R^t$
постановка задачи распознавания выглядит аналогично постановке задачи для
операторов $R$  начального времени: задача $Q^t(\hat x_i^j(\tau_s),
\omega_{i\Delta t}^j, \bar\alpha)\in\mathcal Q^t$ состоит в построении
алгоритма $A^{t*}\!,$ переводящего набор $(\hat x_i^j(\tau_s), \omega_{i\Delta
t}^j)$ в информационный вектор~$\bar\alpha=(\alpha_1,\ldots,\alpha_l).$

Определения свойств корректности алгоритма и полноты задачи, а также
корректного решающего правила $C^{t*}\!,$ идентичны случаю с начальным моментом
времени (рис.\:\ref{fg:rb_correct_statt}). Аналогично, рассматривая только
такие задачи $Q^t(\hat x_i^j(\tau_s), \omega_{i\Delta t}^j, \bar\alpha),$
в которых последовательность $\omega_{i\Delta t}^j$ не содержит нулевых
векторов, можно сформулировать следующую теорему (далее индексы~$i,j$ будем опускать).

\fig{{rb_correct-1}}{\caption{Статическая схема корректности для
момента времени $\tau_s<t\le{\tau_s+h_i^j}$}\label{fg:rb_correct_statt}}

\begin{Theorem}
 {\unct\label{th:correctness_t}}Линейное замыкание $L(\mathcal A^t)$ семейства
алгоритмов $\mathcal A^t=\{ R^t\cdot C^{t*}|R^t\in\mathcal R^t\} $
с произвольным корректным решающим правилом $C^{t*}$ и операторами
распознавания $\mathcal R^t\!,$ определенными шагами
 {\unct\ref{alst:cycle_start}--\ref{alst:cycle_end}} алгоритма $\mathfrak
 A_{\op{th}},$ является корректным на множестве задач $\mathcal Q^t\!.$
\end{Theorem}
%

\begin{Proof}
Пусть для простоты $\tau_s=0,$ т.\,е. будем рассматривать первый
вычислительный цикл распознающего автомата. Как и в случае доказательства
теоремы \ref{th:correctness}, будем строить для некоторой задачи $Q^t\in
 \mathcal Q^t$ базис из операторов $R_k^t,\ k=1,2,\ldots,l$, из $\mathcal
 R^t\!,$ переводящих пару $(\hat x(\tau_s), \omega_{\Delta t})$ в числовой
вектор\hbox{}
 \[!E
 \label{crit:fillness_t}
 \olitco x_k^*(t)=(x_{k1}^*,\ldots,x_{kl}^*),\ x_{kk}^*=1\quad \forall\,  u\neq k\ x_{ku}^*=0.
\]

Зафиксируем, как и в случае доказательства теоремы \ref{th:correctness},
константы $c_1$ и $c_2$: $c_1=\min_v\hat x_v,$ $c_2=\frac{M}{1+M},$ где
$M$~--- норма последнего вектора $\olitco x(t)$ из последовательности
$\omega_{\Delta t}.$ Зафиксировав индекс $k,$ рассмотрим каузальные матрицы
из множеств $Z_1,\ldots,Z_l$ признаков $f_1^*,\ldots,f_l^*,$ удовлетворяющие
следующим условиям\hbox{}:

 \begin{itemize}
 \item в каждой каузальной матрице $Z_r^k\in Z_k$ первые $t$ столбцов равны
соответствующим $t$ элементам последовательности $\omega_{\Delta t},$
а в $(t+1)$"~м столбце $\olitco z_{t+1}^r=(z_{(t+1)1}^r,\ldots,z_{(t+1)q}^r)$
компонента $z_{(t+1)v}^r=1,$ если $x_v=x_{\op{max}},$ и $z_{(t+1)v}^r=0,$
если $x_v<x_{\op{max}},$ где $x_{\op{max}}$~--- максимальная компонента
вектора $\olitco x(t)$;
 \item в каждой каузальной матрице $Z_r^u\in Z_u,$ $u\ne k$, первые $t$
столбцов также равны соответствующим $t$ элементам последовательности
$\omega_{\Delta t},$ а $(t+1)$"~й столбец $\olitco z_{t+1}^r$ нулевой.
 \end{itemize}

Вследствие значения константы $c_1$ условие $\hat x_s\ge c_1$ на
шаге \ref{alst:select_f} алгоритма $\mathfrak A_{\op{th}}$ автоматически
выполняется при любых $s$ и все функции измерения попадают в множество $\hat
 F^*\!.$ Так как до момента времени $t$ столбцы всех матриц из множества
$\mathcal Z$ равны друг другу и при этом в точности соответствуют текущему
входному вектору, то ни одна матрица не отсеивается на
шагах \ref{alst:select_z} и \ref{alst:update_z} алгоритма~$\mathcal
 A_{\op{th}}.$

В~момент времени $t$  состояние распознающего автомата совпадает с состоянием
в начальный момент времени, и мы, таким образом, получаем аналогичную
доказательству теоремы \ref{th:correctness} ситуацию. Ввиду выбора
константы $c_2$ компонента $x_{kk}^*$ выходного вектора $\olitco x^{\,*}$
в момент времени $t$  равна $\gamma\cdot N,$ где $\gamma$~--- весовой
коэффициент, а компоненты $x_{uk}^*,$ $u\ne k,$ равны нулю\hbox{}.

В~итоге операторы распознавания $\frac{1}{\gamma}\,R_k^t(\hat
 x(\tau_s),\mathcal Z_k^t, \omega_{\Delta t})$ ($\gamma$~--- некоторый весовой
коэффициент) выдают выходные векторы, удовлетворяю\-щие
условию \ref{crit:fillness_t}, и эти операторы, таким образом, составляют
необходимый базис в пространстве выходных векторов. Полнота задачи $Q^t$
доказана.
\end{Proof}

\subsubsection{Динамические постановки задачи классификации}

Теперь рассмотрим динамическую постановку задачи. Зафиксируем не конкретный
момент времени $t,$ а полуинтервал времени ${\Delta}t=[\tau_s,\tau_s+h_i^j).$
В~этом случае распознающий автомат $R_i^j$ можно рассматривать как
\textit{динамический оператор распознавания}
$\hat{R}_i^j(\hat{x}_i^{j+1}(\tau_s), \mathcal{Z}_i^j,
\omega_{i\Delta{t}}^j)=\gamma_{i\Delta{t}}^j,$ преобразующий функцию входного
воздействия $\omega_i^j,$ ограниченную на полуинтервале ${\Delta}t,$ в функцию
выходной величины $\gamma_i^j$  на том же временном полуинтервале. Так как
время полагается дискретным, то действие динамического оператора $\hat{R}_i^j$
можно заменить последовательным по времени действием статических опе\-ра\-торов
\[!M
 R(\hat x_i^{j+1}(\tau_s), \mathcal{Z}_i^j, \olitco{x}_i^j(\tau_s)), R^1(\hat
 x_i^j(\tau_s), \mathcal Z_i^j, \olitco x_i^j(\tau_s+1)), \br\ldots,
 R^{h_i^j-1}(\hat x_i^j(\tau_s), \mathcal Z_i^j, \olitco x_i^j(\tau_s+h_i^j-1)),
\]
выдающих последовательность
\[!M
 \{ \olitco{x}_i^{*j}(t)|t\in\Delta t\}=\{
 \olitco{x}_i^{*j}(\tau_s), \olitco{x}_i^{*j}(\tau_s+1), \ldots,
 \olitco{x}_i^{*j}(\tau_s+h_i^j-1)\} .
\]
Так как параметр $h_i^j$ фиксирован, то конечные последовательности векторов
$\omega_{i\Delta{t}}^j$ и $\gamma_{i\Delta{t}}^j$ можно считать матрицами
размерности $l_i^j\times{h_i^j}.$ Далее индексы $i$ и~$j$ будем опускать.

Формулировка задачи в динамическом случае будет выглядеть следующим образом:
задача $\hat{Q}(\hat{x}, \omega_{{\Delta}t}, \bar{\alpha})\in\hat{\mathcal Q}$
состоит в построении алгоритма $\hat{\mathcal A}^*\!,$ вычисляющего по
поступившему начальному вектору ожиданий $\hat{x}$ и матрице входных
воздействий $\omega_{{\Delta}t}$ информационный вектор $\bar{\alpha}.$  Однако
искомый оператор распознавания $\hat{R}$ должен выдавать матрицу весов
присутствия распознаваемых признаков $\gamma_{\Delta{t}},$ столбцы которой
должны сходиться (с~учетом корректного решающего правила) к информационному
вектору: $\lim_{t\to\tau_s+h}\olitco{x}^{\,*}(t)=\bar{\alpha}$
(рис.\:\ref{fg:rb_correct_dyn}).

\fig{{rb_correct-2}}{\caption{Динамическая схема корректности для
одиночного распознающего автомата}\label{fg:rb_correct_dyn}}

Так как из всех столбцов выходной матрицы $\gamma_{\Delta t}$ равенство
информационному вектору требуется только для последнего столбца, а на остальные
накладывается некоторое ограничение, то при разложении алгоритма $\hat A$
будем использовать статический оператор $R^{h-1}$ со следующим ограничением на
выходные векторы в моменты времени~$0\le t<h$:
\[!E
 \label{cond:dyn_to_stat}
 \|\olitco x^{\,*}(\tau_s)-\alpha\|\ge \|\olitco x^{\,*}(\tau_s+1)-\alpha\|\ge
 \ldots\\ \ge\|\olitco x^{\,*}(\tau_s+h-1)-\alpha\|,
\]
где последнее слагаемое приравнивается нулю. В~простейшем случае $\olitco
x^{\,*}(\tau_s+i)=\bar{\alpha},$ $0\le i < h.$ Будем обозначать такие операторы
$\hat R',$ а их множество соответственно~$\hat{\mathcal R}'.$

Определение корректности алгоритма $\hat A$ в данном случае эквивалентно
определению в статическом случае\hbox{}.

\begin{Pred}
 {\unct\label{st:decompositon_dyn}}Каждый алгоритм $\hat A\in\hat{\mathcal A}$
представим в виде последовательности выполнения алгоритмов $\hat R'$ и $C,$ где
$\hat R'(\hat x, \mathcal{Z}, \omega_{\Delta{t}})=\olitco
 x^{\,*}(\tau_s+h-1),$ $\olitco x^{\,*}(\tau_s+h-1)$~--- вектор действительных
чисел, $C(\olitco x^{\,*}(\tau_s+h-1))=\bar\beta,$ $\bar\beta$~--- вектор
значений $\beta_i\in\{ 0,1,\Delta\} .$
\end{Pred}
%

В~качестве корректного решающего правила $C^*$  используется то же правило, что
и в статических случаях. Аналогично статическому случаю вводится определение
линейного $L(\hat{\mathcal R}')$ замыкания над множеством~$\hat{\mathcal R}'.$

\begin{Def}
Если множество векторов $\{ \hat R'(\hat x,\omega_{\Delta t})"|\hat
 R'\in\hat{\mathcal R}'\} $ содержит базис в пространстве числовых
векторов размерности $l,$ то задача $\hat Q(\hat x,\omega_{\Delta
 t},\bar{\alpha})$ называется полной относительно $\hat{\mathcal R}.$
\end{Def}

\begin{Pred}[о корректности линейного замыкания]
 {\unct\label{pred:correctness_d}}Если множество задач $\hat{\mathcal Q}$
состоит лишь из задач, полных относительно $\hat{\mathcal R},$ то линейное
замыкание $L(\{ \hat R'{\,\cdot\,}C^*"|\hat R'\in\hat{\mathcal R}'\} )$
 ($C^*$~--- произвольное фиксированное корректное решающее правило) является
корректным относительно $\hat{\mathcal Q}.$
\end{Pred}
%

Зафиксируем начальный вектор ожиданий $\hat{x}$ и последовательность входных
векторов $\omega_{\Delta{t}}.$ Если, как и в статическом случае, мы будем
рассматривать только такие задачи
$\hat{Q}(\hat{x},\omega_{\Delta{t}},\bar{\alpha}),$ для которых в матрице
$\omega_{\Delta{t}}$ нет нулевых столбцов, то можно сформулировать следующую
теорему\hbox{}.

\begin{Theorem}{\unct\label{th:correctness_d}}Линейное замыкание
$L(\hat{\mathcal A})$ семейства алгоритмов $\hat{\mathcal A}=\{ \hat
R'{\,\cdot\,}C^*"|\hat R'\in\hat{\mathcal R}'\} $ с константным корректным
решающим правилом $C^*$ и операторами распознавания $\hat{\mathcal R}',$
определенными алгоритмом $\mathfrak{A}_{\op{th}},$ является корректным
на~множестве задач $\hat{\mathcal Q}.$
\end{Theorem}
%

\begin{Proof}
В~силу того что динамический оператор $\hat{R}$ эквивалентен по действию
введенному статическому оператору $\hat R',$ для доказательства
корректности линейного замыкания необходимо показать полноту произвольной
задачи $\hat Q\in\hat{\mathcal Q}$ относительно $\hat{\mathcal R}'.$ Для
этого, как и ранее, построим такие операторы $\hat R'_k,$
$k=1,2,\ldots,l,$~что
 \[
 \olitco x_k^*(\tau_s+h-1)=(x_{k1}^*,\ldots,x_{kl}^*),\ x_{kk}^*=1\quad
 \forall\,  u\ne k\ x_{ku}^*=0.
\]

Рассмотрим статические операторы распознавания $R_k^{h-1},$ каузальные
матрицы которых строятся по следующим принципам (считаем для упрощения
выкладок, что~$\tau_s=0$):

 \begin{itemize}
 \item в каждой каузальной матрице $Z_r^k\in Z_k$ первые $h-1$ столбцов
равны соответствующим $h-1$ столбцам матрицы $\omega_{\Delta t},$
а в $h$"~м столбце $\olitco z_h^r=(z_{h1}^r,\ldots,z_{(hq}^r)$ компонента
$z_{hv}^r=1,$ если $x_v=x_{\op{max}},$ и $z_{hv}^r=0,$ если
$x_v<x_{\op{max}},$ где $x_{\op{max}}$~--- максимальная компонента вектора
$\olitco x(h-1)$;
 \item в каждой каузальной матрице $Z_r^u\in Z_u,$ $u\ne k$, первые $h-1$
столбцов также равны соответствующим $h-1$ столбцам матрицы $\omega_{\Delta
 t},$ а $h$"~й столбец $\olitco z_h^r$ нулевой.
 \end{itemize}

Такие операторы, в силу доказательства теоремы \ref{th:correctness_t},
образуют необходимый базис. Композитный оператор, который строится на их
основе, удовлетворяет также и условию \ref{cond:dyn_to_stat}, поскольку все
выходные векторы до момента времени $h-1$ являются единичными векторами
$\olitco e,$ а в момент $h-1$ становятся равными информационному вектору\hbox{}:
 \[
 \|\olitco e- \alpha\|=\|\olitco e- \alpha\|=\ldots \le \|\bar\alpha- \alpha\|.
\]

Полнота задачи $\hat Q$ доказана.
\end{Proof}

Рассмотрим иерархическую постановку задачи, в которой будет учитываться
иерархическая связь между операторами распознавания. Будем рассматривать не
единичный распознающий автомат, а двухуровневую иерархию $E_j^2,$ на каждом
уровне которой будет по одному распознающему автомату $R_{i_1}^{j+1}$
и $R_{i_2}^j.$ Зафиксируем, как и в~динамическом случае, полуинтервал времени
$\Delta t=[\tau_s,\tau_s+h_{i_2}^j).$ Иерархию $E_j^2$  можно рассматривать как
\textit{иерархический оператор распознавания} $\hat R_{e,j}^2(\hat
x_{i_1}^{j+1}(\tau_s),\mathcal Z_{i_1}^{j+1},\mathcal
Z_{i_2}^j,\omega_{i_2\Delta t}^j)=\olitco x_{i_1}^{*j+1},$ принимающий функцию
входного воздействия $\omega_{i_2\Delta t}^j$ нижнего уровня, ограниченную на
полуинтервал времени $\Delta t,$ и выдающий вектор весов распознаваемых
признаков~$\olitco x_{i_1}^{*j+1}.$

Так как в иерархии $E_j^2$ управляющий выходной вектор $R$"~автомата
$R_{i_1}^{j+1}$ является одновременно и вектором ожидания для $R$"~автомата
$R_{i_2}^j,$ а конечный выходной вектор $\olitco x_{i_2}^{*j}$~--- входным
вектором $\olitco x_{i_1}^{j+1},$ то действие иерархического оператора $\hat
R_{e,j}^2$ можно заменить последовательным действием динамического оператора
$\hat R_{i_2}^j(\hat x_{i_2}^{j+1}(\tau_s),\mathcal Z_{i_2}^j,\omega_{i_2\Delta
t}^j)$ нижнего уровня и статического оператора $R_{i_1}^{j+1,t}(\hat
x_{i_1}^{j+2}(\tau_s),\mathcal Z_{i_1}^{j+1},\olitco x_{i_1}^{j+1}(\tau_s))$
верхнего уровня, где для распознающего автомата $R_{i_1}^{j+1}$ рассматривается
начальный момент времени вычислительного цикла, соответствующий моменту
окончания вычислительного цикла распознающего автомата~$R_{i_2}^j.$

\fig{{rb_correct-3}}{\caption{Динамическая схема корректности для
случая двухуровневой иерархии}\label{fg:rb_correct_hier}}

Формулировка задачи в~иерархическом случае будет выглядеть следующим образом:
задача $\hat Q_{e,j}^2(\hat x_{i_1}^{j+2},\omega_{i_2\Delta
t}^j,\bar\alpha_{i_1}^{j+1})\in\hat{\mathcal Q}_{e,j}^2$ состоит в построении
алгоритма $\hat A_e,$ вычисляющего по поступившему начальному вектору ожиданий
$\hat x_{i_1}^{j+2}$ и матрице входных воздействий $\omega_{i_2\Delta t}^j$
значения информационного вектора $\bar\alpha_{i_1}^{j+1}$
(рис.\:\ref{fg:rb_correct_hier}). Определения свойств корректности алгоритма
и полноты задачи, а также корректного решающего правила, в данном случае
с~точностью до обозначений совпадают с аналогичными определениями для
статического случая\hbox{}.

Зафиксируем начальный вектор ожиданий $\hat x_{i_1}^{j+2}$ и последовательность
входных векторов $\omega_{i_2\Delta{t}}^j.$ Если мы будем рассматривать только
такие задачи $\hat Q_{e,j}^2(\hat
x_{i_1}^{j+2},\omega_{i_2\Delta{t}}^j,\bar\alpha_{i_1}^{j+1}),$ для которых
в матрице $\omega_{i_2\Delta{t}}^j$ нет нулевых столбцов, то можно
сформулировать следующую теорему\hbox{}.

\begin{Theorem}
Линейное замыкание $L(\hat{\mathcal A_e})$ семейства алгоритмов
$\hat{\mathcal A}_e=\{ \hat R_{e,j}^2\cdot\hat C_e^*|\hat
 R_{e,j}^2\in\hat{\mathcal R}_{e,j}^2\} $ с произвольным корректным
решающим правилом $\hat C_e^*$ и операторами распознавания $\hat{\mathcal
 R}_{e,j}^2,$ определенными алгоритмом $\mathfrak A_{\op{th}},$ является
корректным на~множестве задач $\hat{\mathcal Q}_{e,j}^2.$
\end{Theorem}

\begin{Proof}
Доказательство корректности в данном случае сводится к формулировке задачи
нижнего уровня $\hat Q_2(\hat x_{i_2}^{j+1},\omega_{i_2\Delta
 t}^j,\bar\alpha_{i_2}^j).$ То есть необходимо сформировать по~задаче $\hat
 Q_{e,j}^2$ информационный вектор $\bar\alpha_{i_2}^j$ и вектор ожидания~$\hat
 x_{i_2}^{j+1}.$

Следуя определению вычислительного цикла в алгоритме $\mathfrak A_{\op{th}},$
будем считать, что $\hat x_{i_2}^{j+1}$ равен тому управляющему воздействию
распознающего автомата $R_{i_1}^{j+1},$ которое было вычислено в начальный
момент времени $\tau_s,$ т.\,е. вектору $\hat x_{i_1}^{j+1}=W(\ssum_{\hat
 f_k\in\hat F^*}\hat x_{ik}^{j+1}\ssum_{Z_r^k\in Z^*}\olitco z_2^r)$
 (см.~шаг \ref{alst:init_control} алгоритма $\mathfrak A_{\op{th}}$). Каждая
компонента $\alpha_{i_2u}^j$ информационного вектора $\bar\alpha_{i_2}^j$
будем вычислять по следующему правилу\hbox{}:
 \[!E
 \alpha_{i_2u}^j=\begin{cases}
 1, &
 \up{если~$\ssum\limits_{v=1}^{l_{i_1}^{j+1}}\frac{\alpha_{i_1v}^{j+1}}{|\mathcal{Z}_v|}\ssum\limits_{w=1}^{|\mathcal{Z}_v|}z_{1v}^w>0$,}\\
 0, & \up{иначе.}
 \end{cases}
\]
Так как входной вектор распознающего автомата $R_{i_1}^j$ равен вектору
$\bar\alpha_{i_2}^j,$ то такие значения компонент информационного вектора
позволяют удовлетворить ограничениям теоремы \ref{th:correctness_t}
 (существование ненулевого входного вектора). С~другой стороны, формулируя
задачу $\hat Q_2(\hat x_{i_2}^{j+1},\omega_{i_2\Delta
 t}^j,\bar\alpha_{i_2}^j)$ мы попадаем в условия
теоремы \ref{th:correctness_d}. В~силу этих теорем, можно сделать вывод, что
среди алгоритмов линейного замыкания $L(\hat{\mathcal A_e})$ имеется
оператор, переводящий пару $(\hat x_{i_1}^{j+1},\omega_{i_2\Delta t}^j)$
в информационный вектор $\bar\alpha_{i_1}^{j+1}.$
\end{Proof}

\subsubsection{Выводы}
На основании исследуемых в работе свойств автоматной функции распознающих
автоматов, построенных в соответствии с данными нейрофизиологов для образной
компоненты знака, можно сделать следующие выводы\hbox{}:
\begin{enumerate}[label*=\arabic*)]
 \item динамические характеристики образной компоненты описываются в терминах
классической теории автоматов;
 \item построенные автоматы могут быть представлены в виде операторов
распознавания, которые можно изучать в рамках классических алгебраических
теорий;
 \item построенные операторы распознавания обладают свойством корректности
относительно входных данных и требуемых результатов классификации, что
означает существование такого процесса обучения, в рамках которого будет
сформирована иерархия базовых элементов, корректно распознающая
 (классифицирующая) поступа"!ющие сигналы.
\end{enumerate}

\subsection{Алгоритм формирования пары "<образ~--- значение"> нового знака} \label{subsect4_6}

\subsubsection{Общая схема образования знака}

В~соответствии с тем, что было сказано при описании синтаксического уровня
модели картины мира в~п.\:\ref{sect:sint_level} до того, как происходит
связывание компонент знака в единую структуру под одним именем, существуют лишь
"<парные"> переходы между компонентами знания агента о том или ином явлении.
До моментам именования эти компоненты образуют "<про\-тознак">:
\begin{itemize}
 \item перцепт становится образом знака после выполнения процедуры именования,
 \item функциональное значение~--- значением знака,
 \item биологический смысл~--- личностным смыслом знака.
\end{itemize}

С~введением этой структуры схема алгоритма формирования нового знака будет
иметь следующий вид \cite{Osipov2014c}.

\begin{enumerate}
 \label{new_sign_alg}
 \item\label{stage1} Формирование перцепта.
 \item\label{stage2} Порождение на основе прошлого опыта или на основе
прецедентов~--- множества пар вида "<перцепт~--- функциональное
значение">~--- функционального значения объекта.
 \item\label{stage3} Получение субъектом из культурной среды, аккумулированной
в системе естественного языка, пары "<имя знака~--- значение"> и оценка
специальным механизмом степени близости функционального значения,
построенного на стадии \ref{stage1}, к значению, полученному из культурной
среды; в случае недостаточной близости~--- переход к стадии \ref{stage1}
и продолжение формирования перцепта.
 \item\label{stage4} Связывание имени из пары "<имя знака~--- значение">
с перцептом, построенным после завершения выполнения
стадий \ref{stage1}--\ref{stage3}; с этого момента перцепт превращается
в образ.
 \item Формирование личностных смыслов знака на основе прецедентов действий с предметом.
 \item Связывание имени из пары "<имя знака~--- значение"> со сформированным
личностным смыслом. С~этого момента функциональное значение превращается
в значение, а биологический смысл~--- в личностный смысл.
 \item Продолжение отображения "<биологический смысл~--- перцепт"> включением
в область определения отображения личностного смысла, полученного
в предыдущем пункте, а в область значений отображения~--- образа из
стадии \ref{stage4}.
\end{enumerate}

Наиболее существенным моментом в приведенном алгоритме является итерационный
процесс на стадиях \ref{stage1}--\ref{stage3}. Данный раздел будет посвящен
исследованию этого про\-цесса.

\subsubsection{Процедурные и объектные признаки}

Введем семейство бинарных отношений $\{
\sqsubset,\sqsubset^1,\sqsubset^2,\ldots\} ,$ определенных на декартовом
произведении $\mathcal F\times \mathcal F.$ Будем считать, что признак $f_1$
поглощается признаком $f_2,$ $(f_1,f_2 )\in\sqsubset$, или $f_1\sqsubset f_2,$
в том случае, если $f_1\dashv R_1^j, f_2\dashv R_2^{j+1},$ $R_2^{j+1}$~---
родительский $R$"~автомат по отношению к $R_1^j$ и в множестве каузальных
матриц $\mathcal Z_2$ признака $f_2$ существует как минимум одна
матрица $Z_r^2,$ содержащая некоторый столбец $\olitco z_u^r$ с элементом
$z_{uv}^r\ne 0,$ где $v$~--- индекс признака $f_1$ во входном векторе для
распознающего автомата $R_2^{j+1}$ (рис.\:\ref{fg:rb_measure}).

\fig{{meas}}{\caption{Определение отношения поглощения на множестве
признаков}\label{fg:rb_measure}}

Пара признаков $(f_1,f_2)\in\sqsubset^t$, или $f_1\sqsubset^t f_2,$ где
$t\in\{ 1,2,\ldots\} ,$ в~том случае если $f_1\dashv R_1^j,
f_2\dashv R_2^{j+1},$ $R_2^{j+1}$~--- родительский $R$"~автомат по отношению
к $R_1^j$ и в множестве каузальных матриц $\mathcal Z_2$ признака $f_2$
существует как минимум одна матрица $Z_r^2,$ содержащая $t$"~й столбец
$\olitco z_t^r$ с~элементом $z_{tv}^r\ne 0,$ где $v$~--- индекс признака $f_1$
во~входном векторе для распознающего автомата~$R_2^{j+1}.$

Каждый элемент векторов"=столбцов соотносится с признаком из входного множества
признаков распознающего автомата, что означает задание индекса для каждого
входного признака. Индекс признака $f_k\in F_i^j$ равен $q,$ если ему
соответствует $q$"~й элемент векторов"=столбцов каузальных матриц распознающего
автомата~$R_i^j.$

Введем операцию $\Lambda,$ которая по множеству матриц распознавания $\mathcal
Z_k$ признака $f_k$ определяет два набора индексов столбцов матриц из $Z_k.$
Первый набор $I_c=\{ i_1^c,i_2^c,\ldots\} ,$ $\forall\,  k\ 0\le i_k^c
< h,$ составляют индексы \textit{столбцов условий}, в которых ненулевые
элементы определяют условия проявления признака $f_k.$  Второй набор
$I_e=\{ i_1^e,i_2^e,\ldots\} ,$ $\forall\,  k\ 0\le i_k^e < h,$
состоит из индексов \textit{столбцов эффектов}, в которых ненулевые элементы
определяют эффекты проявления признака $f_k.$ Примером реализации
процедуры $\Lambda$ может служить алгоритм Норриса по поиску максимального
прямоугольного подмножества в бинарном отношении \cite{Norris1978}.

\begin{Def}
Признаки, для каузальных матриц которых процедура $\Lambda$ выдает непустые
множества индексов $I_c$ и $I_e,$ будем называть процедурными признаками,
остальные~--- объектными признаками.
\end{Def}

Введение данного определения означает, что все множество признаков делится на
два подмножества: $\mathcal F=\mathcal F^{proc}\cup\mathcal F^{obj}$
и~$\mathcal F^{proc}\cap\mathcal F^{obj}=\varnothing.$

Для любого процедурного признака выполняются следующие естественные условия\hbox{}:
\begin{itemize}
 \item условие всегда предшествует эффекту,
 \item условие всегда влечет за собой эффект,
 \item все условия всегда отделены от своих эффектов.
\end{itemize}

Иными словами, если $f_1$~--- процедурный признак, то если столбец $\olitco
z_u^r$ каузальной матрицы $Z_r^1$ является столбцом условий, т.\,е.
$u\in{I_c},$ этот столбец не может одновременно являться столбцом эффектов,
т.\,е. $u\not\in I_e,$ и существует такое $t>0,$ что столбец $\olitco
z_{u+t}^r$ является столбцом эффектов, т.\,е.~$u+t\in I_e.$

Пополним семейство отношений $\{
\sqsubset,\sqsubset^1,\sqsubset^2,\ldots\} $ двумя отношения\-ми:
$\sqsubset^c$ и $\sqsubset^e\!,$ принадлежность к~которым пары признаков
$(f_1,f_2)$ свидетельствует о~том, что признак $f_1$ присутствует
соответственно в~столбце условий и эффектов как минимум в~одной каузальной
матрице процедурного признака~$f_2.$

\subsubsection{Определение компонент знака}

При образовании нового знака $s$, до того как формируемая тройка компонент,
называемая протознаком, получит имя, будем считать,~что будущему знаку $s$
\textit{соответствует} некоторый признак $f\in\mathcal F,$ обладающий
перцептом, функциональным значением и биологическим смыслом, которые после
завершения процесса формирования знака становятся соответственно образом,
значением и личностным смыслом\hbox{}.
\begin{Def}
Если $f_1$~--- признак, соответствующий знаку $s_1,$  то подмножество $\tilde
 p(f_1)\subseteq\mathcal F$ таких признаков, что $\forall\,  f_i\in\tilde
 p(f_1) f_i\sqsubset f_1,$ будем называть перцептом признака $f_1$ (образом
знака $s_1$).
\end{Def}

На множестве всех перцептов $\tilde P$  введем величину $\rho_p(\tilde
p(f_1),\tilde p(f_2)),$ вычисляемую по~следующему правилу\hbox{}:
\begin{itemize}
 \item если $f_1$ и $f_2$ распознаются разными распознающими автоматами,
т.\,е. $f_1\dashv R_1^j, f_2\dashv R_2^i,$ то $\rho_p(\tilde p(f_1),\tilde
 p(f_2))=\infty,$
 \item если $f_1$ и $f_2$ распознаются одним и тем~же распознающим
автоматом $R_1^j$ со~множеством входных признаков $F_1^j$ мощности $q$
и характерным временем $h,$~то
 \[!E
 \rho_p(\tilde p(f_1),\tilde p(f_2))=\min\limits_{\substack{Z_r^1\in Z_1\\
 Z_s^2\in Z_2}}\frac{1}{q\cdot h}\ssum\limits_{u=1}^h\|\olitco z_u^r-\olitco
 z_u^s\|.
\]
\end{itemize}

\begin{Pred}
Величина $\rho_p$ является метрикой на множестве перцептов $\tilde P.$
 \end{Pred}

\begin{Proof}
Свойства тождества и симметрии очевидны вследствие свойств введенной нормы.
Проверим неравенство треугольника. В~том случае, когда признаки распознаются
разными автоматами, неравенство следует из свойств бесконечности.
Во втором случае, вследствие того что $q$ и $h$ являются константами,
неравенство следует из неравенства треугольника для введенной нормы.
\end{Proof}

\begin{Def}
Если $f_1$~--- признак, соответствующий знаку $s_1,$  $f_2$~--- процедурный
признак, $f_1\sqsubset^c f_2,$ будем называть $f_2$ элементом
функционального значения признака $f_1$ (элементом значения знака $s_1$).
Множество всех элементов функционального значения признака $f_1$ будем
обозначать $\tilde m(f_1).$
\end{Def}

На множестве всех функциональных значений $\tilde M$ введем величину
$\rho_m(\tilde m(f_1),\tilde m(f_2)),$ вычисляемую по следующему правилу\hbox{}:
\[!E
 \label{eq:m_metr}
 \rho_m(\tilde m_1(f_1),\tilde m_2(f_2 ))=\min\limits_{\substack{f_i\in\tilde
 m(f_1 )\\ f_j\in\tilde m(f_2 )}}\rho_p(\tilde p(f_i ),\tilde p(f_j )).
\]

\begin{Pred}
Величина $\rho_m$ является метрикой на множестве функциональных значений $\tilde M.$
 \end{Pred}

\begin{Proof}
Утверждение очевидно, поскольку функция $\rho_p$ является метрикой, а функция
минимума не меняет свойств метрики.
\end{Proof}

\subsubsection{Структурный уровень обобщения}

На основе описанной модели компонент знака становится возможным описать
процедуры обобщения на модельном, структурном
уровне. Для этого будем считать, что каузальные матрицы распознаю\-щих автоматов
были сформированы в процессе обучения (например, с использованием алгоритма HTM
\cite{Hawkins2009} или THSOM \cite{Koutn2008}). При рассмотрении множества
каузальных матриц $\mathcal Z$ некоторого распознающего автомата возникают
следующие три основных случая\hbox{}:

\begin{itemize}
 \item \textit{Внутреннее обобщение}. Будем называть схожими такие матрицы из
подмножества $Z'_k=\{ Z_1^k,Z_2^k\ldots,Z_m^k\} $ множества
каузальных матриц $Z_k$ некоторого признака $f_k,$ для которых при
$\forall\,  i,j,l$, таких что $Z_i,Z_j\in Z'_k,$ $l\in\{
 0,\ldots,h\} $, выполняется $\op{card}{}(z_l^i\wedge z_l^j)<c_3,$ где $c_3$~---
некоторая константа. Обобщение в этом случае заключается в замене
подмножества схожих матриц $Z'_k$ одной обобщенной
$Z^*=(\bigwedge\limits_{Z_q\in Z'_k}\olitco
 z_1^q,\bigwedge\limits_{Z_q\in Z'_k}\olitco
 z_2^q,\ldots,\bigwedge\limits_{Z_q\in Z'_k}\olitco z_h^q).$ Таким
образом, осуществляется кластеризация множества каузальных матриц
признака $f_k,$ контролируемая одним параметром близости $c_3.$
 \item \textit{Конкретизация}. В~тех случаях, когда получаемые
с использованием описанной выше меры близости кластеры каузальных матриц
признака $f_k$ расходятся достаточно сильно, образуются новые
конкретизированные признаки для каждого кластера и соответственно
расширяется множество выходных признаков $F^*$ распознающего автомата.
 \item \textit{Внешнее обобщение}. В~том случае, когда во~всех каузальных
матрицах $R$"~автоматов, являющихся родительскими по отношению
к распознающему автомату $R,$ $i$"~е и $j$"~е компоненты всех столбцов
матриц принимают одинаковые значения, выходные признаки $f_i,f_j\in F^*\!,$
соответствующие этим компонентам, обобщаются в один признак с объединенным
множеством каузальных матриц. При этом возможно и дальнейшее внутреннее
обобщение.
\end{itemize}

Отдельно необходимо рассмотреть случай \textit{абстрагирования}, когда
несколько выходных признаков одного или нескольких распознающих автоматов
в результате работы процедуры обобщения на синтаксическом уровне формируют новый признак $f^*$ в некотором $R$"~автомате $R^*\!,$
лежащем на следующем уровне иерархии. В~этом случае каузальная матрица будет
состоять из единственного столбца с ненулевыми элементами, которые
соответствуют признакам, составляющим данную ка\-те\-горию.

И, наконец, еще один случай обобщения на структурном уровне заключается
в образовании ролевой структуры процедурных признаков. Рассмотрим случай, когда
столбцы условий или эффектов некоторых каузальных матриц процедурного
признака $f_p$  различаются только в двух компонентах, т.\,е. $i$"~я компонента
в некоторых столбцах равна $1,$ а в других~--- $0,$ а $j$"~я компонента,
наоборот: в первых равна $0,$ а во вторых~--- $1.$ Если соответствующие
этим компонентам признаки в результате абстрагирования попали в некоторую общую
категорию $f_{cat},$ то к множеству каузальных матриц признака $f_p$
добавляется матрица с новой компонентой, соответствующей признаку $f_{cat}$
и обнуленными компонентами $i$  и $j.$ Данная процедура легко распространяется
на случай, когда количество элементов категории $f_{cat}$ в каузальных матрицах
признака $f_p$  больше двух. Таким образом, для процедурного признака $f_p$
появляется обобщенная, ролевая каузальная матрица\hbox{}.

\subsubsection{Свойства на множестве признаков}\label{subsubsect:matrix_struct}

В~целях дальнейшего изложения рассмотрим подробнее строение каузальной матрицы
процедурного признака. Каузальную матрицу $Z_r^p$ процедурного признака $f_p$
всегда можно представить в следующем виде\hbox{}:
\[!E
 Z_r^p=(\olitco z_1^{r,c},\ldots,\olitco z_{j_1}^{r,c},\olitco
 z_{j_{1+1}}^{r,e},\ldots,\olitco z_{i_1}^{r,e},\ldots,\ldots,\olitco
 z_{i_{k-1}+1}^{r,c},\ldots,\olitco z_{j_k}^{r,c},\olitco
 z_{j_k+1}^{r,e},\ldots,\olitco z_{i_k}^{r,e}),
\]
где $\olitco z_j^{r,c}$~--- столбцы причин, $\olitco z_i^{r,e}$~--- столбцы след\-ствий.

Величину $k$ будем называть \textit{сложностью} процедурного признака.
В~дальнейшем будем рассматривать простые каузальные матрицы $k$"~сложного
процедурного при\-знака:
\[!E
 Z_r^p=(\olitco z_1^{r,c},\olitco z_2^{r,e},\ldots,\olitco z_{2\cdot
 k-1}^{r,c},\olitco z_{2\cdot k}^{r,e}).
\]
Краткая форма $k$"~сложного процедурного признака $f_p$ имеет каузальную
матрицу, в которой оставлены только первый столбец условий и последний столбец
эф\-фектов.

Любой односложный, или элементарный, процедурный признак $f_p,$ распознаваемый
автоматом $R_i^j,$ можно представить в виде правила
$r_p=(F_C(f_p),F_A(f_p),F_D(f_p)),$ в ко\-тором:
\begin{itemize}
 \item $F_C (f_p )\subseteq F_i^j$~--- множество признаков~--- условий
правила: $\forall\,  f\in F_C(f_p)$ $f\sqsubset^c f_p$;
 \item $F_A(f_p)\subseteq F_i^j$~--- множество добавляемых правилом признаков:
$\forall\,  f\in F_A(f_p)$ $f\sqsubset^e f_p,f\not\sqsubset^c f_p$;
 \item $F_D(f_p)\subseteq F_i^j$~--- множество удаляемых правилом признаков:
$\forall\,  f\in F_D(f_p)$ $f\not\sqsubset^e f_p,f\sqsubset^c f_p.$
\end{itemize}

Очевидно, выполняются следующие соотношения:~$F_A(f_p)\cap
F_D(f_p)=\varnothing,$ $F_A(f_p)\cap F_C(f_p)=\varnothing,$~$F_D(f_p)\subseteq
F_C(f_p).$

\begin{Def}\label{def:feas}
Процедурный признак $f_p^1\dashv R_i^j$ с каузальной матрицей $Z=(\olitco
 z_1^c,\olitco z_2^e)$ выполняется на векторе $\olitco z$ длины $q,$ где
$q$~--- длина входного вектора $R$"~автомата $R_i^j,$ если $\olitco z\cdot
 \olitco z_1^c=\olitco z_1^c.$
\end{Def}

Здесь под операцией "<${\,\cdot\,}$"> подразумевается покомпонентное умножение
битовых векторов. Если в качестве вектора $\olitco z$
в определении (\ref{def:feas}) взять столбец условий некоторого
признака $f_p^2,$ то будем говорить, что процедурный признак $f_p^1$ выполним
в~условиях процедурного признака $f_p^2,$ если\hbox{}
\begin{itemize}
 \item оба признака распознаются одним и тем~же распознающим автоматом $R_i^j$
и признак $f_p^1$ выполняется на~столбце условий каузальной матрицы
признака $f_p^2,$
 \item $f_p^1\dashv R_i^{j_1}, f_p^2\dashv R_k^{j_2},$ $i\ne k,$ $F_C(f_p^1
 )\subseteq F_C(f_p^2)$ и признак $f_p^1$ выполняется на~столбце условий
каузальной матрицы признака $f_p^2.$
 \end{itemize}

\begin{Def}
Будем говорить, что два процедурных признака, $f_p^1$  и $f_p^2$, конфликтуют,
если выполнено как минимум одно из~следующих условий\hbox{}:
 \begin{itemize}
 \item $F_D(f_p^1)\cap F_A(f_p^2)\ne \varnothing,$
 \item $F_D(f_p^2)\cap F_A(f_p^1)\ne \varnothing,$
 \item $F_D(f_p^1)\cap F_C(f_p^2)\ne \varnothing,$
 \item $F_D(f_p^2)\cap F_C(f_p^1)\ne \varnothing.$
 \end{itemize}
\end{Def}

\begin{Def}
Результатом операции приведения вектор"=столбца $\olitco z$ матрицы
распознавания $R$"~автомата $R_{i_1}^{j_1}$ к $R$"~автомату $R_{i_2}^{j_2}$
будем называть такой вектор $\olitco z'$ длины $q_{i_2}^{j_2},$ $k$"~й
элемент которого $z'_k=1,$ если признак $f\in F_{i_1}^{j_1}$ с индексом $k$
равен признаку $f'\in F_{i_2}^{j_2}$ с тем же индексом и $z_k=1,$ иначе
$z'_k=0,$ и обозначать его $(\olitco z\rightarrow R_{i_2}^{j_2})=\olitco z'.$
\end{Def}

\begin{Def}
Результатом операции приведения вектор"=столбца $\olitco z$ матрицы
распознавания $R$"~автомата $R_{i_1}^{j_1}$ к $R$"~автомату $R_{i_2}^{j_2}$
по столбцу $\olitco z'$ матрицы распознавания из множества $\mathcal
 Z_{i_2}^{j_2}$ будем называть такой вектор $\olitco z''$ длины
$q_{i_2}^{j_2},$ элемент которого $z''_k=1,$ если признак $f\in
 F_{i_1}^{j_1}$ с индексом $k$ равен признаку $f'\in F_{i_2}^{j_2}$ с тем же
индексом, $z'_k=1$ и $z_k=1,$ иначе $z''_k=0,$ и обозначать $(\olitco
 z\xrightarrow{\olitco z'} R_{i_2}^{j_2})=\olitco z''.$
\end{Def}

\subsubsection{Опыт наблюдения и алгоритм $\mathfrak A_{pm}$}

Будем считать, что у субъекта имеется опыт наблюдения, который выражается
в виде отношения $\Psi_p^m: \Psi_p^m(\tilde p)=\tilde m,$ в том случае, если
$\tilde p\in\tilde P$ является перцептом некоторого признака $f,$ а $\tilde
m\in\tilde M$~--- функциональным значением того же признака~$f.$

На с.~\pageref{alg:cycle_pm_start} представлен алгоритм доопределения
функции $\Psi_p^m,$ который и представляет собой суть итерационного процесса
во время образования знака согласно алгоритму на с.~\pageref{new_sign_alg}. Доопределение проводится на~новую пару $(\tilde
p,\tilde m),$ где функциональное значение $\tilde m$ строится в сравнении
с эталоном $\tilde m^0\!,$ а перцепт $\tilde p$  формируется на основе множества
признаков, входящих в текущую область определения $\hat F=dom\ \Psi_p^m.$
Доопределение функции $\Psi_p^m$ означает формирование нового признака $f^*\!,$
т.\,е. его первой каузальной матрицы $Z^*$ в~рамках распознающего
автомата~$R^*\!.$

\begin{algorithm}[h]
 \caption{Алгоритм $\mathfrak{A}_{pm}$ (часть~I)}
 \label{alg:cycle_pm_start}
 \begin{algorithmic}[1]
 \Require~$\tilde m^0=\{ f_p^0\} ,$~$\Psi_p^m, \hat F=dom\
 \Psi_p^m\subseteq \mathcal F$;

 \State $Z_p^0 := \{ \olitco z_1^{c0},\olitco z_2^{e0}\} $~---
каузальная матрица  признака $f_p^0$;
 \State $\tilde p^{(0)} := \varnothing,$ $\tilde m^{(0)} := \varnothing$;
 \State $R_0\not\in\mathcal R$~--- фиктивный распознающий автомат, для которого
$F_0^*=\{ f_p^0\} $;
 \State $Z^{(0)} := \varnothing,$ $Z_p^{(0)} := \{ \bar 0, \bar 0\} $;
 \State $q^{(0)} := 0,$~$t := 0$;

 \While{$Z_p^{(t)}\ne Z_p$ или $t<|\hat F|$}
 \State $f\in\hat F$~--- первый не рассмотренный ранее признак;
 \State $Z=\{ \olitco z_1,\olitco z_2,\ldots,\olitco z_q\} $~---
его каузальная матрица;
 \If{$\exists\,  \tilde m=\{ f_p\} \in \tilde M$ такое, что
$(\tilde p(f),\tilde m)\in\Psi_p^m,$ $f_p$ выполним в условиях
признака $f_p^0$ и $\nexists f'$, такого что $f'\in\tilde p^{(t)}$, $\tilde
 m'=\{ f'_p\} \in\tilde M,$ $(\tilde p(f'),\tilde m')\in\Psi_p^m,$
$f'_p$ конфликтует с $f_p$}\label{alst:find_m}
 \State $\tilde p^{(t+1)}=\tilde p^{(t)}\cup\{ f\} $;
 \State $Z_p=\{ \olitco z_1^c,\olitco z_2^e\} $~--- каузальная матрица признака~$f_p$;

 \If{$\exists\,  R_i^j$ такой, что $\tilde p^{(t+1)}\subseteq F_i^j$}
 \State $R_i^{j(t+1)}:=R_i^j$;
 \Else
 \State $R_i^{j(t+1)}:=\arg{}\max\limits_{\mathcal R} (F_i^j\cap\tilde p^{(t+1)})$;
 \State $F_i^{j(t+1)}:=F_i^{j(t)}\cup\tilde p^{(t+1)}$;
 \EndIf

 \algstore{algst:store2}
 \end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
 \caption{Алгоритм $\mathfrak{A}_{pm}$ (часть \rim{II})}
 \label{alg:cycle_pm_end}
 \begin{algorithmic}[1]
 \algrestore{algst:store2}
 \State $q^{(t+1)}=\max{}\{ q^{(t)},q\} $;
 \State $Z^{(t+1)}:=\{ \olitco z_1^{(t+1)},\olitco z_2^{(t+1)},\ldots
 \olitco z_{q^{(t+1)}}^{(t+1)}\} ,$ где $\olitco z_i^{(t+1)}=\olitco
 z_i^{(t)}\vee \olitco z_i,$ если $i\le q$ и $i\le q^{(t)}\!,$ $\olitco
 z_i^{(t+1)}=\olitco z_i^{(t)},$ если $i>q$ и $\olitco z_i^{(t+1)}=\olitco
 z_i,$ если~$i > q^{(t)}$;

 \State $Z_p^{(t+1)}:=\{ \olitco z_1^{c(t+1)},\olitco
 z_2^{e(t+1)}\} ,$ где $\olitco z_1^{c(t+1)}=\olitco z_1^{c(t)}\vee
 (\olitco z_1^c\rightarrow R_0),$~$\olitco z_2^{e(t+1)}=\olitco
 z_2^{e(t)}\vee (\olitco z_2^e\xrightarrow{\olitco z_2^{e0}} R_0)$;

 \State $f_p^{(t+1)}$~--- признак с каузальной матрицей~$Z_p^{(t+1)}$;

 \State $\tilde m^{(t+1)}=\{ f_p^{(t+1)}\} $;
 \EndIf

 \State $t=t+1$;
 \EndWhile

 \State $R^*=R_i^{j(t)}$;
 \State $Z^*=Z^{(t)}$;
 \State~$\mathcal Z^*=\mathcal Z_i^{j(t)}\cup\{ Z^*\} $;

 \Return $\Psi_p^m,$ доопределенную на паре $(\tilde p, \tilde m),$ где
$\tilde p=\tilde p^{(t)}\!,$ $\tilde m=\tilde m^{(t)}\!.$
 \end{algorithmic}
\end{algorithm}

Для обоснования данного алгоритма необходимо доказать сходимость функциональных
значений, которые строятся в процессе его выполнения, к эталонному
значению~$\tilde m^0\!.$

\begin{Theorem}[о корректности алгоритма $\mathfrak A_{pm}$]
Алгоритм $\mathfrak A_{pm}$ корректен, т.\,е. элементы последовательности
функциональных значений $\langle\tilde m^{(0)},\tilde m^{(1)},\ldots,\tilde
 m^{(t)}\rangle,$ которая строится с помощью алгоритма $\mathfrak A_{pm}$ для
функционального значения $\tilde m^0\!,$ приближаются к $\tilde m^0$ в смысле
метрики ({\unct\ref{eq:m_metr}}).
\end{Theorem}

\begin{Proof}
Рассмотрим два элемента последовательности $\tilde m^{(t)}=\{
 f_p^{(t)}\} $ и $\tilde m^{(t+1)}=\{ f_p^{(t+1)}\} .$
Соответствующие каузальные матрицы будут иметь следующий~вид:
 \[!E
 Z_p^{(t)}=\{ \olitco z_1^{c(t)},\olitco z_2^{e(t)}\} ,\
 Z_p^{(t+1)}=\{ \olitco z_1^{c(t+1)},\olitco z_2^{e(t+1)}\} .
\]
Если на шаге \ref{alst:find_m} алгоритма $\mathfrak A_{pm}$ на $(t+1)$"~й
итерации не был найден подходящий признак, то матрицы $Z_p^{(t)}$
и $Z_p^{(t+1)}$ равны. Рассмотрим случай, когда был найден подходящий признак
$f'$ с функциональным значением $\tilde m'=\{ f'_p\} $
с соответствующей каузальной матрицей~$Z'=(\olitco z'^c_1,\olitco z'^e_2).$

В~том случае, если на шаге \ref{alst:find_m} был найден признак $f'_p$, матрицы $Z_p^{(t)}$ и $Z_p^{(t+1)}$ будут отличаться в своих двух столбцах\hbox{}:
 \[!E
 \olitco z_1^{c(t+1)}=\olitco z_1^{c(t)}\vee (\olitco z'^c_1\rightarrow R_0),\
 \olitco z_2^{e(t+1)}=\olitco z_2^{e(t)}\vee (\olitco
 z'^e_2\xrightarrow{\olitco z_2^{e0}} R_0).
\]
По определению расстояние между функциональными значениями $\tilde m^{(t)}$
и $\tilde m^0$ примет следующее зна\-чение:
 \[!M
 \rho_m(\tilde m^{(t)},\tilde m^0)=\min\limits_{\substack{f_i\in\tilde
 m^{(t)}\\ f_j\in\tilde m^0}}\rho_p(\tilde p(f_i),\tilde p(f_j
 ))=\rho_p(\tilde p(f'_p),\tilde p(f_p))\=[-1ex]
 \frac{1}{q\cdot h}\ssum\limits_{\substack{\olitco z_u^{1(t)}\in Z_p^{(t)}\\
 \olitco z_u^2\in Z_p^0}}\|\olitco z_u^{1(t)}-\olitco z_u^2\|.
\]
Аналогично для $\tilde m^{(t+1)}$:
 \[!E
 \rho_m(\tilde m^{(t+1)},\tilde m^0)=\frac{1}{q\cdot
 h}\ssum_{\substack{\olitco z_u^{1(t+1)}\in Z_p^{(t+1)}\\ \olitco z_u^2\in
 Z_p^0}}\|\olitco z_u^{1(t+1)}-\olitco z_u^2\|.
\]
Рассмотрим разность
 \[!M
 \rho_m(\tilde m^{(t)},\tilde m^0)-\rho_m(\tilde m^{(t+1)},\tilde
 m^0)\=\frac{1}{q\cdot h}\,(\|\olitco z_1^{c(t)}-\olitco z_1^{c0}\|+\|\olitco
 z_2^{e(t)}-\olitco z_2^{e0}\|-
 \|\olitco z_1^{c(t+1)}-\olitco z_1^{c0}\|-\|\olitco z_2^{e(t+1)}-\olitco
 z_2^{e0}\|)\=\frac{1}{q\cdot h}\,(\|\olitco z_1^{c(t)}-\olitco z_1^{c0}\|+
 \|\olitco z_2^{e(t)}-\olitco z_2^{e0}\|-\|\olitco z_1^{c(t)}\vee (\olitco
 z'^c_1\rightarrow R_0)-\olitco z_1^{c0}\|\-
 \|\olitco z_2^{e(t)}\vee (\olitco z'^e_2\xrightarrow{\olitco z_2^{e0}} R_0)-\olitco z_2^{e0}\|),
\]
где $\olitco z_1^{c0},$ $\olitco z_2^{e0}$~--- столбцы каузальной матрицы
процедурного признака $f_p^0,$ соответствующего функциональному
значению~$\tilde m^0\!.$

Так как $f'_p$ выполним на первом столбце каузальной матрицы
признака $f_p^0,$ то после применения операции приведения $\olitco
 z'^c_1\rightarrow R_0$ в результирующем векторе единицы появляются на
тех же местах, что и в векторе $\olitco z_1^{c0}.$ Это означает, что в векторе
$\olitco z_1^{c(t)}\vee (\olitco z'^c_1\rightarrow R_0)-\olitco z_1^{c0}$ по
сравнению с вектором $\olitco z_1^{c(t)}$ единицы находятся в тех же
местах, что и в векторе $\olitco z_1^{c0},$ а новых нулей не появляется, вследствие чего разность $\|\olitco z_1^{c(t)}-\olitco z_1^{c0}\|-\|\olitco
 z_1^{c(t)}\vee (\olitco z'^c_1\rightarrow R_0)-\olitco z_1^{c0}\|$ всегда
больше либо равна нулю\hbox{}.

Так как для столбцов эффектов применяется операция приведения по столбцу, то
единицы в результирующем векторе остаются только на тех местах, на которых
одновременно находятся единицы в приводимом векторе и векторе, по которому
осуществляется приведение. В~связи с этим разность $\|\olitco
 z_2^{e(t)}-\olitco z_2^{e0}\|-\|\olitco z_2^{e(t)}\vee (\olitco
 z'^e_2\xrightarrow{\olitco z_2^{e0}} R_0)-\olitco z_2^{e0}\|$ также больше
либо равна нулю\hbox{}.

Так как обе разности в скобках выражения для $\rho_m(\tilde m^{(t)},\tilde
 m^0)-\rho_m(\tilde m^{(t+1)},\tilde m^0)$ больше либо равны нулю, отсюда
следует, что функциональное значение $\tilde m^{(t+1)}$ ближе или по крайней
мере находится на том же расстоянии от $\tilde m^0\!,$ что и $\tilde m^t\!.$ Ввиду
произвольности выбора итерации $t$ это приводит к тому, что элементы всей
последовательности $\langle\tilde m^{(0)},\tilde m^{(1)},\ldots\rangle$
приближаются к $\tilde m^0$ в смысле использованной
метрики (\ref{eq:m_metr}).
\end{Proof}

\section{Структурный уровень модели:\\ сетевая организация}\label{sect:matrices}

В~данном разделе рассмотрим более подробно сетевую организацию на множестве
каузальных матриц. Начнем с определений на примере образной компоненты, которая
участвует в распознавании представляе\-мого объекта или процесса. В~данном
разделе рассмотрим процесс распознавания на материале поступающей из внешней
среды сенсорной информации и регистрируемой внутренними сенсорами моторной
информации. При решении некоторых задач (например, при различении уровня
стимула) сенсорный образ становится образом сознания и входит в структуру знака.
До именования знак будем называть протознаком или при\-знаком.

Напомним определение каузальной матрицы (см.~также
п.~\ref{subsubsect:matrix_struct}). Предположим, что во входном потоке
данных выделена последовательность $(x_1,x_2,\ldots,x_h)$ длины $h$ векторов
действительных чисел от 0 до 1, которые будем называться \textit{событиями}.
Каждое событие $x_t$ длины $q$ представляет собой запись выходов от $q$
сенсоров, а каждый элемент события означает степень уверенности (субъективную
вероятность в байесовском смысле) в срабатывании соответствующего сенсора.
Например, событие $(0.1, 0.9, 0.9)$ поступает с трех сенсоров~--- датчиков
красного, синего и зеленого света~--- и означает, что степень уверенности
в срабатывании датчика красного света составляет $0.1,$ а синего и зеленого~---
по~$0.9.$

Образная компонента знака отвечает в первую очередь за распознавание
представляемого объекта на основе входной информации. В~процессе
функционирования образа знака используется или строится специальная
распознающая функция, принимающая на вход последовательность векторов,
содержащих информацию о признаках объекта в отдельные моменты времени.
Распознающая функция определяет, присутствует ли (закодирован ли)
представляемый знаком объект в этой последовательности. Далее будем считать,
что данная функция уже построена в результате специального процесса обучения
(см.~подробнее \cite{Panov2014d,Skrynnik2016}).

Будем представлять распознающую функцию (т.\,е. кодировать характерные признаки
объекта или процесса) специальной структурой~--- каузальной матрицей
$z=(e_1,e_2,\ldots,e_h)$ размерности $q$ на $h,$ где $q$~--- размерность
входных событий, а $h$~--- длина последовательности входных событий. При этом
каждый столбец $e_t$ каузальной матрицы является бинарным вектором длины $q$
и кодирует те признаки (которым соответствуют единицы), которые необходимо должны
присутствовать во входном событии в момент времени $t,$ чтобы представляемый
объект или процесс мог быть распознан во входном потоке данных, т.\,е. задают
множество одновременных характерных признаков. Например, образу знака $s,$
представляющему объект "<лицо">, может соответствовать каузальная матрица\hbox{}
\[
 z=\begin{bmatrix}
 1 & 0 & 0 & 0\\
 0 & 1 & 0 & 0\\
 0 & 0 & 1 & 0\\
 0 & 0 & 0 & 1\\
 \end{bmatrix},
\]
где первая строка является характеристическим вектором информации с датчика
левого глаза на изображении, вторая~--- с датчика правого глаза, третья~---
носа, четвертая~--- рта (см.~рис.\:\ref{fig:face}).

\fig{{face}}{\caption{Визуальная интерпретация каузальной матрицы: 1~--- область детектирования сенсора, отвечающего за левый глаз, 2~--- за
правый глаз, 3~--- за нос и 4~--- за рот. Стрелками обозначены временные
переходы (саккады) от срабатывания одного сенсора к срабатыванию
следующего}\label{fig:face}}

В~вышеприведенном примере каждый признак, составляющий образ знака "<лицо">,
также может представляться некоторым знаком в картине мира субъекта. Таким
образом, случай, когда характерными признаками образа знака выступают данные
с сенсоров, является частным. В~более общей постановке признаками, образующими
образ знака, являются другие знаки, которые соответствуют этим характерным
признакам. Следовательно, мы можем поставить в соответствие образу $p$ знака $s$ множество
$S_p(s)$ мощности $q,$  каждому элементу которого соответствует номер строки
каузальной матрицы $z$  размера $q$ на $h,$ т.\,е. каждому признаку $s_i\in
S_p(s)$ соответствует характеристический бинарный вектор, задающий на местах
единиц те дискретные моменты времени, в которые данный признак должен
присутствовать во входных данных, чтобы успешно распознать образ знака
(актуализировать знак)~$s.$

Образу каждого знака может соответствовать несколько каузальных матриц, которые
задают различные прецеденты наблюдения во внешней среде представляемого объекта
или процесса. Весь кортеж каузальных матриц образа знака $s$ будем обозначать
$Z^p(s).$

Для уточнения определения множества $S_p(s)$ введем семейство вложенных
бинарных отношений $\{
\sqsubset_p,\sqsubset_p^1,\sqsubset_p^2,\ldots\} ,$ определенных на
множестве знаков $S.$ Будем считать, что знак $s_i$ \textit{является
элементом образа} знака $s,$ $(s_i,s)\in\sqsubset_p$ или $s_i\sqsubset_p s,$
в том случае, если $s_i\in S_p(s).$ Если известно, что знаку $s_i$
соответствует единица в $t$"~м столбце некоторой каузальной матрицы $z\in
Z^p(s)$ знака $s,$ то будем использовать отношение $\sqsubset_p^t$, такое
что~$\sqsubset_p^t\subset \sqsubset_p.$

\subsection{Каузальная сеть}

Введем специальную процедуру $\Lambda_p": 2^Z\rightarrow 2^{\mathbb N}\times
2^{\mathbb N},$ которая каждому кортежу каузальных матриц $Z^p(s)\subset Z$
образа знака $s$ ставит в соответствие два непересекающихся подмножества
индексов столбцов $I^c\subset\mathbb N,$ $\forall\,  i\in I^c\ i\leq h$
и $I^e\subset\mathbb N,$ $\forall\,  i\in I^e\ i\leq h$:
$\Lambda_p(Z^p(s))=(I^c,I^e)$, таких что $I^c\cap I^e=\varnothing.$
Множество $I^c$ будем называть индексами столбцов условий,
а множество $I^e$~--- индексами столбцов эффектов. Например, если для кортежа
матриц $Z,$ состоящего только из одной матрицы $((1, 0), (0, 1))$,
процедура $\Lambda_p$ выдает два множества, $\{ 1\} $ и $\{
2\} ,$ то это означает, что появление признака, соответствующего первой
строке матрицы, вызывает появление признака, соответствующего второй строке.
Процедура $\Lambda_p,$  таким образом, устанавливает причинно"=следственное
отношение на множестве входных событий и может реализовываться различными
способами, в~т.\,ч. на основе алгоритмов Норриса, FCO и~др. (см.
\cite{Kuznetsov2001,Kuznetsov1996}).

В~том случае, когда для матриц $Z^p(s)$ образа знака $s$ множество столбцов
эффектов непусто, $I^e \ne \varnothing,$ будем считать, что знак представляет
некоторое действие или процесс, результат которого кодируется в столбцах
эффектов, а условие~--- в столбцах условий (соответствую\-щий знак является
процедурным). В~противном случае, когда для матриц $Z^p(s)$ образа знака $s$
множество столбцов эффектов пусто $I^e=\varnothing,$ т.\,е. когда по данному
кортежу каузальных матриц невозможно однозначно определить, какие события
предшествуют другим, будем считать, что причинно"=следственная связь не
установлена и знак представляет некоторый объект или ситуацию (соответствующий
знак является объ\-ектным).

Справедливы следующие утверждения относительно свойств процедуры~$\Lambda_p$:
\begin{itemize}
 \item $I^c\cap I^e=\varnothing$~--- столбец каузальной матрицы не может быть
одновременно и условием, и эффектом,
 \item $|I^c\cup I^e|=h$~--- других типов столбцов, кроме столбцов условий и эффектов, не существует,
 \item $I^c\ne \varnothing$~--- среди столбцов каузальной матрицы должен быть
хотя бы один столбец условий, в то время как эффектов может и не быть
 (в~случае объектных признаков),
 \item $\forall\,  i\in I^e\!,$ $j\in I^c\ i>j$~--- все условия
предшествуют эффектам по времени.
\end{itemize}

Переходя к нотации, принятой в искусственном интеллекте, можем считать, что
каузальная матрица $z$  образа знака $s$ является правилом $r=\langle
F_C(z),F_A(z),F_D(z)\rangle$ \cite{Osipov2008b}, в ко\-тором:
\begin{itemize}
 \item $F_C (z)\subseteq S_p(s)$~--- множество признаков~--- условий правила:
$\forall\,  f\in F_C(z)$~$f\sqsubset_p^i s, i\in I^c$;

 \item $F_A(z)\subseteq S_p(s)$~--- множество добавляемых правилом признаков:
$\forall\,  f\in F_A(z)$~$f\sqsubset_p^i s,i\in I^e,$~$f\not\sqsubset^j f_p,
 j\in I^c$;

 \item $F_D(z)\subseteq S_p(s)$~--- множество удаляемых правилом признаков:
$\forall\,  f\in F_D(z)$ $f\not\sqsubset^i s, i\in I^e,$ $f\sqsubset^j s, j\in
 I^c.$
\end{itemize}

Пример каузальной матрицы, построенной с учетом вышесказанного, приведен на рис.\:\ref{fig:caus_matr}.

\fig{{caus_matr_ru}}{\caption{Пример каузальной матрицы}\label{fig:caus_matr}}

Теперь введем понятие каузальной сети, которая будет определять гетерархию на
множестве образов. Каузальная сеть $W_p=\langle V_p, E_p \rangle$ является
помеченным ориентированным графом, в ко\-тором
\begin{itemize}
 \item каждому узлу $v\in V_p$ ставится в соответствие кортеж каузальных
матриц $Z^p(s)$ образа некоторого знака $s,$  что будем обозначать как
$v\rightarrow Z^p(s)$;
 \item ребро $e=(v_1, v_2)$ принадлежит множеству ребер графа $E,$ если
$v_1\rightarrow Z^p(s_1),$ $v_2\rightarrow Z^p(s_2)$ и $s_1\in S_p(s_2),$
т.\,е. если знак $s_1$ является элементом образа $s_2$;
 \item каждому ребру графа $e=(v_1, v_2),$ $v_1\rightarrow Z^p(s_1),$
$v_2\rightarrow Z^p(s_2)$ ставится в соответствие метка
$\epsilon=(\epsilon_1,\epsilon_2,\epsilon_3)$~--- кортеж трех натуральных
чисел\hbox{}:
 \begin{itemize}
 \item $\epsilon_1$~--- индекс исходной матрицы в кортеже $Z^p(s_1)$ может
принимать специальное значение 0, если исходными могут служить любые
матрицы из кортежа;
 \item $\epsilon_2$~--- индекс целевой матрицы в кортеже $Z^p(s_2),$ строка
которой ставится в соответствие признаку $s_1$;
 \item $\epsilon_2$~--- индекс столбца в целевой матрице, в которой
в соответствующей признаку $s_1$ строке стоит 1, может принимать
положительные (столбцы условий) и отрицательные значения (столбцы
эффектов).
 \end{itemize}
\end{itemize}

Каузальная сеть является особым типом неоднородной семантической
сети \cite{Osipov1990}. Пример такой сети изображен
на рис.\:\ref{fig:caus_net}.

\fig{{caus_net-0}}{\caption{Схема каузальной сети. Здесь каузальные
матрицы изображены в виде квадратов, столбцы условий~--- левая белая часть
квадрата, столбцы эффектов~--- черная правая часть квадратов.
Метка $\epsilon_1$ отображается в начале каждой стрелки, метка $\epsilon_2$
определяется как номер квадрата, к которому идет стрелка, а метка $\epsilon_3$
отображается в конце каждой стрелки}\label{fig:caus_net}}

Аналогичным образом определяются каузальные сети для остальных компонент
знака~--- для значения и личностного смысла. Для каждого знака $s$ задаются
множества $S_m(s)$ и $S_a(s),$ т.\,е. определяются семейства вложенных
отношений: $\{ \sqsubset_m,\sqsubset_m^1,\sqsubset_m^2,\ldots\} $~---
\textit{являться элементом значения} и $\{
\sqsubset_a,\sqsubset_a^1,\sqsubset_a^2,\ldots\} $~--- \textit{являться
элементом смысла}. Множество $S_m(s)$ интерпретируется как сюжетно"=ролевой
состав знака $s,$ например элементы подкласса или роль действия. Множество
$S_a(s)$ интерпретируется как оценка мгновенного компонентного состава
некоторой ситуации, наблюдаемой и переживаемой субъектом, носителем картины
мира, в настоящее время. Аналогично определяются множества $Z^m(s),$
$Z^a(s),$ процедуры $\Lambda_m$ и~$\Lambda_a.$

Три типа каузальных сетей отличаются друг от друга отношениями, которые
генерируются на основе этих сетей для соответствующего множества компонент
знаков, операциями, которые выполняются на этих сетях, и той ролью, которую они
играют при реализации когнитивных функций, например планирования
поведения \cite{Osipov2015d}. Теперь мы можем дать формальное определение
знака \cite{Osipov2015c} с использованием введенного формализма каузальных
матриц и каузальных сетей\hbox{}.

\begin{Def}
Знаком будем называть четверку $s=\langle n, p, m, a \rangle,$ где $n$~---
имя знака, $p=Z^p$~--- образ знака, т.\,е. кортеж каузальных матриц, которым
соответствует некоторый узел каузальной сети на образах с учетом всех
входящих и исходящих связей, $m=Z^m$~--- значение знака, т.\,е. кортеж
каузальных матриц, которым соответствует некоторый узел каузальной сети на
значениях с учетом всех входящих и исходящих связей, $a=Z^a$~--- образ
знака, т.\,е. кортеж каузальных матриц, которым соответствует некоторый узел
каузальной сети на личностных смыслах с учетом всех входящих и исходящих
связей.
\end{Def}

Далее мы будем считать, что каждый знак обладает значением, т.\,е. $Z^m\ne
\varnothing,$ $S_m\ne \varnothing.$ В~том случае, когда у знака нет сенсорного
образа, т.\,е. $Z^p=\varnothing,$ $S_p=\varnothing,$ будем называть его
\textit{знаком категории} (будем различать метапонятия и категории, как это
указано в \cite{Osipov1997}). Наконец, в том случае, когда знаку не присвоен
личностный смысл, т.\,е. $Z^a=\varnothing,$ $S_a=\varnothing,$ будем называть
его \textit{безличным}.

\subsection{Семиотическая сеть}\label{sec:semnetwork}

Далее определим три семейства бинарных отношений на множестве знаков, которые
генерируются на основе структуры фрагментов трех типов каузальных сетей,
к которым принадлежат соответствующие компоненты знаков. Эти отношения
соответствуют отношениям, введенным на семантическом уровне описания модели
(см.~п.~\ref{subsect4_4})

\subsubsection{Отношения на множестве образов}

Начнем с определения отношений на множестве знаков, генерируемых на основе
каузальной сети на образах. Для этого потребуется определение стандартного
семейства отношений равенства, сходства, включения и противопоставления двух
каузальных матриц\hbox{}.

\begin{Def}
Две каузальные матрицы $z_1$  и $z_2$ равны ($z_1=z_2$) тогда и только тогда,
когда размерности матриц равны, множества индексов столбцов эффектов
и условий совпадают $\Lambda({z_1})=\Lambda({z_2})$ и каждый бинарный
вектор $e_t^1,$ столбец матрицы $z_1,$ равен соответствующему по порядку
бинарному вектору $e_t^2,$ столбцу матрицы $z_2.$
 \end{Def}

\begin{Def}
Две каузальные матрицы $z_1$  и $z_2$ обладают сходством ($z_1\sim z_2$)
тогда и только тогда, когда существуют два таких бинарных вектора $e_i$
и $e_j,$ столбцы матриц $z_1$ и $z_2,$ что их покомпонентное произведение
 (т.\,е. произведение тех компонент, которые соответствуют одному и тому же
признаку, если соответствующего признака в векторе нет, считается, что на
его месте стоит нуль) не равно нулевому вектору, $e_i*e_j\ne \varnothing$,
и они одновременно являются либо столбцами условий $i\in I^c(z_1),$ $j\in
 I^c(z_2),$ либо столбцами эффектов $i\in I^e(z_1),$ $j\in I^e(z_2).$
\end{Def}

\begin{Def}
Каузальная матрица $z_1$ включена в каузальную матрицу $z_2$ ($z_1\subseteq
 z_2$) тогда и только тогда, когда для любого бинарного вектора $e_i,$
столбца матрицы $z_1,$ существует бинарный вектор $e_j,$ столбец
матрицы $z_2,$ такой что $e_i | e_j=e_j$ ($|$~--- операция побитового
 "<или">) и они одновременно являются либо столбцами условий $i\in I^c(z_1),$
$j\in I^c(z_2),$ либо столбцами эффектов $i\in I^e(z_1),$ $j\in I^e(z_2).$
\end{Def}

\begin{Def}
Две каузальные матрицы $z_1$  и $z_2$ противопоставлены друг другу ($z_1\perp
 z_2$) тогда и только тогда, когда размерности матриц равны, множества
индексов столбцов эффектов и условий совпадают $\Lambda({z_1})=\Lambda({z_2})$
и каждый бинарный вектор $e_t^1,$ столбец матрицы $z_1,$ не имеет пересечения
с соответствующим ему по порядку бинарным вектором $e_t^2,$ столбцом
матрицы $z_2,$ т.\,е. $e_t^1\&
 e_t^2=e_0,$ где $\&$~--- операция побитового "<и">, а $e_0$~--- нулевой
вектор той же длины, что и векторы $e_t^1$ и $e_t^2.$
\end{Def}

Кроме уже введенного ранее семейства отношений "<являться элементом образа">,
${\sqsubset_p, \sqsubset_p^1, \ldots},$ на основе определений отношений на
множестве каузальных матриц зададим четыре отношения на множестве знаков~$S.$
\begin{Def}
Пара знаков $s_1$ и $s_2$ принадлежит \textbf{отношению эквивалентности по
образу} $R_{eq}^p,$ $(s_1,s_2)\in R_{eq}^p,$ если кортеж $Z^p(s_1)=\langle
 z_1^1,z_2^1,\ldots\rangle$ поэлементно равен кортежу $Z^p(s_2)=\langle
 z_1^2,z_2^2,\ldots\rangle,$ т.\,е. их мощности равны и каждая каузальная
матрица первого кортежа равна соответствующей матрице второго кортежа, т.\,е.
$|Z^p(s_1)|=|Z^p(s_2)|,$ $\forall\,  z_t^1\in Z^p(s_1)\ \exists\,  z_l^2\in
 Z^p(s_2)": z_t^1=z_l^2,$ $t=l.$
\end{Def}

\begin{Def}\label{def:sim}
Пара знаков $s_1$ и $s_2$ принадлежит \textbf{отношению сходства по образу}
$R_{sim}^p,$ $(s_1,s_2)\in R_{sim}^p,$ если для каждой каузальной матрицы $z_i$
кортежа $Z^p(s_1)$ в кортеже $Z^p(s_2)$ найдется такая матрица $z_j,$
что $z_i$ обладает сходством с $z_j,$ т.\,е. $\forall\,
 z_i\in Z^p(s_1)\ \exists\,  z_j\in Z^p(s_2)": z_i\sim z_2.$
\end{Def}

\begin{Def}
Пара знаков $s_1$ и $s_2$ принадлежит \textbf{отношению включения по
образу} $R_{in}^p,$ $(s_1,s_2)\in R_{in}^p,$ если для каждой каузальной
матрицы $z_i$ кортежа $Z^p(s_1)$ в кортеже $Z^p(s_2)$ найдется такая
матрица $z_j,$ что $z_i$ будет включена в $z_j,$ т.\,е. $\forall\,  z_i\in
 Z^p(s_1)\ \exists\,  z_j\in Z^p(s_2)": z_i\subseteq z_2.$
\end{Def}

\begin{Def}
Пара знаков $s_1$ и $s_2$ принадлежит \textbf{отношению противопоставления
по образу} $R_{con}^p,$ $(s_1,s_2)\in R_{con}^p,$ если мощность кортежа
$Z^p(s_1)=\langle z_1^1,z_2^1,\ldots\rangle$ равна мощности кортежа
$Z^p(s_2)=\langle z_1^2,z_2^2,\ldots\rangle$ и каждая каузальная матрица
первого кортежа противопоставлена соответствующей матрице второго кортежа,
т.\,е. $|Z^p(s_1)|=|Z^p(s_2)|,$ $\forall\,  z_t^1\in Z^p(s_1)\ \exists\,
 z_t^2\in Z^p(s_2)": z_t^1\perp z_t^2.$
\end{Def}

Семейство отношений $R^p$ на множестве образов ввиду введенных определений
формируется отношениями "<являться элементом образа">, эквивалентности,
сходства, включения и противопоставления по образу\hbox{}.

\subsubsection{Отношения на множестве значений}

К~семейству отношений $R^m$ на множестве значений отнесем отношения "<являться
элементом значения">, ${\sqsubset_m,\sqsubset_m^1,\ldots}$ и аналогичные случаю
с образами~--- отношения эквивалентности $R_{eq}^m,$ сходства $R_{sim}^m,$
включения $R_{in}^m$ и противопоставления $R_{con}^m$ по зна\-чению.

Кроме того, важную роль на сети значений при моделировании когнитивных функций
играют следующие два отношения, расширяющие стандартное семейство:
отношение классификации $R_{cl}^m,$ причинно"=следственное отношение
$R_{cas}^m$ и сценарное отношение~$R_{sc}^m.$

\begin{Def}
Пара знаков $s_1$ и $s_2$ принадлежит \textbf{отношению классификации}
$R_{sc}^m,$ $(s_1,s_2)\in R_{sc}^m,$ если $s_1$~--- объектный знак категории
и существует только одна каузальная матрица значения знака $s_1$
с единственным столбцом, в котором только одна единица соответствует
знаку $s_2,$  т.\,е. $Z^p(s_1)=\varnothing,$ $I^e(s_1)=\varnothing,$
$\exists\,  z\in Z^m(s_1)": h(z)=1,$ $|e_1(z)|=1, s_2\sqsubset_m^1 s_1.$
\end{Def}

\begin{Def}
Пара знаков $s_1$ и $s_2$ принадлежит \textbf{сценарному отношению}
$R_{cas}^m,$ $(s_1,s_2)\in R^m,$ если $s_1$~--- процедурный знак,
$s_2$~--- объектный знак, возможно знак категории, и знак $s_2$ является
элементом значения знака $s_1,$ т.\,е. $I^e(s_1)\ne \varnothing,$ $I^e(s_2)
=\varnothing, s_2\sqsubset_m s_1.$
\end{Def}

Примеры элементов отношений $R_{cl}^m$ и $R_{sc}^m$ приведены на рис.\:\ref{fig:signif_relat}.

\fig{{caus_net-1}}{\caption{Пример элементов отношений на каузальной
сети значений. Здесь множество $\{
(s_2,s_3),(s_2,s_4),(s_2,s_5),(s_2,s_6),(s_1,s_2)\} \subset R_{cl}^m$
интерпретируется как "<квадрат, треугольник, трапеция и круг являются
геометрическими фигурами, которые выступают объектами действия рисовать">.
Множество $\{ (s_7,s_1),(s_7,s_8),(s_7,s_9)\} \subset R_{sc}^m$
интерпретируется как "<действие рисовать задается ролями субъект (тот, кто
рисует), инструмент (чем рисуют) и объект (что рисуют)">. Условные обозначения
те же, что и на рис.\:\ref{fig:caus_net}}\label{fig:signif_relat}}

\subsubsection{Отношения на множестве личностных смыслов}
К~семейству отношений $R^a$ на множестве личностных смыслов отнесем отношения
"<являться элементом смысла">, ${\sqsubset_a,\sqsubset_a^1,\ldots}$,
и аналогичные случаю с образами~--- отношения эквивалентности $R_{eq}^a,$
сходства $R_{sim}^a,$ включения $R_{in}^a$ и противопоставления $R_{con}^a$ по
смыслу\hbox{}.

Также на множестве личностных смыслов введем ситуационное отношение~$R_{sit}^a.$

\begin{Def}
Пара знаков $s_1$ и $s_2$ принадлежит \textbf{ситуационному отношению}
$R_{sit}^a,$ $(s_1,s_2)\in R_{sit}^a,$ если $s_1$~--- процедурный знак,
$s_2$~--- объектный знак, не являющийся знаком категории, и знак $s_2$
является элементом смысла знака $s_1,$ т.\,е. $I^e(s_1)\ne \varnothing,$
$I^e(s_2)=\varnothing,$ $S_p(s_2)=\varnothing, s_2\sqsubset_a s_1.$
\end{Def}

На основе определения ситуационного отношения оказывается возможным ввести
понятие ситуации, определяемое на основе некоторого процедурного знака со всеми
объектными знаками, не являющимися знаками категорий, в паре с которыми он
принадлежит ситуационному от\-но\-шению.

\begin{Def}
Множество знаков $Sit=\{ s_1,s_2,\ldots,s_n\} $ будем называть
 \textit{ситуацией}, если $s_1$~--- единственный процедурный знак в множестве
$Sit$ и для всех $1<i\leq n\ s_i\in Sit,$ $(s_1,s_i)\in R_{sit}^a.$
\end{Def}

Пример элементов отношения $R_{sit}^a$ и ситуации приведен на рис.\:\ref{fig:mean_relat}

\fig{{caus_net-2}}{\caption{Пример элементов отношения $R_{sit}^a$
на каузальной сети смыслов. Здесь множество $\{
(s_5,s_1),(s_5,s_2),(s_5,s_3),(s_5,s_4)\} \subset R_{sit}^a$ эквивалентно
ситуации "<Иван рисует трапецию карандашом">. Условные обозначения те же, что
и на рис.\:\ref{fig:caus_net}}\label{fig:mean_relat}}

\subsubsection{Семиотическая сеть}
Будем называть \textit{семиотической сетью} пятерку $\Omega=\langle W_p, W_m,
W_a, R, \Theta \rangle,$~где
\begin{itemize}
 \item $W_p, W_m, W_a$~--- каузальные сети на множестве образов, значений
и личностных смыслов соответственно,
 \item $R$~--- семейство отношений на множестве знаков, образованных на основе
трех каузальных сетей, т.\,е. $R=\{ R^p, R^m, R^a\} ,$
 \item $\Theta$~--- семейство операций на множестве знаков (которые будут определены ниже).
\end{itemize}

\subsection{Операции в семиотической сети}\label{sec:operations}
На структурном уровне модели уточним определения ряда операций, которые
функционируют в картине мира и генерируют новый знак либо сценарий на основе
компонент двух входных знаков. Другими словами, генерация, например, нового
образа на основе двух образов других знаков, влечет за собой формирование
остальных компонент нового знака по правилам данной операции. Здесь в качестве
примера будут даны определения некоторых из них для каждой каузальной сети. Для
простоты изложения будем далее считать, что каждая компонента знака
характеризуется одной кау\-зальной матрицей. Далее будет использована процедура
образования нового знака, описанная в п.~\ref{sect:first_def}, которую
здесь будем обозначать $\Psi.$

\subsubsection{Операция обобщения}

Обобщение является одним из ключевых когнитивных процессов, которые позволяют
организовывать знания в иерархической форме, формировать компактные
представления объектов и процессов действительности. В~психологии выделяют три
вида обобщения: синкрет, комплекс и понятие \cite{Vygotsky1999}. При
синкретическом обобщении в некоторых случаях ведущую роль играет личностный
смысл знаков, т.\,е. субъективное отношение носителя картины мира
к представляемым объектам. При формировании обобщения"--понятия используются
образы знаков, объективно существующие признаки. Обобщение"--комплекс,
основываясь на значении знаков, формируется уже в процессе рассмотрения
родовидовых отношений, знания о которых согласованы с другими участниками
совместной де\-я\-тель\-ности.

Определим операцию \textit{обобщения по образу} (образования
обобщения"--понятия): $\Theta^p": S\times S\rightarrow S.$ Пусть $s_1=\langle n_1,
\{ z_1^p\} , \{ z_1^m\} , \{ z_1^a\} \rangle,$
$s_2=\langle n_2, \{ z_2^p\} , \{ z_2^m\} , \{
z_2^a\} \rangle$~--- знаки, такие что $(s_1,s_2)\in R_{eq}^p,$ т.\,е.
принадлежат отношению сходства. Новый образуемый знак обозначим через~$s_3.$

По определению \ref{def:sim} это означает, что $z_1^p\sim z_2^p,$ т.\,е.
каузальные матрицы обладают сходством. Определим новую каузальную
матрицу $z_3^p$ следующим образом: $z_3^p=(e_1^3,e_2^3,\ldots,e_h^3),$ где для
каждого столбца $e_i^3$ найдется пара столбцов $e_j^1, e_k^2$ матриц $z_1^p$
и $z_2^p$ соответственно, таких что $e_i^3=e_j^1*e_k^2\ne \varnothing$ и $i\in
I^c(z_3^p),$ $j\in I^c(z_1^p),$ $k\in I^c(z_2^p).$ Иными словами,
матрица $z_3^p$ является обобщением матриц $z_1^p$ и $z_2^p$ и содержит
только те события, которые являются обобщением событий для обеих матриц\hbox{}.

Пусть $Z'_1$ и $Z'_2$~--- множества процедурных каузальных матриц, для которых
знаки $s_1$ и $s_2$ соответственно являются признаками. Найдем среди этих двух
множеств пару каузальных матриц, обладающих сходством: $(z_1^m,z_2^m).$ Далее
определим процедурную каузальную матрицу $z_4^m$~--- новую матрицу в каузальной
сети значений, которая будет являться обобщением матриц $z_1^m$ и $z_2^m$:
$z_4^m=(e_1^4,e_2^4,\ldots),$ где для каждого столбца $e_i^4$ найдется пара
столбцов $e_j^1, e_k^2$ матриц $z_1^m$  и $z_2^m$ соответственно, таких~что
\begin{itemize}
 \item в каждом из них ссылка на соответствующие значения знаков $s_1$
и $s_2$ заменена на ссылку на значение с единственной пустой матрицей $z_3^m$
вновь образуемого знака $s_3,$
 \item $e_i^4=e_j^1*e_k^2\ne \varnothing$ и \item либо одновременно $i\in I^c(z_4^m),$ $j\in I^c(z_1^m),$ $k\in I^c(z_2^m),$
 \item либо одновременно $i\in I^e(z_4^m),$ $j\in I^e(z_1^m),$ $k\in I^c(z_2^m).$
\end{itemize}

По сгенерированной паре матриц $z_3^p$  и $z_3^m$ с помощью процедуры
образования нового знака $\Psi$ в результате операции $\Theta^p$ получаем
новый знак $s_3,$ образ которого является обобщением образов знаков $s_1$
и $s_2,$ а значением является некоторая роль в обобщенном действии, выполняемом
как со знаком $s_1,$ так и со знаком $s_2.$ Вновь образованная процедурная
матрица $z_4^m$ может быть включена в один из существующих узлов на сети
значений, либо послужить отдельным узлом нового знака, представляющего новое
обобщенное дей\-ствие.

Приведем пример работы операции обобщения по образу. Пусть имеется два знака, $s_1$
и $s_2$, с именами \textit{"<яблоко">} и \textit{"<апельсин">} соответственно.
Каузальные матрицы для образных компонент знаков $s_1$  и $s_2$ выглядят
следующим образом (вместо единиц в матрице указаны имена при\-знаков):
\[
 z_1^p=\smallArray\qmatr{}{
 0&0& \up{"<зеленый">} \\
 0& \up{"<круглый">} &0 \\
 \up{"<кожура">} &0 &0 \\
 \up{"<тонкий">} &0 &0
 },
 \\
 z_2^p=\smallArray\qmatr{}{
 0&0& \up{"<оранжевый">} \\
 0& \up{"<круглый">} &0 \\
 \up{"<кожура">} &0 &0 \\
 \up{"<толстый">} &0 &0
 }.
\]
Компоненты значений знаков $s_1$ и $s_2$ связаны по каузальной сети
с процедурными знаками $s_3$ "<чистить яблоко"> и $s_4$ "<чистить апельсин">
(здесь вертикальной чертой отделены столбцы условий и эф\-фектов):
\[
 z_3^m=\smallArray\left[\begin{Array}{ccc|cccc}
 0&0&0&0&\up{"<стол">}&0\\
 0&\up{"<яблоко">}&0& 0&0&\up{"<яблоко">}\\
 0&0& \up{"<нож">} &0 &0\\
 0& 0& 0 &\up{"<на">} &0&0\\
 \up{"<вплотную">}& 0& 0 &0 &0&0\\
 \up{"<кожура">} &0 &0 &\up{"<кожура">} &0&0\\
 \up{"<тонкий">} &0 &0 & \up{"<тонкий">} &0&0 \end{Array}
 \right]\!,
\]
\[
 z_4^m=\smallArray\left[\begin{Array}{ccc|cccc}
 0&0&0&0&\up{"<стол">}&0\\
 0&\up{"<апельсин">}&0& 0&0&\up{"<апельсин">}\\
 0&0& \up{"<пальцы">} &0 &0&0\\
 0& 0& 0 &\up{"<на">} &0&0\\
 \up{"<вплотную">}& 0& 0 &0 &0&0\\
 \up{"<кожура">} &0 &0 &\up{"<кожура">} &0&0\\
 \up{"<толстый">} &0 &0 & \up{"<толстый">} &0&0 \end{Array}
 \right]\!.
\]
В~результате выполнения операции обобщения по образу $\Theta^p$ формируются
два знака: обобщенный по признакам образа знак $s_5$ с именем "<фрукт">
и обобщенный по признакам значения знак $s_6$ чистить, представляющий собой
обобщенное действие, которое можно выполнить с фруктом\hbox{}:
\[
 z_5^p=\smallArray\qmatr{}{
 0& \up{"<круглый">} \\
 \up{"<кожура">} &0
 },
\]
\[
 z_6^m=\smallArray\left[\begin{Array}{ccc|cccc}
 0&0&0&0&\up{"<стол">}&0\\
 0&\up{"<фрукт">}&0& 0&0&\up{"<фрукт">}\\
 0& 0& 0 &\up{"<на">} &0&0\\
 \up{"<вплотную">}& 0& 0 &0 &0&0\\
 \up{"<кожура">} &0 &0 &\up{"<кожура">} &0&0\end{Array}
 \right]\!.
\]

\subsubsection{Операция замыкания по значению}
Другой важной когнитивной функцией является способность формировать возможные
сценарии на основе значений знаков. Особую роль этот процесс играет в житейской
картине мира, где большинство когнитивных процессов, формирующих поведение
человека, таких как планирование, коммуникация, основываются на нахождении,
применении и образовании новых сценариев \cite{Chudova2012b,Osipov2015d}. Под
сценарием в простейшем случае подразумевается некоторое действие, в котором
зафиксированы исполнители той или иной роли, т.\,е. сценарий является
специфицированным действием. Формально сценарием будем называть множество
знаков $Scen=\{ s_1,s_2,\ldots, s_n\} ,$ в котором единственным
процедурным знаком является $s_1,$ а все остальные знаки образуют две
подгруппы: $S_r$~--- множество знаков"=ролей и $S_o$~--- множество
знаков"=участников сценария. Знаки"=роли из множества $S_r$~--- это знаки
категорий, которые связаны с $s_1$ сценарным отношением $R_{sc}^m.$
Знаки"=участники из множества $S_o$~--- это либо знаки, не являющиеся
знаками категорий, связанные с $s_1$ сценарным отношением $R_{sc}^m,$ либо
знаки, которые в паре с другим знаком из множества $S_r$ принадлежат отношению
классификации~$R_{cl}^m.$

Определим операцию \textit{замыкания по значению} $\Theta^m\!,$ которая по
некоторому процедурному знаку $s$ формирует сценарий $Scen$:
$\Theta^m(s)=Scen.$ По сути формирование сценария заключается в итерационном
включении знаков в множество $Scen$ при рассмотрении элементов отношений
$R_{cl}^m$ и~$R_{sc}^m$:

\stextit{Шаг 1.} Включить в сценарий $Scen$ процедурный знак $s$: $Scen=\{ s\} .$

\stextit{Шаг 2.} Пополнить сценарий знаками, которые связаны с $s_1$ сценарным
отношением: $Scen=Scen\cup\{ s_i|(s_1,s_i)\in R_{sc}^m,
 I^e(s_i)=\varnothing\} .$

\stextit{Шаг 3.} Пополнить сценарий знаками, не являющимися знаками категорий и связанными с объектными знаками сценария отношением классификации:
$Scen=Scen\cup\{ s_j|(s_i,s_j)\in R_{cl}^m, s_i\in Scen,
 I^e(s_i)=\varnothing, S_p(s_i)=\varnothing, S_p(s_j)\ne \varnothing\} .$

\stextit{Шаг 4.} Повторять шаг 3 до тех пор, пока сценарий не перестанет
пополняться новыми знаками либо не будут перебраны все знаки из некоторого
множества, определяемого решаемой задачей. Например, при решении задачи
целеполагания используется только некоторое подмножество знаков, кандидатов
в образуемый сценарий \cite{Osipov2014c}.

\sskip
Пример сформированного сценария представлен рис.\:\ref{fig:scenarion}.

\fig{{caus_net-3}}{\caption{Пример сценария. Центральный процедурный
знак~--- $s_5.$ Знаки"=роли $S_r=\{ s_1,s_2,s_3,s_4\} ,$
знаки"=участники $S_o=\{ s_7,s_8,s_9,s_{10},s_{11}\} .$ Элементы
сценарного отношения обозначены сплошными стрелками, отношения
классификации~--- прерывистыми. Остальные условные обозначения те же, что
и на рис.\:\ref{fig:caus_net}}\label{fig:scenarion}}

\subsubsection{Операция агглютинации смыслов}

В~заключение приведем характерный пример операции на сети личностных
смыслов~--- операции агглютинации. Агглютинация, или слияние, смыслов двух
знаков позволяет сформировать новый смысл у третьего знака, обычно уже
существующего в картине мира. В~психологии новый смысл представляет собой
комбинацию, сочетание данных в опыте элементов, что представляет собой один из
основных механизмов воображения и творческой
деятельности \cite{Asmolov1990,Rubinshtain2000}. Примером слияния смыслов
в искусстве могут служить аллегорические фигуры Леонардо да Винчи,
а в лингвистике~--- такие слова как "<Мойдодыр"> или "<Ай\-болит">.

Используя введенный формализм, определим операцию агглютинации $\Theta^a$:
$S\times S\rightarrow S.$ Пусть $s_1=\langle n_1, \{ z_1^p\} ,
\{ z_1^m\} , \{ z_1^a\} \rangle,$ $s_2=\langle n_2,
\{ z_2^p\} , \{ z_2^m\} , \{ z_2^a\} \rangle.$
Образуемый или уже существующий в картине мира знак обозначим через $s_3.$
В~результате выполнения операции $\Theta^a$ у знака $s_3$ образуется новый
смысл, представляемый каузальной матрицей $z_3^a,$ которая строится следующим
образом. Пусть $z_1^a=(e_1^1, e_2^1,\ldots,e_h^1)$ и $z_2^a=(e_1^2,
e_2^2,\ldots,e_l^2),$ тогда каузальная матрица $z_3^a=(e_1^3,
e_2^3,\ldots,e_q^3),$ где $q=h+l,$ $I^c(z_3^a)=I^c(z_1^a)\cup \{
i+|I^c(z_1^a)||i\in I^c(z_2^a)\} ,$ $I^e(z_3^a)=I^e(z_1^a)\cup \{
i+|I^e(z_1^a)||i\in I^e(z_2^a)\} ,$~а
\[
 e_t^3=\begin{cases}
 e_t^1, &\up{если}\ t<|I^c(z_1^a)|,\\
 e_{t-|I^c(z_1^a)|}^2, &\up{если}\ |I^c(z_1^a)|<t<|I^c(z_1^a)|+|I^c(z_2^a)|,\\
 e_{t-|I^c(z_2^a)|}^1, &\up{если}\
 |I^c(z_1^a)|+|I^c(z_2^a)|<t<\\&\hfill <|I^c(z_1^a)|+|I^c(z_2^a)|+|I^e(z_1^a)|,\\
 e_{t-|I^c(z_1^a)|-|I^e(z_1^a)|}^2, &\up{если}\ t>|I^c(z_1^a)|+|I^c(z_2^a)|+|I^e(z_1^a)|.
 \end{cases}
\]
Переходя к нотации правил, мы можем сказать, что новый смысл, представляемый
правилом $z_3^a,$ является объединением условий и эффектов правил $z_1^a$
и $z_2^a$: $F_C(z_3^a)=F_C(z_1^a)\cup F_C(z_2^a)$ и либо
$F_A(z_3^a)=F_A(z_1^a)\cup F_A(z_2^a),$ либо $F_D(z_3^a)=F_D(z_1^a)\cup
F_D(z_2^a)$ \cite{Osipov2016a}.

В~качестве примера приведем образование нового личностного смысла у знака
"<Санкт"=Петербург"> в результате операции агглютинации смыслов знаков
"<газета"> и "<кофе">, представимых в виде следующих матриц (действия "<читать
газету"> "<пить кофе\hbox{}">):
\[
 z_1^a=\smallArray\left[\begin{Array}{ccc|cccc}
 0&0&0&0&0&0&\up{"<новости">}\\
 0&\up{"<кафе">}&0&0&\up{"<кафе">}&0&0\\
 0&\up{"<на">}&0&0 &\up{"<на">}&0&0\\
 0& 0& \up{"<Невский">}&0 &0&\up{"<Невский">}&0\\
 \up{"<газета">}&0&0&\up{"<газета">}&0&0&0\\
 \up{"<в">} &0 &0 &\up{"<в">}&0&0&0\\
 0&0 &0 & 0 &0&0&0 \end{Array}
 \right]\!,
\]
\[
 z_2^a=\smallArray\left[\begin{Array}{ccc|cccc}
 0&0&0&0&0&0&\up{"<кофе">}\\
 0&\up{"<кафе">}&0&0&\up{"<кафе">}&0&0\\
 0&\up{"<на">}&0&0 &\up{"<на">}&0&0\\
 0& 0& \up{"<Невский">}&0 &0&\up{"<Невский">}&0\\
 \up{"<чашка">}&0&0&\up{"<газета">}&0&0&0\\
 \up{"<в">} &0 &0 &\up{"<в">}&0&0&0\\
 0&0 &0 & 0 &0&0&0 \end{Array}
 \right]\!.
\]
Новая каузальная матрица $z_3^a$ будет выглядеть следующим образом. Столбцы
условий являются последовательным объединением столбцов"=условий матриц $z_1^a$
и $z_2^a$ (лишние строчки нулей опущены\hbox{})
\[
 \smallArray\left[\begin{Array}{cccccc}
 0&\up{"<кафе">}&0&0&\up{"<кафе">}&0\\
 0&\up{"<на">}&0&0 &\up{"<на">}&0\\
 0& 0& \up{"<Невский">}&0 &0&\up{"<Невский">}\\
 \up{"<газета">}&0&0&0&0&0\\
 0&0&0&\up{"<чашка">}&0&0\\
 \up{"<в">} &0 &0 &\up{"<в">}&0&0 \end{Array}
 \right]\!.
\]
Столбцы эффектов являются последовательным объединением столбцов эффектов
матриц $z_1^a$  и $z_2^a$ (лишние строчки нулей опущены\hbox{})
\[
 \smallArray\Arraycolsep-.05em\left[\begin{Array}{cccccccc}
 0&0 &0 &\up{"<новости">}&0&0&0&0\\
 0&0 &0 &0&0&0&0&\up{"<кофе">}\\
 0&\up{"<кафе">}&0&0&0&\up{"<кафе">}&0&0\\
 0&\up{"<на">}&0&0&0 &\up{"<на">}&0&0\\
 0& 0& \up{"<Невский">}&0&0 &0&\up{"<Невский">}&0\\
 \up{"<газета">}&0&0&0&0&0&0&0\\
 0&0&0&0&\up{"<чашка">}&0&0&0\\
 \up{"<в">} &0 &0&0&\up{"<в">}&0&0&0 \end{Array}
 \right]\!.
\]

В~данном случае вопрос выбора знака $s_3,$ у которого образуется новый смысл,
мы не рас\-смат\-риваем.

\section{Модели когнитивных функций}\label{sect:fun_models}

\subsection{Модель функции целеполагания на синтаксическом уровне\hbox{}}

Задача управления поведением субъекта деятельности включает в себя фазы
планирования и исполнения плана \cite{Osipov2002a,Osipov2003b,Osipov2008b}.
Первая задача планирования заключается в выдвижении цели~--- целеполагании.
Применим развитый выше аппарат к решению этой задачи. Синтез плана и его
исполнение будут рассмотрены во второй части па\-ра\-графа.

Целеполагание~--- сложный процесс, который включает в себя не только выдвижение
цели, но и определение условий и конкретного способа ее достижения. Как уже
было сказано, характер процесса целеполагания определяется типом картины мира
(КМ) субъекта. В~случае житейской КМ ведущей компонентой является значение,
т.\,е. субъект отталкивается от сюжетно"=ролевой структуры и использует уже
существующие знаки, чтобы выбрать подходящую ситуацию, которая и будет це\-левой.

Поскольку знак предмета потребности включен в картину мира субъекта, то следует
найти такой знак (или построить сценарий), личностный смысл которого обеспечил
бы достижение предмета потребности. На семантическом или операционном уровне
это означает поиск или построение такого знака (или сценария), в структуре
личного смысла которого существует действие (или существуют действия),
результатом применения которого (или которых~--- в случае сценария) к текущей
ситуации является образ предмета по\-треб\-ности.

\subsubsection{Алгоритм целеполагания GS}

Пусть знак $s^*$ имеет значение $\mu^*$~--- мотив. Опишем основные шаги
алгоритма це\-ле\-по\-ла\-гания.

\stextit{Шаг 1.} Переход $m^*\rightarrow m_1.$ Поиск на подсети значений такого
значения $m_1,$ знак которого имеет личностный смысл $a_1,$ интерпретируемый
правилом $r_1$  таким что множество его добавляемых фактов $A(r_1)$ таково
что $p^* \subseteq A(r_1).$ Иначе перейти к шагу~2.

\stextit{Шаг 2.} Переход $m_1 \rightarrow m_2.$ Поиск на подсети значений такого
значения $m_2,$ что соответствующий знак $s_2$ включает личностный смысл,
интерпретирующийся правилом $r_2$, таким что множество его добавляемых фактов
$A(r_2)$ таково что $p^* \subseteq A(r_1)\cup A(r_2).$ Построенный сценарий
есть цель\hbox{}.

\sskip
\textit{Иначе} процесс поиска на подсети значений повторяется, пока не будут
найдены знаки $s_1, s_2, \ldots s_n,$ такие что $p^* \subseteq A(r_1) \cup
A(r_2) \cup \ldots \cup A(r_n),$ где $r_1, r_2, \ldots, r_n$~--- правила,
интерпретирующие личностные смыслы знаков $s_1, s_2, \ldots s_n$
соответственно. Если такие знаки существуют, цель построена. Иначе цель не
формируется (см.~рис.\:\ref{fig:goal_set}).

\fig{{goal_set_alg_gos_ru}}{\caption{Схема алгоритма
целеполагания}\label{fig:goal_set}}

\subsection{Планирование в коллективе}

Хорошо известно, что задача планирования при определенных условиях относится
к классу \mbox{EXPSPACE} полных. Иными словами, ее вычислительная сложность
экспоненциальна (по памяти). При этом, показателем экспоненты является общее
число правил в системе~--- $N.$ Можно продемонстрировать, что в случае планирования на
знаковой картине мира сложность также будет экспоненциальна, однако
показателем экспоненты будет являться $N^*$~--- число правил в структуре
личностного смысла такого знака, в котором это число мак\-си\-мально.

Ясно, что чем меньше знаков в модели мира субъекта деятельности, т.\,е. чем
проще, чем менее дифференцирована модель мира, тем больше $N^*\!.$ В~вырожденном
случае, когда в модели мира содержится один знак,~$N=N^*\!.$

В~случае рассмотрения деятельности субъекта в коллективе при составлении плана
могут быть использованы наряду с личностными смыслами, в которые входят
признаки образа "<Я">, смыслы, относящиеся к знаку,
опосредующему другого участника коллектива. Иными словами, пусть у субъекта,
составляющего общий план действий, имеются наборы признаков
$F_1,F_2,\ldots,F_N,$ относящиеся к каждому члену коллектива, т.\,е. имеются
образы других участников деятельности. Если процедура $Interior$ будет наряду
с поиском на множестве личностных смыслов осуществлять поиск и на множестве
процедурных признаков $F_p^{other},$ для которых $F_C(f)\cap F_i\ne
\varnothing,$ $f\in F_p^{other},$ $i\in\{ 1,\ldots,N\} ,$ то
в итоговом плане будут содержаться действия, недоступные самому субъекту, но
выполнимые другими участниками кол\-лектива.

Таким образом, при составлении плана действий в коллективе происходит
распределение ролей по тому, какие действия в общем плане могут быть выполнены
каждым участником. Это возможно в том случае, когда у одного из членов
коллектива имеется представление обо всех участниках и доступных им дей\-ствиях.

На рис.\:\ref{fg:iagent} показана архитектура интеллектуального агента, который
обладает знаковой картиной мира и способен к составлению плана поведения
и распределению ролей в коалиции в описанном выше смысле\hbox{}.

\fig{{iagent}}{\caption{Архитектура интеллектуального агента со
знаковой картиной мира}\label{fg:iagent}}

\section{Некоторые приложения}\label{sect:applications}

\subsection{Планирование согласованных перемещений}

Представление пространственных и временных знаний в задачах достижения общей
цели группой автономных технических объектов (интеллектуальных агентов), в том
числе и беспилотных летательных аппаратов, обладает существенной спецификой по
сравнению с описанием таких знаний отдельного агента. Будем рассматривать
случай группового взаимодействия, в котором агенты решают общую задачу (имеют
общую цель, являющуюся вершиной иерархии подцелей каждого участника группы),
действуют независимо друг от друга (децентрализованное управление) и могут
ставить индивидуальные подцели, обладают разными стратегиями поведения,
различными базами знаний (картинами мира) и действуют в меняющейся среде\hbox{}.

К~ключевым особенностям представления знаний для задач с описанными свойствами
относятся: необходимость поддержки некоторого протокола коммуникации,
разделение знаний на коммуницируемые и некоммуницируемые (личные),
необходимость выделения компоненты знания, не зависящей от индивидуальных
(личных) характеристик агента, на основе которой формируется содержание
передаваемых сообщений, требование к наличию механизма связывания реальных
объектов внешней среды и процедур их распознавания с символьным коммуницируемым
представлением (\textit{symbol grounding problem}) \cite{Harnad1990,Barsalou1999},
поддержка механизмов пополнения картины мира (обучение и аб\-стра\-ги\-ро\-вание).

\subsubsection{Существующие подходы к представлению знаний о~пространстве и времени}
Существует достаточно большое количество моделей представления пространственных
знаний для навигации, построения карты местности, планирования траекторий
и других подобных задач. Многие из них создаются для решения частных
практических примеров и не претендуют на универсальность. Другие модели, как,
например, широко известная модель 4D/RCS \cite{Albus2007} или 3T
\cite{Bonasso1997}, применяются только для отдельных автономных технических
объектов, и в них не учитываются те особенности представления знаний, о которых
говорилось во введении. Существующие модели представления пространственных
и временных знаний, применимые в условиях группового взаимодействия, такие как
групповое расширение модели 4D/RCS \cite{Yakovlev2014}, обычно не учитывают
проблему привязки элементов знания к внешней среде и не подразумевают
какого"=либо сложного обучения, кроме манипуляции известными символами для
составления карты мест\-ности.

Среди имеющихся работ стоит отметить близкую к настоящей работе статью
Д.~Роя \cite{Roy2005}, посвященную проблеме привязанного к внешней среде
представления знаний, в том числе и пространственного характера. Используется
идея знакового представления, где знак понимается не в психологическом,
а в логическом смысле \cite{Pierce2000b}. Для описания объектов, действий
и ситуаций используются так называемые схемы (см.~для примера
рис.\:\ref{fg:roy_schema}). Схема согласуется с результатом обработки сенсорной
информации (распознавание категорий) и с помощью определенных на ее основе
действий обновляет представления агента о внешней среде и одновременно
производит изменения в этой среде\hbox{}.

\fig{{roy_schema}}{\caption{Схема объекта чашка (\textit{cup}), для которого
с помощью перцептивных процедур (\textit{detect}, \textit{measure}) определены свойства цвета
(\mbox{COLOR}) и формы (\mbox{SHAPE}), а также определены действия по
перемещению (\textit{Grip} и \textit{move}), зависящие от текущего положения чашки
(L)}\label{fg:roy_schema}}

С~помощью таких схем удается описать процесс коммуникации агентов, когда агент,
имеющий привязку некоторого символа к внешней среде, сообщает информацию об
этом символе другому агенту, не имеющему средств к проверке такой привязки.
Несмотря на успешную реализацию на роботе"=манипуляторе, оперирующем объектами
на столе, такой подход обладает существенными недостатками. Во-первых, не
используются процессы обучения, т.\,е. все схемы задаются разработчиком, хотя
и привязываются к реальным объектам с помощью заранее известных сенсорных
входов. Во-вторых, количество используемых Роем пространственно"=временных
отношений довольно ограничено (отношения "<содержится в">, "<соприкасается с">,
"<пред\-ше\-ствует">).

Стоит отметить, что в таких работах,
как \cite{Allen1983,Herskovits1997,Kuipers2000}, количество описываемых
отношений, с помощью которых задаются такие свойства, как топология, взаимное
расположение, расстояние, относительное движение, следование во времени,
пересечение во времени и~др., намного больше, и большинство из них необходимы
для описания пространственного движения, более сложного, чем ограниченное
движение манипулятора над столом\hbox{}.

В~настоящей работе для задания пространственных и временных отношений, не
зависящих от сенсорной привязки, используются подходы, разрабатываемые в рамках
теории ситуационного управления \cite{Pospelov1986}. Поспеловым и его учениками
предложен ряд псевдофизических логик, задающих достаточно широкий спектр
отношений, которые полностью покрывают все случаи, возникающие в задаче
двумерного пространственного перемещения агентов. Логический подход позволяет
не только описать ситуацию, но и реализовать вывод на знаниях, с помощью
которого можно предсказывать следующие состояния системы и пополнять знания без
наличия актуальной сенсорной ин\-фор\-мации.

\subsubsection{Когнитивный подход к представлению пространственно"=временных знаний\hbox{}}

Предлагаемая модель знаковой пространственно"=временной картины мира опирается
на работы в области прикладной семиотики \cite{Osipov1999} и на формальное
определения знака, данное в пп.~\ref{sect:first_def}
и \ref{sect:sint_level}.

Напомним, что в соответствии с предлагаемым подходом объекты и их свойства
в картине мира интеллектуального агента представляются в виде специальных
конструкций~--- знаков. Каждый знак $s$ обладает четырехкомпонентной
структурой: $s=\langle n, p, m, a\rangle$ (см.~рис.\:\ref{fg:sign}). Компонента
имени $n$ является согласованным в коллективе агентов условным обозначением
представляемого объекта или свойства. Компонента образа $p$ содержит процедуру
распознавания и категоризации представляемого объекта или свойства. Компонента
значения $m$ задает набор обобщенных согласованных в коллективе действий,
совершаемых с участием данного объекта. И, наконец, компонента личностного
смысла $a$ задает набор индивидуальных действий агента, совершаемых
с представляемым объектом и содержащих в качестве параметров его внутренние
характеристики. Например, для знака с именем "<книга"> образом является как
сама процедура распознавания, так и используе\-мые в ней характерные признаки
("<твердый переплет">, "<300 страниц">, "<о~живописи"> и~т.\,д.), значением~---
общепринятые действия, связанные с объектом книги ("<читать">, "<пересылать по
почте"> и~т.\,п.), личностным смыслом~--- личные действия агента, связанные
с объектом книги ("<читать перед сном">, "<подпирать дверь"> и~т.\,п.).
В этом примере для описания пространственно"=временной картины мира будут
использоваться только имена, образы и значения знаков\hbox{}.

Пространственно"=временная картина мира агента будет задаваться фрагментом
семиотический сети \cite{Panov2012b} $H=\langle H_P, H_A, H_M\rangle,$
состоящей из трех семантических сетей: $H_P=\langle 2^P, R_P\rangle$~--- сеть
с семейством отношений $R_P$ на множестве образом $P$  (таких, как отношения
сходства, противопоставления и эквивалентности), $H_A=\langle 2^A,
R_A\rangle$~--- сеть с семейством отношений $R_A$ на множестве личностных
смыслов $A$ (таких, как отношения агглютинации, поглощения
и противопоставления), $H_M=\langle 2^M, R_M\rangle$~--- сеть с семейством
отношений $R_M$ на множестве значений $M$ (таких, как ситуационные и сюжетные
от\-но\-шения).

Для привязки знаков к опосредуемым объектам внешней среды используются
распознающие автоматы. Специальным образом определенная иерархия таких
автоматов позволяет как описать процесс категоризации (распознавания) знака,
так и определить участие знака в действиях агента. Схема работы автомата
представлена на рис.\:\ref{fg:rb_cycle}.

Кратко напомним алгоритм работы автомата $R$ уровня иерархии $i.$ Каждый
момент времени $t$ он получает на вход последовательность векторов
действительных чисел от 0 до 1 с нижнего уровня иерархии. Входной вектор $\hat
x$ длины $q$ представляет собой веса входных признаков $F,$ участвующих
в распознавании выходных признаков $F^*\!.$ В~начальный момент работы автомата
поступает управляющий вектор $\hat x^{j+1}$ с верхнего уровня иерархии,
задающий предсказание значений весов выходного вектора, которые должны
получиться после завершения рабочего цикла распознающего автомата (через время
$h$). В~каждый момент времени $t$ распознающий автомат вычисляет текущий
весовой вектор $x^*$ выходных признаков длины $l$ и управляющий вектор $\hat x^j$
на нижний уровень иерархии длины $q.$ Автоматы связаны иерархическим
отношением, если выходные признаки (возможно, не все) дочернего автомата
участвуют в распознавании выходных признаков родительского автомата (являются
для последнего входными\hbox{}).

Состояние автомата $R$  задается множеством битовых матриц предсказания $Z$
размерности $q$ на $h.$ Каждому выходному признаку $f^*$ соответствует свой
набор матриц предсказания, в которых в столбце $t$ единицы соответствуют
необходимым для распознавания $f^*$ в момент времени $t$ входным признакам.
Если с помощью некоторой процедуры $\Delta$ множество столбцов всех матриц
распознавания для признака $f_p$ разделяется на множество столбцов, содержащих
всегда предшествую\-щие признаки (условия), и множество столбцов, содержащих
всегда последующие признаки (эффекты), то такой признак $f_p$ называется
процедурным и опосредует действия и про\-цессы.

Если между множеством знаков и множеством признаков, распознаваемых всеми
автоматами иерархии, установлено взаимно"=однозначное соответствие
(именование), то компоненты знака определяются следующим образом. Образом
знака $s,$ соответствующего признаку $f,$ является множество всех признаков,
участвующих в распознавании признака $f.$ Значением знака $s,$
соответствующего признаку $f,$  является множество всех процедурных признаков,
условия которых распознаются с помощью признака~$f.$

Привязка знака к внешним объектам и процессам осуществляется за счет того, что
входными признаками распознающих автоматов нижнего уровня иерархии являются
данные, поступающие с сенсоров. Формирование состояний автомата в процессе
наблюдения агента происходит с помощью специального алгоритма обучения
иерархической временной памяти (\textit{hierarchical temporal memory}, HTM)
\cite{George2009,Panov2015c}. HTM использует нейрофизиологические данные
о строении первичных участков коры головного мозга для формирования
биологически правдоподобной схемы с использованием марковских цепей
и алгоритмов иерархической кластеризации. К~основным принципам работы HTM
относятся: использование иерархии вычислительных узлов с восходящими
и нисходящими связями, использование Хэббовских правил обучения, разделение
пространственного и временного группировщиков, подавление активации для
формирования разреженного пред\-став\-ления.

Формируемые в результате работы алгоритма HTM связи между компонентами
вычислительного узла в рамках двух связанных иерархической связью узлов задают
матрицу предсказания для некоторого выходного признака в модели распознающих
ав\-то\-матов.

\subsubsection{Модельная задача}
В~качестве примера использования предлагаемой модели представления
пространственных и временных знаний опишем модельную задачу по перемещению
группы БПЛА на местности с различными типами препятствий. Пусть имеются два
агента, $A_1$ и $A_2,$ располагающиеся в координатах $(x_1,y_1)$ и $(x_2,y_2)$
соответственно. Агент $A_1$ обладает способностью разрушать препятствия
типа $C$ с большими размерами $r_1,$ не позволяющими ему напрямую построить
траекторию в целевую зону $G$ с координатами $(x_G,y_G).$ Агент $A_2$ обладает
способностью разрушать препятствия типа $B$ с небольшими размерами $r_2,$
позволяющими ему напрямую построить траекторию до целевой зоны $G$
(рис.\:\ref{fg:smart_reloc}). Местность полностью наблюдаема, а ее карта
доступна обоим агентам\hbox{}.

\fig{[scale=.945]{smart_reloc}}{\caption{Планирование совместного перемещения
двух агентов (БПЛА): сетчатые прямоугольники~--- препятствия типа $A,$
прямоугольники с наклонной штриховкой~--- препятствия типа $B$; \textit{а}~---
пространственные области в картинах мира агентов, \textit{б}"~~\textit{и}~---
этапы выполнения плана по перемещению в целевую область
$G$}\label{fg:smart_reloc}}

Агенты в своей картине мира опосредуют действия по перемещению знаками $st(i)$
(признаками $f_t,$ $t$~--- тип перемещения, $i=1,2,\ldots,$~--- имя действия),
которым соответствуют матрицы предсказания типа $Z_t,$  состоящие из трех
столбцов: $z_1=(l_x, I),$ $z_2=(l_y, d_u, E)$ и $z_3=(l_y, I, t_v),$
где $l_x,$ $l_y$~--- признаки, соответствующие категории расстояния
в пространственной логике \cite{Pospelov1986} (например, вплотную, близко,
далеко и~др.), $d_u$~--- признак, соответствующий категории направления
в пространственной логике (например, впереди, слева и~др.), $t_v$~--- признак,
соответствующий категории времени во временной логике [14] (например: скоро,
в будущем и~др.), $I$~--- признак присутствия самого агента, $E$~--- признак
отсутствия препятствия. В~матрице типа $Z_t$ столбцы $z_1$ и $z_2$ являются
столбцами условий, а столбец $z_3$~--- столбцом эф\-фектов.

Всем признакам из образа знака $st(i)$, в свою очередь, соответствуют свои
матрицы распознавания, полученные в результате обучения в процессе наблюдения
агента за средой. В~результате этого обучения и формируются дискретные
категории расстояния, направления и времени, такие как: слева, скоро, близко
и~т.\,п.

В~процессе планирования агент строит некий план достижения цели $G$, для
чего необходимо выполнить действие $st(1),$ в котором, например, $l_x$~---
вплотную, $l_y$~--- далеко (категоризация расстояния между точками $(x_1,y_1)$
или $(x_2,y_2)$ и $(x_G,y_G)$), $d_u$~--- впереди, $t_v$~--- скоро. Если для
агентов доступны только действия типа $st(2),$ где $l_x$~--- вплотную,
$l_y$~--- очень близко, $d_u$~--- впереди, слева и~т.\,п., $t_v$~--- очень
скоро, то происходит построение плана по перемещению, в котором строится
последовательность действий типа~$st(2).$

В~случае агента $A_1$, ввиду его больших размеров, на некотором этапе
признак $E$ будет отсутствовать и условие очередного действия $st(2)$ не будет
выполнено. В~таком случае, если агенту $A_1$ доступно некоторое действие по
передаче сообщения $M_1,$ в план может быть включена посылка информации
агенту $A_2$ о препятствии в области $obs_1$ (см.~рис.\:\ref{fg:smart_reloc},
\textit{в}). Если у агента $A_2$ имеется знак, опосредующий агента $A_1$
(представление о другом агенте), в образ которого входит его положение, то
агент $A_2$ сможет построить план перемещения в область $obs_1$
и устранению препятствия (см.~рис.\:\ref{fg:smart_reloc}, \textit{г}"~\textit{е}).

В~протоколе коммуникации сообщения не включают информацию об образах,
используемых в сообщении знаков, которые могут не совпадать у агентов $A_1$
и $A_2$ (различные матриц предсказания одних и тех же признаков вследствие
несовпадения процессов обучения). За счет согласованности значений этих знаков
(общее множество доступных действий) информация в сообщении может быть
интерпретирована адресатом. На завершающем этапе агенты поочередно перемещаются
в целевую зону (см.~рис.\:\ref{fg:smart_reloc},\,\textit{ж}"~~\textit{и}).

\subsection{Принятие диагностических решений}

Одними из первых экспериментов, проводимых с интеллектуальными агентами, обладающими
знаковой картиной мира, являлись эксперименты по моделированию приобретения
личностных смыслов специалистами в некоторой предметной области. Деятельность
специалистов в процессе принятия решения по поводу той или иной проблемы, как
и любая сознательная деятельность человека, является знаково опосредованной
с точки зрения теории деятельности, что делает правомерным использование
знаковых мо\-делей.

Архитектура интеллектуального агента, основанная на знаковом представлении,
была реализована в виде программного агента, взаимодействующего с другими
агентами в специальном модуле системы построения мультиагентных систем Jadex.
В~качестве предметной области, в которой действовали агенты, была выбрана
консультационная психология. Были проведены эксперименты по оценке соответствия
поведения агента поведению реального психолога"=кон\-суль\-танта.

\subsubsection{Строение интеллектуального агента}
В~данном прикладном примере будем рассматривать знак как отображение множества
имен $\mathbf{N}=\{ n\}$ во множество троек: $\mathbf{N}\to \{
(\mathbf{m},\mathbf{a},\mathbf{p})\},$ такое что
$s(n)=(\mathbf{m}\mathbf{,a}\mathbf{,p}),$ $\mathbf{n}\in N,$ где
$\mathbf{m}$~--- множество значений предмета или способов использования данного
объекта как предмета культуры, $\mathbf{a}$~--- множество действий с предметом
(множество личностных смыслов), $\mathbf{p}$~--- представление о предмете
(образ предмета), в который включена некоторая процедура распознавания образа
${{A}_p}.$ Каждый элемент знака~--- значение, личностный смысл или образ~---
включает в себя фрагмент соответствующей семантической сети на именах
$W=(\mathbf{N},\mathbf{R}),$ $\mathbf{R}$~--- совокупность отношений на
множестве имен, $\mathbf{R}\subseteq {{\mathbf{N}}^2}.$ Фрагментом~$F$
семантической сети $W,$ в свою очередь, назовем подмножество имен
${{\mathbf{N}}_F}\subseteq \mathbf{N}$ и подмножество
${{\mathbf{R}}_F}\subseteq \mathbf{R}$, такое что~$\mathbf R_F \subseteq
{{\mathbf{N}}_F}^2\!.$

Все множество значений формирует семантическую сеть на значениях ${{W}_m},$ все
множество личностных смыслов~--- семантическую сеть на смыслах ${{W}_a},$ все
множество образов~--- семантическую сеть на образах ${{W}_p}.$ Совокупность
всех трех семантических сетей образует картину мира агента\hbox{}.

Для моделирования процесса принятия решений специалистами в простейшем случае
достаточно использовать два компонента знака из трех: личностный смысл и образ.
Значение знака в данных экспериментах играет вспомогательную роль\hbox{}.

В~качестве предметной области была использована консультационная психология,
а агент моделировал поведение психолога"--консультанта в процессе анализа
жалоб и принятия решения о том, к какой категории относится проблематика
поступившей от клиента жалобы\hbox{}.

В~ходе экспериментов интеллектуальному агенту"=консультанту (ИАК) подавалась
серия текстовых жалоб, каждая из которых в свою очередь была разбита на
некоторое количество отрывков ("<реплик">). Целью агента являлось вынесение
решения по поводу того, к какой категории относится жалоба клиента. В~ходе
деятельности у агента менялось количество некоторого условного ресурса, что
моделировало энергетику практической деятельности психолога"=консультанта.
Из анализа получавшихся графиков изменения ресурса делался вывод о соответствии
поведения ИАК поведению реального психолога"=кон\-суль\-танта.

В~соответствии с существующими в современной теории и методологии
психологического консультирования представлениями, в качестве обобщающих категорий были
определены следующие типы жалоб: клиент испытывает проблемы в сфере мотивации
и регуляции деятельности (категория жалоб "<Мотивация">), в сфере
познавательных процессов (категория "<Познание">), в сфере эмоций и чувств
("<Эмоции">), в сфере формирования и проявления идентичности
("<Идентичность">). Жалоба поступает ИАК в виде последовательности реплик, до
тех пор пока ИАК не примет окончательного решения о типе проблематики всей
жалобы. Таким образом, для ИАК достижение мотива интерпретации текста жалобы
в целом происходит в ходе последовательного достижения ряда промежуточных
целей~--- интерпретации отдельных реплик (рис.\:\ref{fg:psy_agents1}).

\fig{{psy_agents1}}{\caption{Деятельность агента~---
психологического консультанта}\label{fg:psy_agents1}}

Цель и соответствующий план ее достижения задавались агенту заранее в знаковом
виде. Имена и образы, соответствующие знакам картины мира, также задавались ИАК
в готовом виде. Формирование же личностных смыслов, отражающих опыт ИАК,
происходило в процессе реального взаимодействия с предметом его де\-я\-тель\-ности.

Семантическая сеть образов представляла собой четыре корневых дерева с двумя
уровнями узлов, корнями которых являлись имена категорий жалоб
(рис.\:\ref{fg:psy_agents2}), а листьями~--- имена признаков категорий:
$\mathbf{N}={{\mathbf{N}}_{cat}}\cup {{\mathbf{N}}_{\op{ind}}}.$ Совокупность
отношений $\mathbf{R}$ состоит из одного несимметричного отношения
${{R}_{par}}$~--- "<Быть эле\-ментом">.

\fig{{psy_agents2}}{\caption{Сеть образов ИАК}\label{fg:psy_agents2}}

При реализации процедуры распознавания ${{A}_p}$ каждой паре
$({{N}_{cat}},{{N}_{\op{ind}}}),{{N}_{cat}}\in {{\mathbf{N}}_{cat}},$
${{N}_{\op{ind}}}\in {{\mathbf{N}}_{\op{ind}}}$, ставился в соответствие
некоторый вес $w\in [0, 1].$ Процессу интерпретации смысла реплики
соответствовал процесс ее категоризации, которому, в свою очередь, ставился
в соответствие процесс распознавания образа категории в данной реплике.
Процедура ${{A}_p}$ выдает 0, если знак присутствует в фокусе внимания, и 1 в противном
случае. Она интерпретировалась как принятие решения о том, к какой категории
относятся все реплики, накопленные в фокусе внимания агента при анализе жалобы
клиента\hbox{}.

Расчет весов на сети образов осуществлялся следующим образом. Изменение веса
$i$"~го знака (веса пары $({{N}_{cat}},{{N}_i})$), относящегося к категории
$cat,$ определялось как $\Delta_{\omega}^i=1+\frac{{{C}_{\omega
}}{{{\tilde{\omega }}}^i}}{1+{{e}^{-\frac{{\tilde{Q}}}{{{C}_Q}}}}},$
$\Delta_{\omega}^i\in [1,1+{{C}_{\omega}}],$ где ${{\tilde{\omega
}}^i}=\frac{re{{q}^i}}{\ssum\limits_j{re{{q}^j}}},$ ${{\tilde{\omega }}^i}\in
[0, 1]$~--- "<эффективный"> вес $i$"~го знака в тексте текущей реплики
(суммирование идет по всем знакам, найденным в текущей реплике),
$re{{q}^i}$~--- количество экземпляров $i$"~го знака в реплике,
$\tilde{Q}=\frac{{{Q}^{cat}}}{{{C}_{cat}}}+{{Q}^i}$~--- "<эффективная"> оценка
личностного смысла $i$"~знака, ${{Q}^{cat}}$~--- оценка личностного смысла
категории $cat,$ ${{Q}^i}$~--- оценка личностного смысла $i$"~го знака,
${{C}_{\omega}}>1,$ ${{C}_{cat}}>1$~--- некоторые константы. Вес категории
$cat$ вычислялся как ${{\hat{\omega }}_{cat}}=\ssum\limits_{j\in
[1,{{n}_{cat}}]}{\omega_t^jre{{q}^j}},$ ${{n}_{cat}}$~--- количество
знаков"=признаков, относящихся к категории $cat$; $\hat{\omega
}_{t+1}^i=\Delta_{\omega}^i\omega_t^{i,cat},$
$\omega_{t+1}^{i,cat}=\frac{\hat{\omega }_{t+1}^i}{\underset{j}{\mathop{\max
}}\,\hat{\omega }_{t+1}^j}$~--- изменение веса $i$"~го знака с течением
времени $t.$ Максимум вычислялся по всем знакам в сети на образах. Это связано
с тем, что увеличение веса конкретного знака сказывается не только на том
фрагменте семантической сети, которому соответствует образ знака"=категории, но
и на всей семантической сети на образах. За счет этого закрепляется опыт
распознавания всех знаков\hbox{}.

Основным этапом в процессе деятельности агента являлся этап анализа реплики.
Он основывался на частотном принципе: в тексте реплики подсчитывалось
количество слов, соответствующих именам знаков"=признаков в картине мира агента
(см.~выше). С~учетом личностных смыслов знаков подсчитывался вес каждой
категории для данной реплики. Если агент не накопил достаточно информации для
принятия решения о категории всей жалобы, он анализировал следующую реплику.
В~зависимости от индивидуальных характеристик агенты по"=разному накапливали
опыт анализа реплик. После принятия окончательного решения агент посылал
сообщение специальному агенту"=оракулу, который отправлял в качестве ответа
объективный результат анализа тестовой реплики. Объективность заключалась
в том, что агент"=оракул не имел личностных смыслов в своей картине мира,
т.\,е. результат его интерпретации не "<искажался"> накопленным личным опытом\hbox{}.

Личностный смысл знаков"=категорий и знаков"=признаков в картине мира ИАК был
представлен оценочной составляющей ${{Q}_a},$ которая изменялась в зависимости
от того, верным ли оказывалось решение, вынесенное по поводу предполагаемой
категории. Изменение оценки личностного смысла $i$"~го знака имеют вид\hbox{}
\[
 \Delta_Q^i=\begin{cases}
-{{C}_Q},& D(ag)\ne D(oq), \\
 {{C}_Q},& D(ag)=D(oq), \\
 \end{cases}
\]
где $D(ag)$~--- решение агента, $D(oq)$~--- правильный результат (решение
оракула $oq$), ${{C}_Q}>0$~--- некоторая константа.
$Q_{t+1}^i=Q_t^i+\Delta_Q^i$~--- изменение оценки личностного смысла $i$"~го
знака с течением времени~$t.$

В~картине мира ИАК, помимо знаков"=категорий и знаков"=признаков, присутствовали
также и вспомогательные знаки для обеспечения деятельности~ИАК:
\begin{itemize}
 \item знак ${{S}_{res\_an}}$ с именем ${{N}_{res\_an}}$ ("<Результат анализа
реплики">), с которым ИАК связывал действие ${{a}_{sig\_upd}}$ по обновлению
своей картины мира (запоминание результата анализа):
$\mathbf{N}_{{{{a}_{sig\_upd}}}}^{out}=\{ {{N}_{res\_an}}\} ,$
$\mathbf{N}_{{{{a}_{sig\_upd}}}}^{in}=\varnothing ,$
 \item знак ${{S}_{decis}}$ с именем ${{N}_{decis}}$ ("<Консультационное
решение">), в его образ входило название категории, к которой ИАК отнес
текущую жалобу,
 \item знак ${{S}_{hypot}}$ с именем ${{N}_{hypot}}$ ("<Консультационная
гипотеза">), в образ которого входили текущие представления агента о том,
к какой категории относится текущая жалоба,
 \item знак ${{S}_{text}}$ с именем ${{N}_{text}}$ ("<Текст реплики">),
с которым ИАК связывал действие ${{a}_{text}}$ по анализу текста и получению
результата анализа, $\mathbf{N}_{{{{a}_{text}}}}^{out}=\{
 {{N}_{text}}\} ,$ $\mathbf{N}_{{{a}_{text}}}^{in}=\{
 {{N}_{res\_an}}\} $, и действие ${{a}_{check}}$ по проверке своего
решения: $\mathbf{N}_{{{a}_{check}}}^{out}=\{
 {{N}_{text}},{{N}_{decis}}\} ,$
$\mathbf{N}_{{{a}_{check}}}^{in}=\varnothing .$
\end{itemize}

При анализе каждой реплики затрачивалось константное количество ${{C}_A}$
условного ресурса. В~случае подтверждения решения ИАК оракулом ресурс
увеличивался на некоторую константу ${{C}_r}{{C}_R}$ а в случае отрицательного
результата~--- уменьшался на~${{C}_R}$:
\[
 {{\Delta }_R}=\begin{cases}
-{{C}_R},& D(ag)\ne D(oq), \\
 {{C}_r}{{C}_R},& D(ag)=D(oq), \\
 \end{cases}
\]
${{C}_R}>0,$ ${{C}_r}>1.$ Если ресурс агента становился меньше 0, то ИАК
прекращал деятельность~--- наступало так называемое психологическое
выгорание спе\-ци\-а\-листа.

В~зависимости от стратегии того, как происходило накопление опыта анализа реплик клиентов и принятия
решения о категории жалобы, ИАК делились на четыре типа\hbox{}:
\begin{itemize}
 \item "<хаотичные"> ИАК принимали решение в пользу категории $cat$, после того
как эта категория набирала определенный критический вес ${{Y}_H}>0,$
 \item "<активные"> ИАК принимали решение в пользу категории $cat$, после того
как разница весов лидирующей категории в текущей гипотезе превышала вес
 "<второго места"> на некоторую критическую величину ${{Y}_A}>0,$
 \item "<активные"> ИАК принимали решение в пользу категории $cat$, после того
как разница весов лидирующей категории в текущей гипотезе превышала вес
 "<второго места"> на некоторую критическую величину ${{Y}_A}>{{Y}_P}>0,$
 \item "<стереотипные"> ИАК принимали решение в пользу категории $cat$, после
того как вес категории, которая была лидирующей в первой гипотезе
относительно проблематики текущей жалобы (после анализа первой реплики),
превышал критическое значение~${{Y}_S}>0.$

\end{itemize}

Индивидуальные особенности поведения агентов различных типов в процессе анализа
жалобы клиента представлены в табл.~1.

\begin{tabular}{ccc}
	\caption{Особенности поведения агентов различных типов.}
	Активный ИАК&	Пассивный ИАК&	Хаотичный ИАК&	Стереотипный ИАК\\
Проверяет все гипотезы как равнозначные?&	+&	+&	+&	-
(определяет гипотезу сразу после анализа первого текста)\\
При принятии решения учитывает суммарный вес, накопленный по всем анализировавшимся репликам?&	+&	+&	-&	+&
Как определяет, какую гипотезу следует принять?&	Если её накопленный вес превышает 70\%&	Если её накопленный вес превышает 90\%&	Если в любой реплике какая-либо категория "<опережает"> ближайшую на 10\%&	Принимает "<свою"> гипотезу, когда её накопленный вес превысит 70\%
\end{tabular}

\subsubsection{Система проведения экспериментов}

Для проведения экспериментов с интеллектуальными агентами"=консультантами была
реализована программная система в виде модуля системы построения мультиагентных
систем Jadex \cite{Jadex2016}. Выбор именно этой системы основывался на
следующих ее пре\-иму\-ще\-ствах:
\begin{itemize}
 \item блок рассуждений Jadex базируется на классической BDI (Belief Desire Intention) модели,
 \item облегчено задание внешней среды и действий агента с использованием XML,
 \item возможность расширения функциональности агентов, создание своих типов
агентов (не только BDI архитектуры) с помощью модулей на языке
программирования Java,
 \item возможность подключения мультиагентной среды JADE в качестве среды
коммуникации агентов с поддержкой стандарта FIPA (Foundation for Intelligent
 Physical Agents),
 \item использование мощного блока вывода на основе правил.
\end{itemize}

Перед началом проведения экспериментов происходит настройка среды моделирования
в контрольном центре. К~настраиваемым параметрам системы от\-но\-сятся:
\begin{itemize}
 \item число агентов, запускаемых в мультиагентной среде,
 \item тип запускаемых агентов,
 \item флаг сохранения снимков картины мира агента,
 \item путь к файлу настроек внешней среды.
\end{itemize}

После предварительной настройки модуля и его запуска появляется информация
о текущем состоянии мультиагентной системы, где от\-ра\-жается:
\begin{itemize}
 \item информация о внешней среде: список загруженных реплик и список действий,
совершенных агентами в процессе работы; проанализированные реплики
отмечаются галочками, там же находится кнопка выбора списка файлов реплик для
анализа;
 \item общая информация об агенте: тип агента, список имен знаков, находящихся
в фокусе внимания, список объектов (текстов) в фокусе внимания, список
проанализированных текстов, список принятых решений (правильные~--- зеленые,
неправильные~--- красные) и ответов оракула, текущее количество ресурсов;
справа располагается график изменения ресурса с течением времени;
 \item часть картины мира~--- часть сети на образах с цветовым обозначением
оценок личностных смыслов; есть возможность увеличения и уменьшения масштаба,
подсветка выделяемых вершин и ребер.
\end{itemize}

Агенты работают до тех пор, пока не исчерпается их ресурс или не закончатся
реплики жалоб клиентов. В~качестве реплик использовались либо отрывки
с объективным преобладанием какой"=либо одной категории (например
"<Мотивация">)~--- тогда среда считалась предсказуемой, либо отрывки,
относящиеся по проблематике к различным категориям~--- тогда среда считалась
слу\-чайной.

\subsubsection{Результаты экспериментов}

В~результате проведения экспериментов для каждого агента получается набор
снимков его картины мира через некоторые промежутки времени (порядка 1000
снимков), из которых формируется видеоролик эволюции картины мира агента,
а также график изменения ресурса с течением времени. Характерные снимки
представлены на рис.\:\ref{fg:psy_agents5} и \ref{fg:psy_agents6} (в~конце
работы агента\hbox{}).

\fig{{psy_agents5}}{\caption{Картина мира агента в конце работы}\label{fg:psy_agents5}}

\fig{{psy_agents6}}{\caption{Фрагмент картины мира агента в конце
работы}\label{fg:psy_agents6}}

На снимках отражаются только те связи (и~только те знаки), веса связей которых
максимальны на текущий момент в картине мира~--- выбирается по 25
знаков"=признаков для каждой категории с максимальным весом. Толщина связей на
снимках прямо пропорциональна весу пар знак"--категория. Категории
обозначаются квадратами, знаки"=признаки~--- овалами. В~процессе эволюции
картины мира на снимках появляются новые знаки (вес которых оказался в списке 25
наибольших для данной категории), выделяемые черным, и изменяются толщины ребер\hbox{}.

Наибольший интерес представляют графики изменения ресурсов агентов различных
типов, представленные на рис.\:\ref{fg:psy_agents7}.

\fig{[scale=.97]{psy_agents7}}{\caption{Графики изменения количества ресурса
(по оси ординат) в течением времени (по оси абсцисс)}\label{fg:psy_agents7}}

Цвета соответствуют оценкам личностных смыслов знаков. В~начале оценки
отсутствуют: все узлы одинакового лазурного цвета и в скобках рядом
с именами знаков одинаковые нулевые значения. Затем в ходе работы агента,
в процессе накопления им опыта знаки приобретают различные оценки:
отрицательные (оттенки синего и красного цветов, отрицательные значения оценок
в скобках) и положительные (оттенки зеленого и желтого цветов, положительные
значения оценок в скобках\hbox{}).

В~процессе работы ИАК, приобретая оценки личностных смыслов, начинает
по"=разному относиться к различным знакам. Те знаки, которые участвовали
в принятии верного решения, приобретают положительную оценку, и ИАК придает им
больший вес при встрече в очередной реплике. Те же знаки, которые участвовали
в принятии неверного решения, приобретают отрицательную оценку, и ИАК не
замечает их в очередных репликах. Такая нагрузка профессиональных знаний
личностными смыслами хорошо согласуется с поведением начинающего
психолога"=кон\-суль\-танта.

Из приведенных графиков следует, что у агентов различных типов (обладающих
разными индивидуальными характеристиками) графики имеют различный вид и имеют
характерные особенности, которые соответствуют особенностям поведения реальных
психологов"=консультантов. Например, "<выгорание"> у хаотичного ИАК в случайной
среде происходит не сразу (как у агентов других типов), а только с течением
большего промежутка времени, т.\,е. в среднем время его работы в два раза
выше. Это связано с особенностью его поведения~--- отсутствием "<памяти">:
агент не запоминает, к какой категории относились предыдущие запросы,
а находится в ожидании такого запроса, в котором какая"=либо категория будет
существенно преобладать над другой. Это позволяет ему в случайной среде, где
тип попавшейся реплики случаен, вести себя более успешно. С~другой стороны,
следует отметить, что активный агент быстрее набирает ресурс, чем пассивный,
поскольку ему достаточно меньшего количества реплик, относящихся
к данной категории, чтобы принять решение в ее пользу. Примечательно
также, что стереотипный агент, ждущий подтверждения своей первоначальной
гипотезы, "<выгорает"> даже в предсказуемой среде, в отличие от агентов других
типов\hbox{}.

Представленные особенности поведения интеллектуальных агентов, выраженные
в механизме распознавания знаков"=категорий и в динамике ресурса, хорошо
согласуются с реальными особенностями поведения консультантов"=людей
с различными индивидуальными стратегиями. Этот результат говорит о том,
что представленная архитектура агентов со знаковой картиной мира применима для
моделирования поведения специалистов в соответствующих предметных об\-ластях.

\section{Выводы}

Выше было предложение описание знаковой картины мира на
синтаксическом, семантическом и структурном уровнях. На синтаксическом уровне
были введены основные компоненты знака и базовые семейства отношений на их
множестве. Рассмотрены  три типа семантических сетей и базовые операции на этих
сетях: операции обобщения, замыкания по значениям и агглютинации смыслов.
На семантическом уровне каждая компонента знака была описана с помощью языка
предикатных символов и правил, были даны описания итеративных процедур работы
образной компоненты знака и образования нового знака. На структурном уровне
были учтены нейрофизиологические данные и предложена специальная математическая
структура~--- каузальная матрица, а также введено понятие каузальной сети, в которой
реализуются основные отношения на трех типах семантических сетей
синтаксического уровня. Приведенные в конце главы приложения, использующие
введенный формализм, содержат иллюстративные примеры применения знакового
подхода\hbox{}.

\endgroup
